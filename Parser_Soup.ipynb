{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Parser_Soup.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pjt_hfXJNLI",
        "colab_type": "code",
        "colab": {},
        "outputId": "6bf4ce33-aeeb-4a4c-c06f-20a246c29520"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import csv\n",
        "#План:\n",
        "    #1. выяснить количество страниц\n",
        "    #2. Сформировать список урлов на страницу выдачи \n",
        "    #3. Собрать данные\n",
        "def get_html(url):\n",
        "    r = requests.get(url)\n",
        "    return r.text\n",
        "\n",
        "def get_html(url):\n",
        "    r = requests.get(url)\n",
        "    return r.text\n",
        "\n",
        "def write_csv(data):\n",
        "    with open('19376.csv', 'a') as f:\n",
        "        writer = csv.writer(f)\n",
        "        \n",
        "        writer.writerow((data['title'],\n",
        "                                    data['url']))\n",
        "\n",
        "def get_page_data(html):\n",
        "    soup = BeautifulSoup(html, 'lxml')\n",
        "    \n",
        "    ads = soup.find('table', class_ = 'views-view-grid cols-4').find_all('div', class_ = 'views-field views-field-name')\n",
        "    \n",
        "    for ad in ads:\n",
        "        try:\n",
        "            title = ad.find('span', class_='field-content').find('a').text.strip()\n",
        "        except:\n",
        "            title = ' '\n",
        "        try:\n",
        "            url = 'http://1937god.info'+ ad.find('span', class_='field-content').find('a').get('href')\n",
        "        except:\n",
        "            url = ' '\n",
        "            \n",
        "        data = {'title':title,\n",
        "                    'url':url}\n",
        "        write_csv(data)\n",
        "    print(len(ads))\n",
        "    \n",
        "def main ():\n",
        "    url = \"http://1937god.info/persons?page=1\"\n",
        "    base_url = 'http://1937god.info/persons?'\n",
        "    page_part = 'page='\n",
        "    \n",
        "    #total_pages = get_total_pages(get_html(url))\n",
        "    \n",
        "    for i in range(1, 36):\n",
        "        url_gen = base_url + page_part + str(i)\n",
        "        print(url_gen)\n",
        "        html = get_html(url_gen)\n",
        "        get_page_data(html)\n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://1937god.info/persons?page=1\n",
            "50\n",
            "http://1937god.info/persons?page=2\n",
            "50\n",
            "http://1937god.info/persons?page=3\n",
            "50\n",
            "http://1937god.info/persons?page=4\n",
            "50\n",
            "http://1937god.info/persons?page=5\n",
            "50\n",
            "http://1937god.info/persons?page=6\n",
            "50\n",
            "http://1937god.info/persons?page=7\n",
            "50\n",
            "http://1937god.info/persons?page=8\n",
            "50\n",
            "http://1937god.info/persons?page=9\n",
            "50\n",
            "http://1937god.info/persons?page=10\n",
            "50\n",
            "http://1937god.info/persons?page=11\n",
            "50\n",
            "http://1937god.info/persons?page=12\n",
            "50\n",
            "http://1937god.info/persons?page=13\n",
            "50\n",
            "http://1937god.info/persons?page=14\n",
            "50\n",
            "http://1937god.info/persons?page=15\n",
            "50\n",
            "http://1937god.info/persons?page=16\n",
            "50\n",
            "http://1937god.info/persons?page=17\n",
            "50\n",
            "http://1937god.info/persons?page=18\n",
            "50\n",
            "http://1937god.info/persons?page=19\n",
            "50\n",
            "http://1937god.info/persons?page=20\n",
            "50\n",
            "http://1937god.info/persons?page=21\n",
            "50\n",
            "http://1937god.info/persons?page=22\n",
            "50\n",
            "http://1937god.info/persons?page=23\n",
            "50\n",
            "http://1937god.info/persons?page=24\n",
            "50\n",
            "http://1937god.info/persons?page=25\n",
            "50\n",
            "http://1937god.info/persons?page=26\n",
            "50\n",
            "http://1937god.info/persons?page=27\n",
            "50\n",
            "http://1937god.info/persons?page=28\n",
            "50\n",
            "http://1937god.info/persons?page=29\n",
            "50\n",
            "http://1937god.info/persons?page=30\n",
            "50\n",
            "http://1937god.info/persons?page=31\n",
            "50\n",
            "http://1937god.info/persons?page=32\n",
            "50\n",
            "http://1937god.info/persons?page=33\n",
            "50\n",
            "http://1937god.info/persons?page=34\n",
            "50\n",
            "http://1937god.info/persons?page=35\n",
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goTO-UiqJNLW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import csv\n",
        "\n",
        "def get_html(url):\n",
        "    r = requests.get(url)\n",
        "    return r.text\n",
        "\n",
        "def write_csv(data1):\n",
        "    with open('19379.csv', 'a') as f:\n",
        "        writer = csv.writer(f)\n",
        "        \n",
        "        writer.writerow((data1['text']))\n",
        "\n",
        "def get_page_data(html):\n",
        "    soup = BeautifulSoup(html, 'lxml')\n",
        "    ads = soup.find('div', class_ = 'taxonomy-term vocabulary-subjects').find_all('div', class_ = 'content')\n",
        "    \n",
        "    for ad in ads:\n",
        "        try:\n",
        "            text = ad.find('div', class_='taxonomy-term-description').find('p').text.strip()\n",
        "        except:\n",
        "            text = ' '\n",
        "            \n",
        "        data1 = {'text':text}\n",
        "        write_csv(data1)\n",
        "    \n",
        "def main (): \n",
        "    url = \"http://1937god.info/taxonomy/term/934\"\n",
        "    data = pd.read_csv(\"C:\\\\Users\\\\User\\\\PycharmProjects\\\\19375.csv\", engine ='python')\n",
        "    \n",
        "    for a in data['http://1937god.info/taxonomy/term/40']:\n",
        "        html = get_html(a)\n",
        "        get_page_data(html)\n",
        "        \n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Umf6mKWgJNLl",
        "colab_type": "code",
        "colab": {},
        "outputId": "55576eea-ba1f-4a3c-94b4-91d5f4b1e1d1"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "data = pd.read_csv(\"C:\\\\Users\\\\User\\\\PycharmProjects\\\\19376.csv\", engine ='python')\n",
        "data.head()\n",
        "data.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Алкснис Яков Иванович + 28.07.1938</th>\n",
              "      <th>http://1937god.info/taxonomy/term/40</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>Алкснис Ян Янович + 23.12.1943</td>\n",
              "      <td>http://1937god.info/taxonomy/term/454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>Альшанский Анатолий Романович + 25 12 1940</td>\n",
              "      <td>http://1937god.info/taxonomy/term/995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>Альшиц Даниил Нотанович</td>\n",
              "      <td>http://1937god.info/taxonomy/term/1508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>Алякринский Николай Владимирович + 22.02.1938</td>\n",
              "      <td>http://1937god.info/taxonomy/term/933</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>Алякрицкий Борис Евгеньевич + 26.11.1937</td>\n",
              "      <td>http://1937god.info/taxonomy/term/934</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Алкснис Яков Иванович + 28.07.1938  \\\n",
              "0                 Алкснис Ян Янович + 23.12.1943   \n",
              "1     Альшанский Анатолий Романович + 25 12 1940   \n",
              "2                        Альшиц Даниил Нотанович   \n",
              "3  Алякринский Николай Владимирович + 22.02.1938   \n",
              "4       Алякрицкий Борис Евгеньевич + 26.11.1937   \n",
              "\n",
              "     http://1937god.info/taxonomy/term/40  \n",
              "0   http://1937god.info/taxonomy/term/454  \n",
              "1   http://1937god.info/taxonomy/term/995  \n",
              "2  http://1937god.info/taxonomy/term/1508  \n",
              "3   http://1937god.info/taxonomy/term/933  \n",
              "4   http://1937god.info/taxonomy/term/934  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3R6c1_a0JNLu",
        "colab_type": "code",
        "colab": {},
        "outputId": "376899a4-7bca-450b-9ec6-1e5b9e910835"
      },
      "source": [
        "data = pd.read_csv(\"C:\\\\Users\\\\User\\\\PycharmProjects\\\\19375.csv\", engine ='python')\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Алкснис Яков Иванович + 28.07.1938</th>\n",
              "      <th>http://1937god.info/taxonomy/term/40</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>Алкснис Ян Янович + 23.12.1943</td>\n",
              "      <td>http://1937god.info/taxonomy/term/454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>Альшанский Анатолий Романович + 25 12 1940</td>\n",
              "      <td>http://1937god.info/taxonomy/term/995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>Альшиц Даниил Нотанович</td>\n",
              "      <td>http://1937god.info/taxonomy/term/1508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>Алякринский Николай Владимирович + 22.02.1938</td>\n",
              "      <td>http://1937god.info/taxonomy/term/933</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>Алякрицкий Борис Евгеньевич + 26.11.1937</td>\n",
              "      <td>http://1937god.info/taxonomy/term/934</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Алкснис Яков Иванович + 28.07.1938  \\\n",
              "0                 Алкснис Ян Янович + 23.12.1943   \n",
              "1     Альшанский Анатолий Романович + 25 12 1940   \n",
              "2                        Альшиц Даниил Нотанович   \n",
              "3  Алякринский Николай Владимирович + 22.02.1938   \n",
              "4       Алякрицкий Борис Евгеньевич + 26.11.1937   \n",
              "\n",
              "     http://1937god.info/taxonomy/term/40  \n",
              "0   http://1937god.info/taxonomy/term/454  \n",
              "1   http://1937god.info/taxonomy/term/995  \n",
              "2  http://1937god.info/taxonomy/term/1508  \n",
              "3   http://1937god.info/taxonomy/term/933  \n",
              "4   http://1937god.info/taxonomy/term/934  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6kRQytxJNMJ",
        "colab_type": "code",
        "colab": {},
        "outputId": "23b4e9fc-2b61-4f50-cff4-26fa630cf77c"
      },
      "source": [
        "url = \"http://1937god.info/node/1\"\n",
        "base_url = 'http://1937god.info/node/'\n",
        "    \n",
        "    #total_pages = get_total_pages(get_html(url))\n",
        "    \n",
        "for i in range(1, 36):\n",
        "    url_gen = base_url + str(i)\n",
        "    print(url_gen)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://1937god.info/node/1\n",
            "http://1937god.info/node/2\n",
            "http://1937god.info/node/3\n",
            "http://1937god.info/node/4\n",
            "http://1937god.info/node/5\n",
            "http://1937god.info/node/6\n",
            "http://1937god.info/node/7\n",
            "http://1937god.info/node/8\n",
            "http://1937god.info/node/9\n",
            "http://1937god.info/node/10\n",
            "http://1937god.info/node/11\n",
            "http://1937god.info/node/12\n",
            "http://1937god.info/node/13\n",
            "http://1937god.info/node/14\n",
            "http://1937god.info/node/15\n",
            "http://1937god.info/node/16\n",
            "http://1937god.info/node/17\n",
            "http://1937god.info/node/18\n",
            "http://1937god.info/node/19\n",
            "http://1937god.info/node/20\n",
            "http://1937god.info/node/21\n",
            "http://1937god.info/node/22\n",
            "http://1937god.info/node/23\n",
            "http://1937god.info/node/24\n",
            "http://1937god.info/node/25\n",
            "http://1937god.info/node/26\n",
            "http://1937god.info/node/27\n",
            "http://1937god.info/node/28\n",
            "http://1937god.info/node/29\n",
            "http://1937god.info/node/30\n",
            "http://1937god.info/node/31\n",
            "http://1937god.info/node/32\n",
            "http://1937god.info/node/33\n",
            "http://1937god.info/node/34\n",
            "http://1937god.info/node/35\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CWHPn5mJNMT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#3 опись ГАРФ\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import csv\n",
        "#План:\n",
        "    #1. выяснить количество страниц\n",
        "    #2. Сформировать список урлов на страницу выдачи \n",
        "    #3. Собрать данные\n",
        "def get_html(url_2):\n",
        "    r = requests.get(url_2)\n",
        "    \n",
        "    return r.text\n",
        "\n",
        "def write_csv(data):\n",
        "    with open('garf_3.csv', 'a') as f:\n",
        "        writer = csv.writer(f)\n",
        "        \n",
        "        writer.writerow((data['familia'],\n",
        "                                    data['name'],\n",
        "                                    data['otch'],\n",
        "                                    data['together'],\n",
        "                                    data['nomer_dela'],\n",
        "                                    data['deloproizvod_nomer'],\n",
        "                                    data['krainie_dat'],\n",
        "                                    data['primechania'],\n",
        "                                    data['url'],))\n",
        "\n",
        "def get_page_data(html):\n",
        "    soup = BeautifulSoup(html, 'lxml', fromEncoding='utf-8')\n",
        "    \n",
        "    ads = soup.find_all('font', class_ = 'black')##[8].text.split()[4:7]\n",
        "    try:\n",
        "        familia = ads[6].text.split()[4]\n",
        "    except IndexError:\n",
        "        familia = 'NaN'\n",
        "    try:\n",
        "        name = ads[6].text.split()[5]\n",
        "    except IndexError:\n",
        "        name = 'NaN'\n",
        "    try:\n",
        "        otch = ads[6].text.split()[6]\n",
        "    except IndexError:\n",
        "        otch = 'NaN'\n",
        "    try:\n",
        "        together =  ' '.join(map(str, ads[6].text.split()[4:7]))\n",
        "    except IndexError:\n",
        "        together = 'NaN'\n",
        "    try:\n",
        "        nomer_dela = ads[0].text.split()[0]\n",
        "    except IndexError:\n",
        "        nomer_dela = 'NaN'\n",
        "    try:\n",
        "        deloproizvod_nomer = ads[1].text.split()[0]\n",
        "    except IndexError:\n",
        "        deloproizvod_nomer = 'NaN'\n",
        "    try:\n",
        "        krainie_dat =  ' '.join(map(str, ads[8].text.split()))#[0]\n",
        "    except IndexError:\n",
        "        krainie_dat = 'NaN'\n",
        "    try:\n",
        "        primechania = ' '.join(map(str, ads[10].text.split()))#[0]\n",
        "    except IndexError:\n",
        "        primechania = 'NaN'\n",
        "    try:\n",
        "        url =  'http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447215&fond=3236&opis=6065&delo=509718'\n",
        "    except IndexError:\n",
        "        url = 'NaN'\n",
        "            \n",
        "    data = {'familia':familia,\n",
        "                    'name':name,\n",
        "                    'otch':otch,\n",
        "                    'together':together,\n",
        "                    'nomer_dela':nomer_dela,\n",
        "                    'deloproizvod_nomer':deloproizvod_nomer,\n",
        "                    'krainie_dat':krainie_dat,\n",
        "                    'primechania':primechania,\n",
        "                    'url':url}\n",
        "    write_csv(data)\n",
        "    \n",
        "def main ():\n",
        "    url = \"http://1937god.info/persons?page=1\"\n",
        "    url_2 = \"http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447215&fond=3236&opis=6065&delo=5029718\"\n",
        "    url_3 = \"http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447215&fond=3236&opis=6065&delo=5039454\"\n",
        "    base_url = 'http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447215&fond=3236&opis=6065&delo=50'\n",
        "    page_part = 'page='\n",
        "    \n",
        "    \n",
        "    for i in range(29718, 39455):\n",
        "        url_2 = base_url + str(i)\n",
        "        html = get_html(url_2)\n",
        "        get_page_data(html)\n",
        "        \n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7D0wRyNJNMZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "data_3 = pd.read_csv(\"C:\\\\Users\\\\User\\\\PycharmProjects\\\\garf_3.csv\", engine ='python',names= ['familia', 'name','otch', 'together','nomer_dela', 'deloproizvod_nomer','krainie_dat', 'primechania', 'url'])\n",
        "\n",
        "pd.DataFrame.to_csv(data_3, 'garf_33.csv')\n",
        "#data.tail()\n",
        "#data.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBbDBREMJNMd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#4 опись ГАРФ\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import csv\n",
        "#План:\n",
        "    #1. выяснить количество страниц\n",
        "    #2. Сформировать список урлов на страницу выдачи \n",
        "    #3. Собрать данные\n",
        "def get_html(url_2):\n",
        "    r = requests.get(url_2)\n",
        "    return r.text\n",
        "\n",
        "def write_csv(data):\n",
        "    with open('garf_4.csv', 'a') as f:\n",
        "        writer = csv.writer(f)\n",
        "        \n",
        "        writer.writerow((data['familia'],\n",
        "                                    data['name'],\n",
        "                                    data['otch'],\n",
        "                                    data['together'],\n",
        "                                    data['nomer_dela'],\n",
        "                                    data['deloproizvod_nomer'],\n",
        "                                    data['krainie_dat'],\n",
        "                                    data['primechania'],\n",
        "                                    data['url'],))\n",
        "\n",
        "def get_page_data(html):\n",
        "    soup = BeautifulSoup(html, 'lxml', fromEncoding='utf-8')\n",
        "    ads = soup.find_all('font', class_ = 'black')##[8]#.text.split()[4:7]\n",
        "    try:\n",
        "        familia = ads[6].text.split()[4]\n",
        "    except IndexError:\n",
        "        familia = 'NaN'\n",
        "    try:\n",
        "        name = ads[6].text.split()[5]\n",
        "    except IndexError:\n",
        "        name = 'NaN'\n",
        "    try:\n",
        "        otch = ads[6].text.split()[6]\n",
        "    except IndexError:\n",
        "        otch = 'NaN'\n",
        "    try:\n",
        "        together =  ' '.join(map(str, ads[6].text.split()[4:7]))\n",
        "    except IndexError:\n",
        "        together = 'NaN'\n",
        "    try:\n",
        "        nomer_dela = ads[0].text.split()[0]\n",
        "    except IndexError:\n",
        "        nomer_dela = 'NaN'\n",
        "    try:\n",
        "        deloproizvod_nomer = ads[1].text.split()[0]\n",
        "    except IndexError:\n",
        "        deloproizvod_nomer = 'NaN'\n",
        "    try:\n",
        "        krainie_dat =  ' '.join(map(str, ads[8].text.split()))#[0]\n",
        "    except IndexError:\n",
        "        krainie_dat = 'NaN'\n",
        "    try:\n",
        "        primechania = ' '.join(map(str, ads[10].text.split()))#[0]\n",
        "    except IndexError:\n",
        "        primechania = 'NaN'\n",
        "    try:\n",
        "        url =  \"http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447411&fond=3236&opis=6066&delo=5013235\"\n",
        "    except IndexError:\n",
        "        url = 'NaN'\n",
        "            \n",
        "    data = {'familia':familia,\n",
        "                    'name':name,\n",
        "                    'otch':otch,\n",
        "                    'together':together,\n",
        "                    'nomer_dela':nomer_dela,\n",
        "                    'deloproizvod_nomer':deloproizvod_nomer,\n",
        "                    'krainie_dat':krainie_dat,\n",
        "                    'primechania':primechania,\n",
        "                    'url':url}\n",
        "    write_csv(data)\n",
        "    \n",
        "def main ():\n",
        "    url = \"http://1937god.info/persons?page=1\"\n",
        "    url_4 = \"http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447411&fond=3236&opis=6066&delo=5013235\"\n",
        "    url_3 = \"http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447411&fond=3236&opis=6066&delo=5023597\"\n",
        "    base_url = 'http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447411&fond=3236&opis=6066&delo=50'\n",
        "    page_part = 'page='\n",
        "     \n",
        "    for i in range(13235, 23598):\n",
        "        url_2 = base_url + str(i)\n",
        "        html = get_html(url_2)\n",
        "        get_page_data(html)\n",
        "   \n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaLYlMajJNMi",
        "colab_type": "code",
        "colab": {},
        "outputId": "187daa8a-97dd-4220-ea1a-aeff1c5adf3f"
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "data = pd.read_csv(\"C:\\\\Users\\\\User\\\\PycharmProjects\\\\garf_4.csv\", engine ='python',names= ['familia', 'name','otch', 'together','nomer_dela', 'deloproizvod_nomer','krainie_dat', 'primechania', 'url'])\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>familia</th>\n",
              "      <th>name</th>\n",
              "      <th>otch</th>\n",
              "      <th>together</th>\n",
              "      <th>nomer_dela</th>\n",
              "      <th>deloproizvod_nomer</th>\n",
              "      <th>krainie_dat</th>\n",
              "      <th>primechania</th>\n",
              "      <th>url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>Кайгородов</td>\n",
              "      <td>Игнатий</td>\n",
              "      <td>Яковлевич</td>\n",
              "      <td>Кайгородов Игнатий Яковлевич</td>\n",
              "      <td>1.0</td>\n",
              "      <td>12711.0</td>\n",
              "      <td>01 мая 1955</td>\n",
              "      <td>1882г.р.</td>\n",
              "      <td>http://opisi.garf.su/default.asp?base=garf&amp;men...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>Королев</td>\n",
              "      <td>Василий</td>\n",
              "      <td>Иванович</td>\n",
              "      <td>Королев Василий Иванович</td>\n",
              "      <td>2.0</td>\n",
              "      <td>12712.0</td>\n",
              "      <td>01 мая 1955</td>\n",
              "      <td>1891г.р.</td>\n",
              "      <td>http://opisi.garf.su/default.asp?base=garf&amp;men...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>Кузнецов</td>\n",
              "      <td>Леонид</td>\n",
              "      <td>Федорович</td>\n",
              "      <td>Кузнецов Леонид Федорович</td>\n",
              "      <td>3.0</td>\n",
              "      <td>12713.0</td>\n",
              "      <td>01 мая 1955</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://opisi.garf.su/default.asp?base=garf&amp;men...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>Кастра</td>\n",
              "      <td>Альма</td>\n",
              "      <td>Мартыновна</td>\n",
              "      <td>Кастра Альма Мартыновна</td>\n",
              "      <td>4.0</td>\n",
              "      <td>12714.0</td>\n",
              "      <td>01 мая 1955</td>\n",
              "      <td>1884г.р.</td>\n",
              "      <td>http://opisi.garf.su/default.asp?base=garf&amp;men...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>Календро</td>\n",
              "      <td>Зоя</td>\n",
              "      <td>Леонидовна</td>\n",
              "      <td>Календро Зоя Леонидовна</td>\n",
              "      <td>5.0</td>\n",
              "      <td>12715.0</td>\n",
              "      <td>01 апреля 1955</td>\n",
              "      <td>1896г.р.</td>\n",
              "      <td>http://opisi.garf.su/default.asp?base=garf&amp;men...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      familia     name        otch                      together  nomer_dela  \\\n",
              "0  Кайгородов  Игнатий   Яковлевич  Кайгородов Игнатий Яковлевич         1.0   \n",
              "1     Королев  Василий    Иванович      Королев Василий Иванович         2.0   \n",
              "2    Кузнецов   Леонид   Федорович     Кузнецов Леонид Федорович         3.0   \n",
              "3      Кастра    Альма  Мартыновна       Кастра Альма Мартыновна         4.0   \n",
              "4    Календро      Зоя  Леонидовна       Календро Зоя Леонидовна         5.0   \n",
              "\n",
              "   deloproizvod_nomer     krainie_dat primechania  \\\n",
              "0             12711.0     01 мая 1955    1882г.р.   \n",
              "1             12712.0     01 мая 1955    1891г.р.   \n",
              "2             12713.0     01 мая 1955         NaN   \n",
              "3             12714.0     01 мая 1955    1884г.р.   \n",
              "4             12715.0  01 апреля 1955    1896г.р.   \n",
              "\n",
              "                                                 url  \n",
              "0  http://opisi.garf.su/default.asp?base=garf&men...  \n",
              "1  http://opisi.garf.su/default.asp?base=garf&men...  \n",
              "2  http://opisi.garf.su/default.asp?base=garf&men...  \n",
              "3  http://opisi.garf.su/default.asp?base=garf&men...  \n",
              "4  http://opisi.garf.su/default.asp?base=garf&men...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Lfn8jyoJNMn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.DataFrame.to_csv(data, 'garf_44.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcUgg7jmJNMs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#5 опись ГАРФ\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import csv\n",
        "#План:\n",
        "    #1. выяснить количество страниц\n",
        "    #2. Сформировать список урлов на страницу выдачи \n",
        "    #3. Собрать данные\n",
        "def get_html(url_2):\n",
        "    r = requests.get(url_2)\n",
        "    return r.text\n",
        "\n",
        "def write_csv(data):\n",
        "    with open('garf_5.csv', 'a') as f:\n",
        "        writer = csv.writer(f)\n",
        "        \n",
        "        writer.writerow((data['familia'],\n",
        "                                    data['name'],\n",
        "                                    data['otch'],\n",
        "                                    data['together'],\n",
        "                                    data['nomer_dela'],\n",
        "                                    data['deloproizvod_nomer'],\n",
        "                                    data['krainie_dat'],\n",
        "                                    data['primechania'],\n",
        "                                    data['url'],))\n",
        "\n",
        "def get_page_data(html):\n",
        "    soup = BeautifulSoup(html, 'lxml', fromEncoding='utf-8')\n",
        "    ads = soup.find_all('font', class_ = 'black')##[8]#.text.split()[4:7]\n",
        "\n",
        "    try:\n",
        "        familia = ads[6].text.split()[4]\n",
        "    except IndexError:\n",
        "        familia = 'NaN'\n",
        "    try:\n",
        "        name = ads[6].text.split()[5]\n",
        "    except IndexError:\n",
        "        name = 'NaN'\n",
        "    try:\n",
        "        otch = ads[6].text.split()[6]\n",
        "    except IndexError:\n",
        "        otch = 'NaN'\n",
        "    try:\n",
        "        together =  ' '.join(map(str, ads[6].text.split()[4:7]))\n",
        "    except IndexError:\n",
        "        together = 'NaN'\n",
        "    try:\n",
        "        nomer_dela = ads[0].text.split()[0]\n",
        "    except IndexError:\n",
        "        nomer_dela = 'NaN'\n",
        "    try:\n",
        "        deloproizvod_nomer = ads[1].text.split()[0]\n",
        "    except IndexError:\n",
        "        deloproizvod_nomer = 'NaN'\n",
        "    try:\n",
        "        krainie_dat =  ' '.join(map(str, ads[8].text.split()))#[0]\n",
        "    except IndexError:\n",
        "        krainie_dat = 'NaN'\n",
        "    try:\n",
        "        primechania = ' '.join(map(str, ads[10].text.split()))#[0]\n",
        "    except IndexError:\n",
        "        primechania = 'NaN'\n",
        "    try:\n",
        "        url =  \"http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447411&fond=3236&opis=6066&delo=5013235\"\n",
        "    except IndexError:\n",
        "        url = 'NaN'\n",
        "            \n",
        "    data = {'familia':familia,\n",
        "                    'name':name,\n",
        "                    'otch':otch,\n",
        "                    'together':together,\n",
        "                    'nomer_dela':nomer_dela,\n",
        "                    'deloproizvod_nomer':deloproizvod_nomer,\n",
        "                    'krainie_dat':krainie_dat,\n",
        "                    'primechania':primechania,\n",
        "                    'url':url}\n",
        "    write_csv(data)\n",
        "\n",
        "def main ():\n",
        "    url = \"http://1937god.info/persons?page=1\"\n",
        "    url_4 = \"http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447433&fond=3236&opis=6067&delo=5023598\"\n",
        "    url_3 = \"http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447433&fond=3236&opis=6067&delo=5046655\"\n",
        "    base_url = 'http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447433&fond=3236&opis=6067&delo=50'\n",
        "    page_part = 'page='\n",
        "    \n",
        "    for i in range(23598, 46656):\n",
        "        url_2 = base_url + str(i)\n",
        "        html = get_html(url_2)\n",
        "        get_page_data(html)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3ouSbmQJNMv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "data_5 = pd.read_csv(\"C:\\\\Users\\\\User\\\\PycharmProjects\\\\garf_5.csv\", engine ='python',names= ['familia', 'name','otch', 'together','nomer_dela', 'deloproizvod_nomer','krainie_dat', 'primechania', 'url'])\n",
        "pd.DataFrame.to_csv(data_5, 'garf_55.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-G4QhrUJNMy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#6 опись ГАРФ\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import csv\n",
        "#План:\n",
        "    #1. выяснить количество страниц\n",
        "    #2. Сформировать список урлов на страницу выдачи \n",
        "    #3. Собрать данные\n",
        "def get_html(url_2):\n",
        "    r = requests.get(url_2)\n",
        "    return r.text\n",
        "\n",
        "def write_csv(data):\n",
        "    with open('garf_6.csv', 'a') as f:\n",
        "        writer = csv.writer(f)\n",
        "        \n",
        "        writer.writerow((data['familia'],\n",
        "                                    data['name'],\n",
        "                                    data['otch'],\n",
        "                                    data['together'],\n",
        "                                    data['nomer_dela'],\n",
        "                                    data['deloproizvod_nomer'],\n",
        "                                    data['krainie_dat'],\n",
        "                                    data['primechania'],\n",
        "                                    data['url'],))\n",
        "\n",
        "def get_page_data(html):\n",
        "    soup = BeautifulSoup(html, 'lxml', fromEncoding='utf-8')\n",
        "    ads = soup.find_all('font', class_ = 'black')##[8]#.text.split()[4:7]\n",
        "    \n",
        "    try:\n",
        "        familia = ads[6].text.split()[4]\n",
        "    except IndexError:\n",
        "        familia = 'NaN'\n",
        "    try:\n",
        "        name = ads[6].text.split()[5]\n",
        "    except IndexError:\n",
        "        name = 'NaN'\n",
        "    try:\n",
        "        otch = ads[6].text.split()[6]\n",
        "    except IndexError:\n",
        "        otch = 'NaN'\n",
        "    try:\n",
        "        together =  ' '.join(map(str, ads[6].text.split()[4:7]))\n",
        "    except IndexError:\n",
        "        together = 'NaN'\n",
        "    try:\n",
        "        nomer_dela = ads[0].text.split()[0]\n",
        "    except IndexError:\n",
        "        nomer_dela = 'NaN'\n",
        "    try:\n",
        "        deloproizvod_nomer = ads[1].text.split()[0]\n",
        "    except IndexError:\n",
        "        deloproizvod_nomer = 'NaN'\n",
        "    try:\n",
        "        krainie_dat =  ' '.join(map(str, ads[8].text.split()))#[0]\n",
        "    except IndexError:\n",
        "        krainie_dat = 'NaN'\n",
        "    try:\n",
        "        primechania = ' '.join(map(str, ads[10].text.split()))#[0]\n",
        "    except IndexError:\n",
        "        primechania = 'NaN'\n",
        "    try:\n",
        "        url =  \"http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447449&fond=3236&opis=6068&delo=5046656\"\n",
        "    except IndexError:\n",
        "        url = 'NaN'\n",
        "            \n",
        "    data = {'familia':familia,\n",
        "                    'name':name,\n",
        "                    'otch':otch,\n",
        "                    'together':together,\n",
        "                    'nomer_dela':nomer_dela,\n",
        "                    'deloproizvod_nomer':deloproizvod_nomer,\n",
        "                    'krainie_dat':krainie_dat,\n",
        "                    'primechania':primechania,\n",
        "                    'url':url}\n",
        "    write_csv(data)\n",
        "    \n",
        "def main ():\n",
        "    url = \"http://1937god.info/persons?page=1\"\n",
        "    url_2 = \"http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447449&fond=3236&opis=6068&delo=5046656\"\n",
        "    url_3 = \"http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447446&fond=3236&opis=6068&delo=5056299\"\n",
        "    base_url = 'http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447446&fond=3236&opis=6068&delo=50'\n",
        "    page_part = 'page='\n",
        "    \n",
        "    for i in range(46656, 56300):\n",
        "        url_2 = base_url + str(i)\n",
        "        html = get_html(url_2)\n",
        "        get_page_data(html)\n",
        "\n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKk60KroJNM2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "data_6 = pd.read_csv(\"C:\\\\Users\\\\User\\\\PycharmProjects\\\\garf_6.csv\", engine ='python',names= ['familia', 'name','otch', 'together','nomer_dela', 'deloproizvod_nomer','krainie_dat', 'primechania', 'url'])\n",
        "pd.DataFrame.to_csv(data_6, 'garf_66.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UDAcab_JNM6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#7 опись ГАРФ\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import csv\n",
        "#План:\n",
        "    #1. выяснить количество страниц\n",
        "    #2. Сформировать список урлов на страницу выдачи \n",
        "    #3. Собрать данные\n",
        "def get_html(url_2):\n",
        "    r = requests.get(url_2)\n",
        "    return r.text\n",
        "\n",
        "def write_csv(data):\n",
        "    with open('garf_7.csv', 'a') as f:\n",
        "        writer = csv.writer(f)\n",
        "        \n",
        "        writer.writerow((data['familia'],\n",
        "                                    data['name'],\n",
        "                                    data['otch'],\n",
        "                                    data['together'],\n",
        "                                    data['nomer_dela'],\n",
        "                                    data['deloproizvod_nomer'],\n",
        "                                    data['krainie_dat'],\n",
        "                                    data['primechania'],\n",
        "                                    data['url'],))\n",
        "\n",
        "def get_page_data(html):\n",
        "    soup = BeautifulSoup(html, 'lxml', fromEncoding='utf-8')\n",
        "    ads = soup.find_all('font', class_ = 'black')##[8]#.text.split()[4:7]\n",
        "    \n",
        "    try:\n",
        "        familia = ads[6].text.split()[4]\n",
        "    except IndexError:\n",
        "        familia = 'NaN'\n",
        "    try:\n",
        "        name = ads[6].text.split()[5]\n",
        "    except IndexError:\n",
        "        name = 'NaN'\n",
        "    try:\n",
        "        otch = ads[6].text.split()[6]\n",
        "    except IndexError:\n",
        "        otch = 'NaN'\n",
        "    try:\n",
        "        together =  ' '.join(map(str, ads[6].text.split()[4:7]))\n",
        "    except IndexError:\n",
        "        together = 'NaN'\n",
        "    try:\n",
        "        nomer_dela = ads[0].text.split()[0]\n",
        "    except IndexError:\n",
        "        nomer_dela = 'NaN'\n",
        "    try:\n",
        "        deloproizvod_nomer = ads[1].text.split()[0]\n",
        "    except IndexError:\n",
        "        deloproizvod_nomer = 'NaN'\n",
        "    try:\n",
        "        krainie_dat =  ' '.join(map(str, ads[8].text.split()))#[0]\n",
        "    except IndexError:\n",
        "        krainie_dat = 'NaN'\n",
        "    try:\n",
        "        primechania = ' '.join(map(str, ads[10].text.split()))#[0]\n",
        "    except IndexError:\n",
        "        primechania = 'NaN'\n",
        "    try:\n",
        "        url =  \"http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447215&fond=3236&opis=6065&delo=5029718\"\n",
        "    except IndexError:\n",
        "        url = 'NaN'\n",
        "            \n",
        "    data = {'familia':familia,\n",
        "                    'name':name,\n",
        "                    'otch':otch,\n",
        "                    'together':together,\n",
        "                    'nomer_dela':nomer_dela,\n",
        "                    'deloproizvod_nomer':deloproizvod_nomer,\n",
        "                    'krainie_dat':krainie_dat,\n",
        "                    'primechania':primechania,\n",
        "                    'url':url}\n",
        "    write_csv(data)\n",
        "    \n",
        "def main ():\n",
        "    url = \"http://1937god.info/persons?page=1\"\n",
        "    url_2 = \"http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447450&fond=3236&opis=6069&delo=5056300\"\n",
        "    url_3 = \"http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447451&fond=3236&opis=6069&delo=5066504\"\n",
        "    base_url = 'http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447451&fond=3236&opis=6069&delo=50'\n",
        "    page_part = 'page='\n",
        "    \n",
        "    for i in range(56300, 66505):\n",
        "        url_2 = base_url + str(i)\n",
        "        html = get_html(url_2)\n",
        "        get_page_data(html)\n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HXrcmf7JNM9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "data_7 = pd.read_csv(\"C:\\\\Users\\\\User\\\\PycharmProjects\\\\garf_7.csv\", engine ='python',names= ['familia', 'name','otch', 'together','nomer_dela', 'deloproizvod_nomer','krainie_dat', 'primechania', 'url'])\n",
        "pd.DataFrame.to_csv(data_7, 'garf_77.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxQdqRrJJNNB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#8 опись ГАРФ\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import csv\n",
        "#План:\n",
        "    #1. выяснить количество страниц\n",
        "    #2. Сформировать список урлов на страницу выдачи \n",
        "    #3. Собрать данные\n",
        "def get_html(url_2):\n",
        "    r = requests.get(url_2)\n",
        "    return r.text\n",
        "\n",
        "def write_csv(data):\n",
        "    with open('garf_8.csv', 'a') as f:\n",
        "        writer = csv.writer(f)\n",
        "        \n",
        "        writer.writerow((data['familia'],\n",
        "                                    data['name'],\n",
        "                                    data['otch'],\n",
        "                                    data['together'],\n",
        "                                    data['nomer_dela'],\n",
        "                                    data['deloproizvod_nomer'],\n",
        "                                    data['krainie_dat'],\n",
        "                                    data['primechania'],\n",
        "                                    data['url'],))\n",
        "\n",
        "def get_page_data(html):\n",
        "    soup = BeautifulSoup(html, 'lxml', fromEncoding='utf-8')\n",
        "    ads = soup.find_all('font', class_ = 'black')##[8]#.text.split()[4:7]\n",
        "    \n",
        "    try:\n",
        "        familia = ads[6].text.split()[4]\n",
        "    except IndexError:\n",
        "        familia = 'NaN'\n",
        "    try:\n",
        "        name = ads[6].text.split()[5]\n",
        "    except IndexError:\n",
        "        name = 'NaN'\n",
        "    try:\n",
        "        otch = ads[6].text.split()[6]\n",
        "    except IndexError:\n",
        "        otch = 'NaN'\n",
        "    try:\n",
        "        together =  ' '.join(map(str, ads[6].text.split()[4:7]))\n",
        "    except IndexError:\n",
        "        together = 'NaN'\n",
        "    try:\n",
        "        nomer_dela = ads[0].text.split()[0]\n",
        "    except IndexError:\n",
        "        nomer_dela = 'NaN'\n",
        "    try:\n",
        "        deloproizvod_nomer = ads[1].text.split()[0]\n",
        "    except IndexError:\n",
        "        deloproizvod_nomer = 'NaN'\n",
        "    try:\n",
        "        krainie_dat =  ' '.join(map(str, ads[8].text.split()))#[0]\n",
        "    except IndexError:\n",
        "        krainie_dat = 'NaN'\n",
        "    try:\n",
        "        primechania = ' '.join(map(str, ads[10].text.split()))#[0]\n",
        "    except IndexError:\n",
        "        primechania = 'NaN'\n",
        "    try:\n",
        "        url =  \"http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447215&fond=3236&opis=6065&delo=5029718\"\n",
        "    except IndexError:\n",
        "        url = 'NaN'\n",
        "            \n",
        "    data = {'familia':familia,\n",
        "                    'name':name,\n",
        "                    'otch':otch,\n",
        "                    'together':together,\n",
        "                    'nomer_dela':nomer_dela,\n",
        "                    'deloproizvod_nomer':deloproizvod_nomer,\n",
        "                    'krainie_dat':krainie_dat,\n",
        "                    'primechania':primechania,\n",
        "                    'url':url}\n",
        "    write_csv(data)\n",
        "    \n",
        "def main ():\n",
        "    url = \"http://1937god.info/persons?page=1\"\n",
        "    url_2 = \"http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447453&fond=3236&opis=6070&delo=5066505\"\n",
        "    url_3 = \"http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447456&fond=3236&opis=6070&delo=5077050\"\n",
        "    base_url = 'http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447456&fond=3236&opis=6070&delo=50'\n",
        "    page_part = 'page='\n",
        "    \n",
        "    for i in range(66505, 77051):\n",
        "        url_2 = base_url + str(i)\n",
        "        html = get_html(url_2)\n",
        "        get_page_data(html)\n",
        "\n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eD35gPO-JNNF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "data_8 = pd.read_csv(\"C:\\\\Users\\\\User\\\\PycharmProjects\\\\garf_8.csv\", engine ='python',names= ['familia', 'name','otch', 'together','nomer_dela', 'deloproizvod_nomer','krainie_dat', 'primechania', 'url'])\n",
        "pd.DataFrame.to_csv(data_8, 'garf_88.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7z6EyPZJNNI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#9 опись ГАРФ\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import csv\n",
        "#План:\n",
        "    #1. выяснить количество страниц\n",
        "    #2. Сформировать список урлов на страницу выдачи \n",
        "    #3. Собрать данные\n",
        "def get_html(url_2):\n",
        "    r = requests.get(url_2)\n",
        "    return r.text\n",
        "\n",
        "def write_csv(data):\n",
        "    with open('garf_9.csv', 'a') as f:\n",
        "        writer = csv.writer(f)\n",
        "        \n",
        "        writer.writerow((data['familia'],\n",
        "                                    data['name'],\n",
        "                                    data['otch'],\n",
        "                                    data['together'],\n",
        "                                    data['nomer_dela'],\n",
        "                                    data['deloproizvod_nomer'],\n",
        "                                    data['krainie_dat'],\n",
        "                                    data['primechania'],\n",
        "                                    data['url'],))\n",
        "\n",
        "def get_page_data(html):\n",
        "    soup = BeautifulSoup(html, 'lxml', fromEncoding='utf-8')\n",
        "    ads = soup.find_all('font', class_ = 'black')##[8]#.text.split()[4:7]\n",
        "\n",
        "    try:\n",
        "        familia = ads[6].text.split()[4]\n",
        "    except IndexError:\n",
        "        familia = 'NaN'\n",
        "    try:\n",
        "        name = ads[6].text.split()[5]\n",
        "    except IndexError:\n",
        "        name = 'NaN'\n",
        "    try:\n",
        "        otch = ads[6].text.split()[6]\n",
        "    except IndexError:\n",
        "        otch = 'NaN'\n",
        "    try:\n",
        "        together =  ' '.join(map(str, ads[6].text.split()[4:7]))\n",
        "    except IndexError:\n",
        "        together = 'NaN'\n",
        "    try:\n",
        "        nomer_dela = ads[0].text.split()[0]\n",
        "    except IndexError:\n",
        "        nomer_dela = 'NaN'\n",
        "    try:\n",
        "        deloproizvod_nomer = ads[1].text.split()[0]\n",
        "    except IndexError:\n",
        "        deloproizvod_nomer = 'NaN'\n",
        "    try:\n",
        "        krainie_dat =  ' '.join(map(str, ads[8].text.split()))#[0]\n",
        "    except IndexError:\n",
        "        krainie_dat = 'NaN'\n",
        "    try:\n",
        "        primechania = ' '.join(map(str, ads[10].text.split()))#[0]\n",
        "    except IndexError:\n",
        "        primechania = 'NaN'\n",
        "    try:\n",
        "        url =  \"http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447215&fond=3236&opis=6065&delo=5029718\"\n",
        "    except IndexError:\n",
        "        url = 'NaN'\n",
        "            \n",
        "    data = {'familia':familia,\n",
        "                    'name':name,\n",
        "                    'otch':otch,\n",
        "                    'together':together,\n",
        "                    'nomer_dela':nomer_dela,\n",
        "                    'deloproizvod_nomer':deloproizvod_nomer,\n",
        "                    'krainie_dat':krainie_dat,\n",
        "                    'primechania':primechania,\n",
        "                    'url':url}\n",
        "    write_csv(data)\n",
        "    \n",
        "def main ():\n",
        "    url = \"http://1937god.info/persons?page=1\"\n",
        "    url_2 = \"http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447458&fond=3236&opis=6071&delo=5077051\"\n",
        "    url_3 = \"http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447461&fond=3236&opis=6071&delo=5087416\"\n",
        "    base_url = 'http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447458&fond=3236&opis=6071&delo=50'\n",
        "    page_part = 'page='\n",
        "    \n",
        "    for i in range(77051, 87417):\n",
        "        url_2 = base_url + str(i)\n",
        "        html = get_html(url_2)\n",
        "        get_page_data(html)\n",
        "\n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tYcUO__JNNK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "data_9 = pd.read_csv(\"C:\\\\Users\\\\User\\\\PycharmProjects\\\\garf_9.csv\", engine ='python',names= ['familia', 'name','otch', 'together','nomer_dela', 'deloproizvod_nomer','krainie_dat', 'primechania', 'url'])\n",
        "pd.DataFrame.to_csv(data_9, 'garf_99.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWEIuyjjJNNN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#10 опись ГАРФ\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import csv\n",
        "#План:\n",
        "    #1. выяснить количество страниц\n",
        "    #2. Сформировать список урлов на страницу выдачи \n",
        "    #3. Собрать данные\n",
        "def get_html(url_2):\n",
        "    r = requests.get(url_2)\n",
        "    return r.text\n",
        "\n",
        "def write_csv(data):\n",
        "    with open('garf_10.csv', 'a') as f:\n",
        "        writer = csv.writer(f)\n",
        "        \n",
        "        writer.writerow((data['familia'],\n",
        "                                    data['name'],\n",
        "                                    data['otch'],\n",
        "                                    data['together'],\n",
        "                                    data['nomer_dela'],\n",
        "                                    data['deloproizvod_nomer'],\n",
        "                                    data['krainie_dat'],\n",
        "                                    data['primechania'],\n",
        "                                    data['url'],))\n",
        "\n",
        "def get_page_data(html):\n",
        "    soup = BeautifulSoup(html, 'lxml', fromEncoding='utf-8')\n",
        "    ads = soup.find_all('font', class_ = 'black')##[8]#.text.split()[4:7]\n",
        "\n",
        "    try:\n",
        "        familia = ads[6].text.split()[4]\n",
        "    except IndexError:\n",
        "        familia = 'NaN'\n",
        "    try:\n",
        "        name = ads[6].text.split()[5]\n",
        "    except IndexError:\n",
        "        name = 'NaN'\n",
        "    try:\n",
        "        otch = ads[6].text.split()[6]\n",
        "    except IndexError:\n",
        "        otch = 'NaN'\n",
        "    try:\n",
        "        together =  ' '.join(map(str, ads[6].text.split()[4:7]))\n",
        "    except IndexError:\n",
        "        together = 'NaN'\n",
        "    try:\n",
        "        nomer_dela = ads[0].text.split()[0]\n",
        "    except IndexError:\n",
        "        nomer_dela = 'NaN'\n",
        "    try:\n",
        "        deloproizvod_nomer = ads[1].text.split()[0]\n",
        "    except IndexError:\n",
        "        deloproizvod_nomer = 'NaN'\n",
        "    try:\n",
        "        krainie_dat =  ' '.join(map(str, ads[8].text.split()))#[0]\n",
        "    except IndexError:\n",
        "        krainie_dat = 'NaN'\n",
        "    try:\n",
        "        primechania = ' '.join(map(str, ads[10].text.split()))#[0]\n",
        "    except IndexError:\n",
        "        primechania = 'NaN'\n",
        "    try:\n",
        "        url =  \"http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447215&fond=3236&opis=6065&delo=5029718\"\n",
        "    except IndexError:\n",
        "        url = 'NaN'\n",
        "            \n",
        "    data = {'familia':familia,\n",
        "                    'name':name,\n",
        "                    'otch':otch,\n",
        "                    'together':together,\n",
        "                    'nomer_dela':nomer_dela,\n",
        "                    'deloproizvod_nomer':deloproizvod_nomer,\n",
        "                    'krainie_dat':krainie_dat,\n",
        "                    'primechania':primechania,\n",
        "                    'url':url}\n",
        "    write_csv(data)\n",
        "    \n",
        "def main ():\n",
        "    url = \"http://1937god.info/persons?page=1\"\n",
        "    url_2 = \"http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447462&fond=3236&opis=6072&delo=5087417\"\n",
        "    url_3 = \"http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447465&fond=3236&opis=6072&delo=5097393\"\n",
        "    base_url = 'http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447462&fond=3236&opis=6072&delo=50'\n",
        "    page_part = 'page='\n",
        "    \n",
        "    for i in range(87417, 97393):\n",
        "        url_2 = base_url + str(i)\n",
        "        html = get_html(url_2)\n",
        "        get_page_data(html)\n",
        "\n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIFNYFPKJNNP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "data_10 = pd.read_csv(\"C:\\\\Users\\\\User\\\\PycharmProjects\\\\garf_10.csv\", engine ='python',names= ['familia', 'name','otch', 'together','nomer_dela', 'deloproizvod_nomer','krainie_dat', 'primechania', 'url'])\n",
        "pd.DataFrame.to_csv(data_10, 'garf_1010.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjN34EywJNNT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#11 опись ГАРФ\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import csv\n",
        "#План:\n",
        "    #1. выяснить количество страниц\n",
        "    #2. Сформировать список урлов на страницу выдачи \n",
        "    #3. Собрать данные\n",
        "def get_html(url_2):\n",
        "    r = requests.get(url_2)\n",
        "    return r.text\n",
        "\n",
        "def write_csv(data):\n",
        "    with open('garf_11_2.csv', 'a') as f:\n",
        "        writer = csv.writer(f)\n",
        "        \n",
        "        writer.writerow((data['familia'],\n",
        "                                    data['name'],\n",
        "                                    data['otch'],\n",
        "                                    data['together'],\n",
        "                                    data['nomer_dela'],\n",
        "                                    data['deloproizvod_nomer'],\n",
        "                                    data['krainie_dat'],\n",
        "                                    data['primechania'],\n",
        "                                    data['url'],))\n",
        "\n",
        "def get_page_data(html):\n",
        "    soup = BeautifulSoup(html, 'lxml', fromEncoding='utf-8')\n",
        "    ads = soup.find_all('font', class_ = 'black')##[8]#.text.split()[4:7]\n",
        "\n",
        "    try:\n",
        "        familia = ads[6].text.split()[4]\n",
        "    except IndexError:\n",
        "        familia = 'NaN'\n",
        "    try:\n",
        "        name = ads[6].text.split()[5]\n",
        "    except IndexError:\n",
        "        name = 'NaN'\n",
        "    try:\n",
        "        otch = ads[6].text.split()[6]\n",
        "    except IndexError:\n",
        "        otch = 'NaN'\n",
        "    try:\n",
        "        together =  ' '.join(map(str, ads[6].text.split()[4:7]))\n",
        "    except IndexError:\n",
        "        together = 'NaN'\n",
        "    try:\n",
        "        nomer_dela = ads[0].text.split()[0]\n",
        "    except IndexError:\n",
        "        nomer_dela = 'NaN'\n",
        "    try:\n",
        "        deloproizvod_nomer = ads[1].text.split()[0]\n",
        "    except IndexError:\n",
        "        deloproizvod_nomer = 'NaN'\n",
        "    try:\n",
        "        krainie_dat =  ' '.join(map(str, ads[8].text.split()))#[0]\n",
        "    except IndexError:\n",
        "        krainie_dat = 'NaN'\n",
        "    try:\n",
        "        primechania = ' '.join(map(str, ads[10].text.split()))#[0]\n",
        "    except IndexError:\n",
        "        primechania = 'NaN'\n",
        "    try:\n",
        "        url =  \"http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447215&fond=3236&opis=6065&delo=5029718\"\n",
        "    except IndexError:\n",
        "        url = 'NaN'\n",
        "            \n",
        "    data = {'familia':familia,\n",
        "                    'name':name,\n",
        "                    'otch':otch,\n",
        "                    'together':together,\n",
        "                    'nomer_dela':nomer_dela,\n",
        "                    'deloproizvod_nomer':deloproizvod_nomer,\n",
        "                    'krainie_dat':krainie_dat,\n",
        "                    'primechania':primechania,\n",
        "                    'url':url}\n",
        "    write_csv(data)\n",
        "    \n",
        "def main ():\n",
        "    url = \"http://1937god.info/persons?page=1\"\n",
        "    url_2 = \"http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447466&fond=3236&opis=6073&delo=5097394\"\n",
        "    url_3 = \"http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447468&fond=3236&opis=6073&delo=5107830\"\n",
        "    base_url = 'http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447466&fond=3236&opis=6073&delo=5'\n",
        "    base_url_1 = 'http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447466&fond=3236&opis=6073&delo=50'\n",
        "    page_part = 'page='\n",
        "    \n",
        "    for i in range(97394, 107830):\n",
        "        if i < 100000:\n",
        "            url_2 = base_url_1 + str(i)\n",
        "        else:\n",
        "            url_2 = base_url + str(i)\n",
        "        html = get_html(url_2)\n",
        "        get_page_data(html)\n",
        "\n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRFLEs3KJNNZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "data_11 = pd.read_csv(\"C:\\\\Users\\\\User\\\\PycharmProjects\\\\garf_11_2.csv\", engine ='python',names= ['familia', 'name','otch', 'together','nomer_dela', 'deloproizvod_nomer','krainie_dat', 'primechania', 'url'])\n",
        "pd.DataFrame.to_csv(data_11, 'garf_1111.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLJ9ZQjKJNNc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#12 опись ГАРФ\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import csv\n",
        "#План:\n",
        "    #1. выяснить количество страниц\n",
        "    #2. Сформировать список урлов на страницу выдачи \n",
        "    #3. Собрать данные\n",
        "def get_html(url_2):\n",
        "    r = requests.get(url_2)\n",
        "    return r.text\n",
        "\n",
        "def write_csv(data):\n",
        "    with open('garf_12.csv', 'a') as f:\n",
        "        writer = csv.writer(f)\n",
        "        \n",
        "        writer.writerow((data['familia'],\n",
        "                                    data['name'],\n",
        "                                    data['otch'],\n",
        "                                    data['together'],\n",
        "                                    data['nomer_dela'],\n",
        "                                    data['deloproizvod_nomer'],\n",
        "                                    data['krainie_dat'],\n",
        "                                    data['primechania'],\n",
        "                                    data['url'],))\n",
        "\n",
        "def get_page_data(html):\n",
        "    soup = BeautifulSoup(html, 'lxml', fromEncoding='utf-8')\n",
        "    ads = soup.find_all('font', class_ = 'black')##[8]#.text.split()[4:7]\n",
        "\n",
        "    try:\n",
        "        familia = ads[6].text.split()[4]\n",
        "    except IndexError:\n",
        "        familia = 'NaN'\n",
        "    try:\n",
        "        name = ads[6].text.split()[5]\n",
        "    except IndexError:\n",
        "        name = 'NaN'\n",
        "    try:\n",
        "        otch = ads[6].text.split()[6]\n",
        "    except IndexError:\n",
        "        otch = 'NaN'\n",
        "    try:\n",
        "        together =  ' '.join(map(str, ads[6].text.split()[4:7]))\n",
        "    except IndexError:\n",
        "        together = 'NaN'\n",
        "    try:\n",
        "        nomer_dela = ads[0].text.split()[0]\n",
        "    except IndexError:\n",
        "        nomer_dela = 'NaN'\n",
        "    try:\n",
        "        deloproizvod_nomer = ads[1].text.split()[0]\n",
        "    except IndexError:\n",
        "        deloproizvod_nomer = 'NaN'\n",
        "    try:\n",
        "        krainie_dat =  ' '.join(map(str, ads[8].text.split()))#[0]\n",
        "    except IndexError:\n",
        "        krainie_dat = 'NaN'\n",
        "    try:\n",
        "        primechania = ' '.join(map(str, ads[10].text.split()))#[0]\n",
        "    except IndexError:\n",
        "        primechania = 'NaN'\n",
        "    try:\n",
        "        url =  \"http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447215&fond=3236&opis=6065&delo=5029718\"\n",
        "    except IndexError:\n",
        "        url = 'NaN'\n",
        "            \n",
        "    data = {'familia':familia,\n",
        "                    'name':name,\n",
        "                    'otch':otch,\n",
        "                    'together':together,\n",
        "                    'nomer_dela':nomer_dela,\n",
        "                    'deloproizvod_nomer':deloproizvod_nomer,\n",
        "                    'krainie_dat':krainie_dat,\n",
        "                    'primechania':primechania,\n",
        "                    'url':url}\n",
        "    write_csv(data)\n",
        "    \n",
        "def main ():\n",
        "    url = \"http://1937god.info/persons?page=1\"\n",
        "    url_2 = \"http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447472&fond=3236&opis=6074&delo=5107839\"\n",
        "    url_3 = \"http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447474&fond=3236&opis=6074&delo=5117404\"\n",
        "    base_url = 'http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447472&fond=3236&opis=6074&delo=5'\n",
        "    page_part = 'page='\n",
        "    \n",
        "    \n",
        "    for i in range(107839, 117405):\n",
        "        url_2 = base_url + str(i)\n",
        "        html = get_html(url_2)\n",
        "        get_page_data(html)\n",
        "\n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sO-ETXrJNNg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "data_12 = pd.read_csv(\"C:\\\\Users\\\\User\\\\PycharmProjects\\\\garf_12.csv\", engine ='python',names= ['familia', 'name','otch', 'together','nomer_dela', 'deloproizvod_nomer','krainie_dat', 'primechania', 'url'])\n",
        "pd.DataFrame.to_csv(data_12, 'garf_1212.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}