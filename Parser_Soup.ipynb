{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a href=\"http://1937god.info/taxonomy/term/271\">Белые</a>]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def main ():\n",
    "    html = open('C:\\\\Users\\\\User\\\\jupyterprojects\\\\1937_alphabit.html', encoding='utf-8').read()\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "    div = soup.find('div', class_= 'views-field views-field-name')\n",
    "    links = div.find_all('a',)\n",
    "    print(links)\n",
    "    #find.all\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"views-field views-field-name\"> <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/271\">Белые</a></span> </div>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def main ():\n",
    "    html = open('C:\\\\Users\\\\User\\\\jupyterprojects\\\\1937_alphabit.html', encoding='utf-8').read()\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "    div = soup.find('div',{'class':'views-field views-field-name'})\n",
    "    print(div)\n",
    "    #find.all\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a class=\"element-invisible element-focusable\" href=\"http://1937god.info/persons#main-content\">Перейти к основному содержанию</a>\n",
      "<a href=\"http://1937god.info/\" id=\"logo\" rel=\"home\" title=\"Главная\">\n",
      "<img alt=\"Главная\" src=\"./Алфавитный указатель _ 1937-й и другие годы_files/1937w.jpg\"/>\n",
      "</a>\n",
      "<a href=\"http://1937god.info/\" rel=\"home\" title=\"Главная\"><span>1937-й и другие годы</span></a>\n",
      "<a href=\"http://1937god.info/\">Главная</a>\n",
      "<a href=\"http://1937god.info/persons/%D0%B0\" title=\"\">А</a>\n",
      "<a href=\"http://1937god.info/persons/%D0%B1\" title=\"\">Б</a>\n",
      "<a href=\"http://1937god.info/persons/%D0%B2\" title=\"\">В</a>\n",
      "<a href=\"http://1937god.info/persons/%D0%B3\" title=\"\">Г</a>\n",
      "<a href=\"http://1937god.info/persons/%D0%B4\" title=\"\">Д</a>\n",
      "<a href=\"http://1937god.info/persons/%D0%B5\" title=\"\">Е</a>\n",
      "<a href=\"http://1937god.info/persons/%D0%B6\" title=\"\">Ж</a>\n",
      "<a href=\"http://1937god.info/persons/%D0%B7\" title=\"\">З</a>\n",
      "<a href=\"http://1937god.info/persons/%D0%B8\" title=\"\">И</a>\n",
      "<a href=\"http://1937god.info/persons/%D0%BA\" title=\"\">К</a>\n",
      "<a href=\"http://1937god.info/persons/%D0%BB\" title=\"\">Л</a>\n",
      "<a href=\"http://1937god.info/persons/%D0%BC\" title=\"\">М</a>\n",
      "<a href=\"http://1937god.info/persons/%D0%BD\" title=\"\">Н</a>\n",
      "<a href=\"http://1937god.info/persons/%D0%BE\" title=\"\">О</a>\n",
      "<a href=\"http://1937god.info/persons/%D0%BF\" title=\"\">П</a>\n",
      "<a href=\"http://1937god.info/persons/%D1%80\" title=\"\">Р</a>\n",
      "<a href=\"http://1937god.info/persons/%D1%81\" title=\"\">С</a>\n",
      "<a href=\"http://1937god.info/persons/%D1%82\" title=\"\">Т</a>\n",
      "<a href=\"http://1937god.info/persons/%D1%83\" title=\"\">У</a>\n",
      "<a href=\"http://1937god.info/persons/%D1%84\" title=\"\">Ф</a>\n",
      "<a href=\"http://1937god.info/persons/%D1%85\" title=\"\">Х</a>\n",
      "<a href=\"http://1937god.info/persons/%D1%86\" title=\"\">Ц</a>\n",
      "<a href=\"http://1937god.info/persons/%D1%87\" title=\"\">Ч</a>\n",
      "<a href=\"http://1937god.info/persons/%D1%88\" title=\"\">Ш</a>\n",
      "<a href=\"http://1937god.info/persons/%D1%89\" title=\"\">Щ</a>\n",
      "<a href=\"http://1937god.info/persons/%D1%8D\" title=\"\">Э</a>\n",
      "<a href=\"http://1937god.info/persons/%D1%8E\" title=\"\">Ю</a>\n",
      "<a href=\"http://1937god.info/persons/%D1%8F\" title=\"\">Я</a>\n",
      "<a href=\"http://1937god.info/\">Главная</a>\n",
      "<a href=\"http://1937god.info/cctags/page/1\">Облако тэгов</a>\n",
      "<a href=\"http://1937god.info/other\">Прочие статьи</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/271\">Белые</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/130\">Военные</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/582\">Депутаты ГД</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/144\">Дипломаты</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/986\">Из казаков</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/580\">Кадеты</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/126\">Карательные органы</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/210\">Лидеры нац. движений</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/215\">Меньшевики</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/131\">Партийные деятели</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/127\">Разведка</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/1481\">Сановники</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/750\">Священнослужители</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/129\">Творческие работники</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/234\">Троцкисты</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/146\">Ученые</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/246\">Харбинцы</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/265\">ЧСИР</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/128\">Эсеры</a>\n",
      "<a href=\"http://www.hrono.ru/\" rel=\"nofollow\">ПОРТАЛ ХРОНОС</a>\n",
      "<a href=\"http://www.hrono.info/forum/\" rel=\"nofollow\">ФОРУМ</a>\n",
      "<a href=\"http://www.pravitelimira.ru/portal/\" rel=\"nofollow\">ПРАВИТЕЛИ МИРА</a>\n",
      "<a href=\"http://nik2nik.ru/\" rel=\"nofollow\">ОТ НИКОЛАЯ ДО НИКОЛАЯ</a>\n",
      "<a href=\"http://1914ww.ru/\" rel=\"nofollow\">ПЕРВАЯ МИРОВАЯ</a>\n",
      "<a href=\"http://www.doc20vek.ru/\" rel=\"nofollow\">ДОКУМЕНТЫ XX ВЕКА</a>\n",
      "<a href=\"http://www.1812w.ru/\" rel=\"nofollow\">ВОЙНА 1812 ГОДА</a>\n",
      "<a class=\"cctags cctags-block vid-1 level-6 depth-0 count-1381 ccfilter tooltip\" href=\"http://1937god.info/taxonomy/term/1\" rel=\"tag\" title='Имеется множество описаний расстрелов. Наиболее раннее дано писателем Владимиром Зазубриным в книге \"Щепка. Повесть о революции и о личности. Сам писатель был в 1937 году расстрелян...\n",
      "\n",
      "&amp;nbsp;\n",
      "\n",
      "&amp;nbsp;\n",
      "\n",
      "&amp;nbsp;\n",
      "'>Расстрелян</a>\n",
      "<a class=\"cctags cctags-block vid-1 level-6 depth-0 count-476 ccfilter tooltip\" href=\"http://1937god.info/taxonomy/term/200\" rel=\"tag\" title='\"Обвинен в военном заговоре\" (военно-фашистком, антисоветском, создании террористической организации в вооруженных силах и пр.), - подобная формулировка попадается в биографиях многих военных, расстрелянных в 1937-1938 годах. А был ли заговор? - вопрошают многие читатели. Более или менее внятный ответ находим в книге Гровера Ферра \"Шестьдесят одна неправда Никиты Хрущёва\" (оригинальное название издания - \"Антисталинская подлость\"). Он разбирает вопрос: почему до сих пор нет ясности по заговору:\n",
      "\n",
      "\"Из тех немногих свидетельств, что стали известны после распада СССР, явствует, что Тухачевский и осужденные с ним командиры были действительно виновны в том, что им инкриминировалось. Однако пока рассекречено ничтожно малое число таких источников: власти, под чьим контролем находится доступ в такие ведомственные учреждения, как архив ФСБ и президентский архив, - где, собственно, и хранятся архивно-следственные материалы по \"делу военных\", а также открытых и закрытых процессов 1936-1938 годов, - не спешат предавать огласке хранящиеся там документы.\n",
      "&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Даже несмотря на отрицание какой-либо вины командующих со стороны официозной российской науки, сами первоисточники говорят об обратном. Например, в недавно опубликованном протоколе признательных показаний Ежова подтверждается существование трех самостоятельных, но соперничающих между собой групп военных заговорщиков: во-первых, \"крупных военных работников\" во главе с А.И.Егоровым, во-вторых, троцкистской группы Я.Б.Гамарника, И.Э.Якира и И.П.Уборевича и, наконец, \"офицерско-бонапартистской группы\" Тухачевского. (125)\n",
      "&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Характерный штрих: Хрущев настоял на реабилитации Тухачевского и большинства других командиров в 1957 году. Но более или менее подробное изучение материалов по \"делу военных\" началось не ранее чем в 1962 году. Отчет соответствующей комиссии, где в сущности опубликованы лишь дополнительные доказательства виновности военачальников, оставался засекреченным вплоть до 1994 года.\n",
      "&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;2. Начиная с хрущевских времен Тухачевскому и другим репрессированным военачальникам воздаются почести чуть не Героев Советского Союза. Эта тенденция, как ни удивительно, продолжает сохраняться и после \"демонтажа\" СССР в 1991 году...\"\n",
      "\n",
      "Цитируется по кн.: Гровер Ферр. Шестьдесят одна неправда Никиты Хрущёва. Глава 5. Сталин и война. # Расстрелянные полководцы.\n",
      "\n",
      "&amp;nbsp;\n",
      "'>Обвинялись в заговоре</a>\n",
      "<a class=\"cctags cctags-block vid-1 level-4 depth-0 count-149 ccfilter tooltip\" href=\"http://1937god.info/taxonomy/term/73\" rel=\"tag\" title=\"\">Умер в заключении</a>\n",
      "<a class=\"cctags cctags-block vid-1 level-4 depth-0 count-128 ccfilter tooltip\" href=\"http://1937god.info/taxonomy/term/3\" rel=\"tag\" title='Категорию \"выжил\" также необходимо расшифровать, так как люди, зачисленные в данную категорию, испытали на себе давление репрессивной машины не в меньшей степени, чем покончившие жизнь самоубийством или умершие в местах заключения. Выжившие пережили все те же мучения, но вот только выжили - в отличие от остальных. Не скрою, при составлении биографического справочника \"Репрессированное поколение\" порой приходилось ловить себя на мысли: \"Ничего себе репрессированный! Дожил до глубоких седин, а ведь немногие из избежавших преследования так долго протянули! (на воле-то!)\" Но эта реакция, хоть и объяснима эмоционально, несправедлива по своему существу. Судите сами. Вот возьмем для примера биографию Владимира Константинова. Человека арестовали, осудили, потому пересудили, затем все-таки посадили, он отсидел и в целом почти три десятилетия прожил еще после ареста. Казалось бы, благополучнейшая судьба. А теперь вчитаемся внимательнее: после ареста приговорен к высшей мере наказания (ВМН) - расстрелу... потом палачам вдруг понадобился опытный переводчик с японского языка, каким и был Константинов. Тогда ему заменили ВМН на 20 лет, чтобы иметь возможность его периодически привлекать - как бесплатную рабочую силу, как раба. Вдумайтесь: пережить приговор к ВМН - ждать прихода расстрельной команды кадую ночь... Некоторые от одного этого с ума не сходили. А Константинов выдержал. Далее - пересылки и лагеря. Вот Николай Вавилов в заключении просто&amp;nbsp; умер от голода (вроде бы власти тут и не при чем - сам виноват, почему за пайку с урками не дрался). Константинов выжил, сохранил свою жизнь. А это значит, что категория \"выжил\" - это раздел проекта об особой форме репрессий, особо изуверской. А то, что подвергнутые этой пытке люди до глубокой старости дожили - так это только их заслуга.\n",
      "'>Выжил</a>\n",
      "<a class=\"cctags cctags-block vid-1 level-4 depth-0 count-64 ccfilter tooltip\" href=\"http://1937god.info/taxonomy/term/374\" rel=\"tag\" title=\"Полигон возле поселка Коммунарка Московской области в 30-е годы использовался для массовых расстрелов и одновременно для захоронений расстрелянных. Участок земли на 24 километре Калужского шоссе с конца 20-х годов XX века находился &amp;nbsp;в ведении НКВД, здесь была устроена загородная дача наркома ОГПУ-НКВД Г.Г.Ягоды. Рядом с дачными угодьями из крестьянских хозяйств окрестных деревень был организован совхоз «Коммунарка». В марте 1938 г. нарком был расстрелян, дача некоторое время пустовала, а затем ее территория была превращена Центральным аппаратом Госбезопасности в расстрельный полигон. По мнению сотрудников ФСБ, здесь лежат от 10 до 14 тысяч расстрелянных, но пока известны имена около 4,5 тысячи человек. В отличие от всех подобных мест, которых немало в нашей стране, в «Коммунарке» покоятся руководство страны, военачальники высоких рангов, руководители крупных предприятий, дипломаты, разведчики, чекисты. Полигон «Коммунарка» и полигон в Бутове - два самых больших места захоронения останков жертв массовых политических репрессий 1937-1941 гг. в Москве.\n",
      "\">Коммунарка</a>\n",
      "<a class=\"cctags cctags-block vid-1 level-3 depth-0 count-44 ccfilter tooltip\" href=\"http://1937god.info/taxonomy/term/356\" rel=\"tag\" title=\"\">Необходимо уточнять</a>\n",
      "<a class=\"cctags cctags-block vid-1 level-3 depth-0 count-22 ccfilter tooltip\" href=\"http://1937god.info/taxonomy/term/89\" rel=\"tag\" title=\"САМОУБИЙСТВО (SUICIDE). Убийство себя. Некоторые люди считают самоубийство преступлением. Я, со своей стороны, считаю его правом каждого. «Подобно тому, как я не нарушаю законов, установленных против воров, когда уношу то, что мне принадлежит, или сам беру у себя кошелек, — пишет Монтень, — и не являюсь поджигателем, когда жгу свой лес, точно так же я не подлежу законам против убийц, когда лишаю себя жизни» («Опыты», II, 3). Вместе с тем не следует придавать самоубийству большего значения, чем оно того заслуживает. Самоубийство — не священный акт и не жертвоприношение. О самоубийстве нельзя сказать, что оно нравственно или безнравственно, как нельзя считать его свидетельством духовности или бездуховности человека. Положить конец собственной жизни не значит сделать выбор в пользу смерти (такого выбора у нас нет — все мы рано или поздно умрем); это значит выбрать время своей смерти. Самоубийство может быть уместным или неуместным, но придавать ему значение абсолюта, как это иногда делается, неправомерно. Самоубийца просто выигрывает время у неизбежности, забегает вперед небытия, если угодно, обгоняет судьбу. Он сокращает свой путь, и принятое им решение необратимо.\n",
      "\n",
      "Каждый человек имеет право на самоубийство, и это право тем ближе к абсолюту, чем успешнее оно смеется над всяким правом. «Лучший дар, который мы получили от природы... — продолжает Монтень, — это возможность сбежать» (там же). Так что самоубийство — это одновременно и минимальная, и максимальная степень свободы.\n",
      "\n",
      "Конт-Спонвиль Андре. Философский словарь / Пер. с фр. Е.В. Головиной. – М., 2012, с. 505-506.\n",
      "\n",
      "См. также Примечание к дефиниции.\n",
      "\">Покончил жизнь самоубийством</a>\n",
      "<a class=\"cctags cctags-block vid-1 level-3 depth-0 count-18 ccfilter tooltip\" href=\"http://1937god.info/taxonomy/term/1494\" rel=\"tag\" title=\"ГУЛАГ, Главное Управление исправительно-трудовых лагерей, трудовых поселений и мест заключения — подразделение НКВД СССР, МВД СССР, МЮ СССР, осуществлявшее руководство системой исправительно-трудовых лагерей (ИТЛ) в 1934-1960 гг. Всего за годы существования системы ГУЛАГа через него прошли 15— 18 млн. человек. Из них скончались в лагерях примерно 1,5 миллиона.\n",
      "\n",
      "Цитируется по изд.: Лев Гумилев. Энциклопедия. / Гл. ред. Е.Б. Садыков,&amp;nbsp; сост. Т.К. Шанбай, — М., 2013, с. 200.\n",
      "\n",
      "&amp;nbsp;\n",
      "\">ГУЛАГ</a>\n",
      "<a class=\"cctags cctags-block vid-1 level-2 depth-0 count-16 ccfilter tooltip\" href=\"http://1937god.info/taxonomy/term/427\" rel=\"tag\" title=\"Дубовка – одно из мест захоронений жертв Большого террора Воронежа и Воронежской области. Здесь захоранивали расстрелянных во внутренней тюрьме НКВД Воронежа (ул. Володарского, дом № 39). Места захоронений (86 га) примыкали к территории учебных лагерей полка НКВД в поселке Дубовка. Захоронение производилось в ямы, территория не была огорожена и не охранялась.\n",
      "\n",
      "Границы не выявлены, общее количество ям не установлено, численность захороненных здесь неизвестна. В начале 1950-х на этой территории посажен сосновый лес. В 1989 году место захоронений было обнаружено.\n",
      "\n",
      "По данным городского общества «Мемориал», всего в годы сталинских репрессий в Дубовке было расстреляно более 10.000 человек.\n",
      "\n",
      "«Дубовка» – урочище в пойме реки Усманка в пос. Дубовка, в 2,5 км от ж/д. станции Сомовская Юго-Восточной железной дороги, ныне микрорайон «Дубовка» (Сомово) в черте города Воронеж. В Дубовке расположена мемориальная зона захоронения жертв политических репрессий.\n",
      "\n",
      "По данным воронежского «Мемориала», на настоящий момент перезахоронено 1869 человек — 44 братские могилы разбросаны по лесу. Территория, которая называется мемориальной зоной — здесь захоронены погибшие в ходе политических репрессий 1930-х гг. — не огорожена.\n",
      "\n",
      "+ + +\n",
      "\n",
      "История с раскопками захоронений под Дубовкой началась с письма местного жителя В.П. Новикова в газету «Коммуна», которое опубликовал 7 июля 1989 г. журналист В.М. Котенко в статье «Какой лес хранит тайну?». Реакция администрации города, заинтересованных организаций (КГБ, МВД, Прокуратуры) и широкой общественности оказалась неожиданно быстрой и дружной. Начались серьезные поиски.\n",
      "\n",
      "Поначалу в Воронеже расстрелянных хоронили на Коминтерновском кладбище. Но в те страшные времена за одну ночь могли привести в исполнение приговор сразу для нескольких десятков человек. Нужно было копать большие ямы, а это привлекло бы внимание горожан. И в 1937 году было принято решение о том, чтобы приговоренных тайно вывозить в специально отведенные места за городом. Одним из таких мест стала часть поймы реки Усманки, которая примыкала к полигону НКВД в поселке Дубовка.\n",
      "\n",
      "Иногда заключенных привозили в «черных воронках» к ямам и там приводили приговор в исполнение. Иногда расстреливали в Воронеже, во внутренней тюрьме НКВД (она находилась на ул. Дзержинского, сейчас на ее месте построен элитный дом), а в Дубовку вывозили трупы. Специалисты, исследующие захоронения, говорят: если вместе с останками находят обувь, значит, человека привезли живым.\n",
      "\n",
      "Все это происходило ночами. Автомашины НКВД ездили с выключенными фарами. Местонахождение расстрельной зоны было засекречено. Все лица, имеющие отношение к расстрелам, давали подписку о неразглашении, за нарушение которой следовало строгое наказание. А в начале 1950-х территория была засажена сосновым лесом, под которым оказалось более сотни расстрельных ям с останками около 8000 человек.\n",
      "\n",
      "Мало известен тот факт, что к 1941 году в Воронежском управлении НКВД осталось только 30 % личного состава, а остальные сотрудники были либо уволены, либо сосланы в лагеря и расстреляны, где — доподлинно не известно.\n",
      "\n",
      "Материалы с сайта http://letopis.vrn.ru/\n",
      "\n",
      "&amp;nbsp;\n",
      "\">Дубровка</a>\n",
      "<a class=\"cctags cctags-block vid-1 level-2 depth-0 count-16 ccfilter tooltip\" href=\"http://1937god.info/taxonomy/term/452\" rel=\"tag\" title='Иногда в документах встречаются странные формулировки: некоторых репрессированных вообще не судили никаким судом, ни \"тройкой\", а \"пустили в расход\" по личному указанию влиятельного лица. Порой бессудная расправа скрывается под формулировкой \"расстрелян в особом порядке\". Расстреливали по личному указанию - как правило (или даже исключительно) по указанию Лаврентия Берии. Бывало так, что трибунал оправдывал или давал срок заключения, но Берия, опасаясь, что заключенные что-то кому-то расскажет, давал внесудебное указание - расстрелять.\n",
      "'>В особом порядке</a>\n",
      "<a class=\"cctags cctags-block vid-1 level-2 depth-0 count-11 ccfilter tooltip\" href=\"http://1937god.info/taxonomy/term/233\" rel=\"tag\" title=\"В Советской исторической энциклопедии об этом заведении сказано следующее:\n",
      "\n",
      "ОРЛОВСКИЙ ЦЕНТРАЛ - каторжная тюрьма в России, основан в 1908 году. До 20% узников составляли политзаключенные. Условия заключения отличались исключительной жестокостью, избиениями и пытками, порождали массовые заболевания, высокую смертность, самоубийства заключенных. Режим Орловского централа вызывал протесты передовой общественности России и за рубежом, был предметом освещения в печати, запросов в Государственной думе (1913). Существовал до падения самодержавия в 1917 года.\n",
      "\n",
      "Советская историческая энциклопедия. В 16 томах. — М.: Советская энциклопедия. 1973—1982. Том 10. НАХИМСОН - ПЕРГАМ. 1967.\n",
      "\n",
      "Как видим, он продолжил свое существование и даже весьма активное. Авторы энциклопедии явно поторопились его хоронить. К началу Великой Отечественной войны в Орловском централе содержался ряд известных лидеров революционного движения, являвшихся политическими противниками большевиков. Когда война началась, всех их расстреляли в Медведевском лесу под Орлом.\n",
      "\">Орловский централ</a>\n",
      "<a class=\"cctags cctags-block vid-1 level-2 depth-0 count-11 ccfilter tooltip\" href=\"http://1937god.info/taxonomy/term/1493\" rel=\"tag\" title=\"БЕЛОМОРСКО-БАЛТИЙСКИЙ КАНАЛ, соединяет Онежское озеро с Белым морем (Карелия). Длина 222&amp;nbsp;км, из них только 37&amp;nbsp;км – искусственный путь. В основном трасса проходит по естественным водоёмам. В составе канала реки Выг и Повечанка, озёра – Выгозеро, Водлозеро, Узкое, Маткозеро и другие. Входит в единую глубоководную систему Европейской части России. Состоит из 19&amp;nbsp;шлюзов, 15 плотин, 12 водоспусков, 49 дамб и других сооружений. Средняя длительность навигации 165 дней – с середины мая до конца октября. Построен в 1933&amp;nbsp;году, в рекордно короткие сроки, в основном заключёнными ГУЛАГа.\n",
      "\n",
      "Использованы материалы кн.: Современная иллюстрированная энциклопедия. География. Росмэн-Пресс, М., 2006.\n",
      "\n",
      "&amp;nbsp;\n",
      "\">Беломорско-Балтийский канал</a>\n",
      "<a class=\"cctags cctags-block vid-1 level-2 depth-0 count-10 ccfilter tooltip\" href=\"http://1937god.info/taxonomy/term/2\" rel=\"tag\" title=\"\">Убит по приказу</a>\n",
      "<a class=\"cctags cctags-block vid-1 level-2 depth-0 count-10 ccfilter tooltip\" href=\"http://1937god.info/taxonomy/term/1509\" rel=\"tag\" title=\"«Ленинградское дело» (дело русских национал-большевиков), процесс над русскими национал-большевиками в рядах коммунистической партии, организованный еврейскими большевиками в борьбе за власть над Русским Народом. Главной целью его было уничтожение «русской партии» в высших эшелонах власти СССР, а также разгром русских патриотов на местах.\n",
      "\n",
      "Фактически «ленинградское дело» было антирусским, антипатриотическим заговором еврейских большевиков под руководством Берии, Хрущева, Маленкова и Кагановича для того, чтобы изгнать русские кадры, привлеченные Сталиным в государственный аппарат после Великой Отечественной войны.\n",
      "\n",
      "После войны и вплоть до «ленинградского дела» формирование государственного аппарата шло на русской основе. Рядом со старой сплоченной, преимущественно космополитической руководящей элитой, возникла новая, составленная из молодых людей, хорошо проявивших себя в годы войны. Центром создания кадров нового руководства становятся Совмин Российской Федерации и Ленинградский обком и горком. Душой нового руководящего слоя был Н. А. Вознесенский, председатель Госплана СССР, заместитель председателя Совета Министров СССР, член Политбюро ЦК ВКП(б). Образуется сплоченная группа лиц, куда кроме Вознесенского входили член Оргбюро, секретарь ЦК А. А. Кузнецов, председатель Совета Министров РСФСР М. И. Родионов, кандидат в члены ЦК, первый секретарь Ленинградского обкома и горкома ВКП(б) П. С. Попков, второй секретарь Ленинградского горкома Я. Ф. Капустин, председатель Ленинградского горисполкома П. Г. Лазутин.\n",
      "\n",
      "С 1946 по авг. 1948 Ленинградская партийная организация подготовила для России около 800 чел. новых русских руководящих кадров. П. С. Попков стал членом Президиума Верховного Совета СССР, бывший секретарь ЛГК(б) и зампред Ленсовета М. В. Басов — первым заместителем председателя Совмина РСФСР. В ЦК и на «центральную работу» были выдвинуты ленинградцы Т. В. Закржевская, Н. Д. Шумилов, П. Н. Кубаткин. Первыми секретарями обкомов и ЦК республиканских компартий стали М. И. Турко, Н. В. Соловьев, Г. Т. Кедров, А. Д. Вербицкий.\n",
      "\n",
      "Во время войны наиболее приближенной к Сталину фигурой был Маленков, деливший свою близость к Сталину с А. С. Щербаковым. Второй ряд политиков высшего эшелона составляли Молотов, Берия, Вознесенский, Каганович. В третьем ряду стояли Андреев, Ворошилов, Жданов, Калинин, Микоян, Хрущев. Все они были членами Политбюро и только Маленков, Вознесенский и Берия — кандидатами в члены Политбюро. Как утверждал Молотов, Хрущев, Маленков и Берия во время войны были приятелями.\n",
      "\n",
      "Сразу же после войны расстановка сил в высших эшелонах власти изменяется в пользу русских. Хотя Берия, Маленков и Вознесенский становятся членами Политбюро, их роль, особенно Маленкова и Берии, падает. Самым близким к Сталину лицом является Жданов, занявший второй место в государстве. Маленкова отправляют работать в Среднюю Азию (и он опасается ареста). Берию отстраняют от курирования органов безопасности и сосредоточивают только на деятельности Комиссии по атомной энергии. На должность министра МГБ вместо ставленника Берии Меркулова по рекомендации Жданова назначается Абакумов, бывший руководитель военной разведки СМЕРШ и находившийся с Берией в конфликтных отношениях. Хрущева понижают в его положении, пересадив с места первого секретаря ЦК Украины на менее значительную должность — председателя Совета Министров этой республики.\n",
      "\n",
      "В Совете Министров СССР Жданов делает ставку на Вознесенского, а в ЦК — на секретаря ЦК А. А. Кузнецова, ответственного за подбор и расстановку руководящих кадров. Вплоть до смерти Жданова в 1948 такая расстановка сил имела стабильный характер.\n",
      "\n",
      "Как в средние века национально-освободительная борьбы шла под видом религиозных войн, так и в высших эшелонах власти послевоенной России национально-патриотическое движение Русского Народа осуществлялось чаще всего под видом борьбы за чистоту партийных рядов, за правильный классовый подход. Выдвигая на передний план привычную марксистско-ленинскую фразеологию, оппоненты на самом деле преследовали свои скрытые цели. Как и до войны продолжалась жестокая схватка двух непримиримых сил — русской национально-патриотической и антирусской космополитической. Ни та, ни другая не смели обозначить свои цели открыто.\n",
      "\n",
      "Имеющиеся в нашем распоряжении материалы позволяют представить реальную расстановку национально-русских и космополитических сил в высших эшелонах власти.\n",
      "\n",
      "Условно говоря, к «русской партии» в высшем руководстве принадлежали следующие лица: сам Сталин, кандидат в члены Политбюро А. С. Щербаков (умер в 1945), член Политбюро А. А. Жданов, а также выдвинутые Ждановым председатель Госплана Н. А. Вознесенский, секретарь ЦК А. А. Кузнецов и руководители ленинградской партийной организации.\n",
      "\n",
      "Им противостояла группа влиятельнейших руководителей — члены и кандидаты в члены Политбюро Маленков, Берия, Каганович, Микоян, а также ряд колеблющихся членов Политбюро, женатых на еврейках: Молотов, Андреев, Ворошилов.\n",
      "\n",
      "В к. 40-х вплоть до смерти Жданова шансы «русской партии» на политическое руководство страной были очень велики. По многим свидетельствам, Сталин, думая о преемниках, хотел видеть на посту Генерального секретаря ЦК сначала Жданова, а после его смерти Кузнецова и на месте председателя Совета Министров СССР — Вознесенского. Сталин все реже появлялся на заседаниях Совета Министров, как правило, назначая председательствовать вместо себя Вознесенского. Конечно, такое предпочтение вызывало у космополитической части руководства чувство тревоги и ненависти к «русской партии».\n",
      "\n",
      "Смерть Жданова в 1948 резко изменила расстановку сил в высшем эшелоне власти. Фаворитом Сталина, как во время войны, вновь становится Маленков. Вместо отстраненного по ложному доносу Кузнецова ключевой пост секретаря ЦК по подбору и расстановке кадров получает Хрущев. К альянсу Маленков—Хрущев присоединяется и Берия. Объединившись, они становятся самой влиятельной в государственном аппарате силой.\n",
      "\n",
      "Как позднее вспоминал Каганович, за 2-3 года перед смертью Сталина сложился прочный политический союз Хрущева, Берии и Маленкова. Особенно тесная дружба существовала между Берией и Хрущевым.\n",
      "\n",
      "К к. 40-х Сталин начал сдавать, часто находился в нервном взвинченном состоянии и, что важнее всего, стал очень подозрителен. Как утверждал Молотов, «впадал в крайности некоторые». Это состояние Сталина было использовано космополитической группировкой в борьбе против «русской партии».\n",
      "\n",
      "Жданов умер 31 авг. 1948. Еще накануне он чувствовал себя хорошо. Есть данные, что он умер не своей смертью, возможно, отравлен какими-то ядами созданной Берией бактериологической лаборатории. Кроме уже известных нам показаний Тимашук о неправильном лечении, существуют показания прислуги валдайской дачи Жданова, которая незадолго до его смерти пришла к работнику местного исполкома и сказала, что секретаря ЦК «сознательно морят», просила принять меры. Человек этот позвонил в Москву, потом испугался и в ту же ночь, все бросив, уехал, спасая свою жизнь.\n",
      "\n",
      "Смерть Жданова нарушила хрупкий баланс в расстановке сил. Антирусская группировка в руководстве страной получила преимущество. Лица, входившие в нее, были опытны в аппаратной борьбе, лучше знали поведение и настроение Сталина, а значит и могли им в известном смысле управлять. Берия, Хрущев и Маленков пытаются представить Сталину, что «русские» в составе руководства подготавливают его отстранение от власти. В качестве доказательств Сталину сообщают факты о самостоятельной экономической политике, проводимой российскими организациями (в частности, устройство без уведомления Сталина в янв. 1948 Всероссийской торговой оптовой ярмарки), об искажении итогов выборов в к. дек. 1948 в Ленинградской объединенной партийной организации, фальсификации государственной отчетности, а также о намерениях некоторых руководителей РСФСР создать компартию России (намерения эти не шли дальше разговоров).\n",
      "\n",
      "На этой основе возникает т. н. «ленинградское дело», которое правильнее было бы назвать «русским делом», ибо посредством него была разгромлена большая часть русских кадров, пришедших после войны на замену старым еврейско-космополитическим функционерам. Многие документы «ленинградского дела» были впоследствии уничтожены Г. М. Маленковым. Поэтому о деталях его приходится судить по косвенным свидетельствам. По всей видимости, дело началось с доноса, подписанного Маленковым и Хрущевым. В 1957, во время заседания июньского пленума ЦК КПСС, Маленков изъял из «ленинградского дела» целый ряд материалов, заявив, что уничтожил их как личные документы. И то, что ему позволили это сделать, говорит о том, что в уничтожении их был заинтересован и Н. С. Хрущев.\n",
      "\n",
      "На основании указанного доноса в февр. 1949 Политбюро принимает Постановление «Об антипартийных действиях членов ЦК ВКП(б) тт. Родионова М. И. и Попкова П. С.», в котором говорилось, что «их противогосударственные действия явились следствием нездорового, небольшевистского уклона, выражающегося в демагогическом заигрывании с Ленинградской организацией, охаивании ЦК ВКП(б), в попытках представить себя в качестве особых защитников Ленинграда, в попытках создать средостение между ЦК ВКП(б) и Ленинградской организацией и отдалить таким образом Ленинградскую организацию от ЦК ВКП(б)».\n",
      "\n",
      "Решением Политбюро А. А. Кузнецов, М. И. Родионов и П. С. Попков снимаются со всех постов. Для разборки их дела создается комиссия в составе Маленкова, Хрущева и Шкирятова (человека Берии). Допросы обвиняемых вели не следователи МГБ, а члены партийной комиссии.\n",
      "\n",
      "Имея целью уничтожить все русские кадры в высшем руководстве, члены партийной комиссии уже на первом этапе «привязывают» к этому делу председателя Госплана СССР Вознесенского.\n",
      "\n",
      "Как вспоминает Н. К. Байбаков, в качестве компромата против Вознесенского была использована докладная записка председателя Госснаба СССР М. Т. Помазнева о занижении Госпланом СССР, который в то время возглавлял Вознесенский, плана промышленного производства на 1-й квартал 1949. С этого начинается организованная травля Вознесенского.\n",
      "\n",
      "Назначенный в Госплан на должность уполномоченного ЦК ВКП(б) по кадрам Е. Е. Андреев летом 1949 представил записку об утере Госпланом за период 1944—49 ряда секретных документов. В записке на имя Сталина, составленной Берией, Маленковым и Булганиным, было сказано: «Товарищ Сталин, по Вашему указанию Вознесенского допросили и считаем, что он виновен».\n",
      "\n",
      "9 сент. председатель Комитета партийного контроля, член комиссии по «ленинградскому делу» представляет Политбюро решение КПК: «Предлагаем исключить Н. А. Вознесенского из членов ЦК ВКП(б) и привлечь его к судебной ответственности».\n",
      "\n",
      "Сначала Сталин был против ареста Вознесенского и Кузнецова, но Маленков и Берия сумели представить дело так, что арест необходим.\n",
      "\n",
      "В 1949 проходят массовые аресты руководящих русских кадров в центре и на местах, в т. ч. секретарей обкомов и председателей исполкомов. В Ленинграде, Москве, Крыму, Рязани, Ярославле, Мурманске, Горьком, Таллине, Пскове, Новгороде, Петрозаводске и в др. городах по приказу Маленкова арестовываются люди, преимущественно выдвиженцы Жданова, бывшие в 40-е гг. в руководящем звене Ленинграда, их жены, родственники, друзья или просто сослуживцы. Только в Ленинградской обл. арестовываются св. 2 тыс. чел.\n",
      "\n",
      "Одним из первых был арестован (а впоследствии убит) первый секретарь Крымского обкома партии Н. В. Соловьев, энергично выступавший против создания на территории Крыма еврейской республики. Арестовывается и подвергается пыткам первый секретарь Ярославского обкома М. И. Турко.\n",
      "\n",
      "Как впоследствии отмечалось в выводах специальной комиссии, изучившей это дело: «С целью получения вымышленных показаний о существовании в Ленинграде антипартийной группы Г. М. Маленков лично руководил ходом следствия по делу и принимал в допросах непосредственное участие. Ко всем арестованным применялись незаконные методы следствия, мучительные пытки, побои и истязания. Для создания видимости о существовании в Ленинграде антипартийной группировки по указанию Г. М. Маленкова были произведены массовые аресты… Более года арестованных готовили к суду, подвергали грубым издевательствам, зверским истязаниям, угрожали расправиться с семьями, помещали в карцер и т. д. Психологическая обработка усилилась накануне и в ходе самого судебного разбирательства. Подсудимых заставляли учить наизусть протоколы допросов и не отклоняться от заранее составленного сценария судебного фарса».\n",
      "\n",
      "Антирусская группировка Маленкова—Хрущева—Берии превратила следствие по «ленинградскому делу» в сплошную череду пыток и издевательств над русскими кадрами.\n",
      "\n",
      "Сразу же после заседания военной коллегии 30 сент. 1950 по показаниям свидетелей «были не расстреляны, а зверски убиты Н. А. Вознесенский, А. А. Кузнецов, П. С. Попков, М. И. Родионов, Я. Ф. Капустин и П. Г. Лазутин.»\n",
      "\n",
      "Чуть позже были убиты многие другие лица, проходившие по «ленинградскому делу»: Г. Ф. Бадаев, И. С. Харитонов, П. Н. Кубаткин, М. В. Басов, А. Д. Вербицкий, Н. В. Соловьев, А. И. Бурлин, В. И. Иванов, М. Н. Никитин, М. И. Сафонов, П. А. Чурсин, А. Т. Бондаренко. Всего расстреляли около 200 чел., а несколько тыс. приговорили к длительным срокам заключения, а еще тысячи были отстранены от активной деятельности и назначены на низкие должности (среди последних, в частности, пострадал талантливый русский руководитель А. Н. Косыгин, сосланный на работу в текстильную промышленность).\n",
      "\n",
      "Развязав руки антирусской группе Маленкова—Берии—Хрущева, позволив ей расправиться с ведущими русскими кадрами в руководстве страной, Сталин по сути дела подписал себе смертный приговор, ибо потерял опору для проведения твердой и последовательной национальной русской политики. Являясь главой Русского государства, он обрекал себя на неизбежное одиночество и гибель. Самые способные и энергичные, проверенные войной русские руководители были истреблены; требовались годы, чтобы воссоздать их. Но на это Сталин уже не имел времени.\n",
      "\n",
      "Олег Платонов\n",
      "\n",
      "Использованы материалы сайта Большая энциклопедия русского народа\n",
      "\n",
      "&amp;nbsp;\n",
      "\">Ленинградское дело</a>\n",
      "<a class=\"cctags cctags-block vid-1 level-2 depth-0 count-9 ccfilter tooltip\" href=\"http://1937god.info/taxonomy/term/363\" rel=\"tag\" title=\"Бутовский полигон – крупнейшее в Московском регионе место массовых расстрелов и захоронений жертв сталинских репрессий. Сегодня известны имена 20760 человек здесь убиенных. Эти люди были расстреляны в течении очень короткого периода времени, с августа 1937г. по октябрь 1938, а полигон функционировал с 34 по 53 год…\n",
      "\n",
      "&amp;nbsp; Те, о ком мы знаем – мужчины и женщины в возрасте от 14 до 82 лет, представители 73 национальностей, всех вероисповеданий, всех сословий, но большинство из них, простые рабочие и крестьяне – русские православные люди.\n",
      "\n",
      "&amp;nbsp; Около 1000 человек, из числа погребенных в Бутово, пострадали как исповедники Православной Веры, более трехсот, сегодня прославлены в лике святых...\n",
      "\n",
      "Справочная статья с сайта http://www.martyr.ru/\n",
      "\n",
      "&amp;nbsp;\n",
      "\">Бутово</a>\n",
      "<a class=\"cctags cctags-block vid-1 level-2 depth-0 count-6 ccfilter tooltip\" href=\"http://1937god.info/taxonomy/term/1492\" rel=\"tag\" title=\"КАРАГАНДИНСКИЙ ИСПРАВИТЕЛЬНО-ТРУДОВОЙ ЛАГЕРЬ (КАРЛАГ) — &amp;nbsp;один из крупнейших исправительно-трудовых лагерей ГУЛАГа, располагавшийся на территории Карагандинской области Казахстана (1930-1959). 13 сентября 1950 года состоялось Особое судебное совещание, на котором Гумилёв был осужден по ст. 58 п. 8,10,11 УК сроком на 10 лет. 23 ноября он прибыл в 3-е отделение Карлага — лагерь Песчаный под Карагандой. 13 декабря переведен в 10-е лаготделение Карлага. Вдова ученого Наталия Викторовна Гумилева, к которой обратился в девяностые годы карагандинский краевед Юрий Попов, выписала строки из дневника Льва Николаевича о времени, проведенном в Карлаге: «...Караганда. Холод, голод, бандеровцы, власовцы, тяжелая работа. К счастью, устроился топографом, потом истопником, потом переписывал чего-то... Друг — перс Рахим, бежавший от шаха. Учу персидский язык. Читаю в бараке лекции по истории...». В заключение Наталия Викторовна отметила, что в свободные часы и минуты Гумилёв отрабатывал свою пассионарную теорию, которую в 1974 году защитил как вторую докторскую. «К сожалению, других подробностей я не знаю. Лев Николаевич старался не вспоминать плохое, рассказывал что-либо забавное...» (из статьи В. Рыжкова «Лев Гумилев: время Карлага» / в газ. Индустриальная Караганда. 2006.-25 апр. С. 10).\n",
      "\n",
      "Здесь цитируется по изд.: Лев Гумилев. Энциклопедия. / Гл. ред. Е.Б. Садыков,&amp;nbsp; сост. Т.К. Шанбай, — М., 2013, с. 305-306.\n",
      "\">КАРЛАГ</a>\n",
      "<a class=\"cctags cctags-block vid-1 level-1 depth-0 count-3 ccfilter tooltip\" href=\"http://1937god.info/taxonomy/term/762\" rel=\"tag\" title=\"\">Не реабилитирован</a>\n",
      "<a class=\"cctags cctags-block vid-1 level-1 depth-0 count-2 ccfilter tooltip\" href=\"http://1937god.info/taxonomy/term/278\" rel=\"tag\" title=\"\">Убит в стычке</a>\n",
      "<a class=\"cctags cctags-block vid-1 level-1 depth-0 count-2 ccfilter tooltip\" href=\"http://1937god.info/taxonomy/term/748\" rel=\"tag\" title=\"\n",
      "\n",
      "Так выглядел Соловецкий монастырь.\n",
      "\n",
      "Первое в СССР «исправительно-трудовое» учреждение – Соловецкий лагерь особого назначения (СЛОН) ОГПУ был образован в 1923 году. На протяжении многих лет соловецкие лагеря были самыми крупными в «стране Советов» и играли роль «полигона», на котором отрабатывались методы каторжного содержания и способы использования принудительного труда больших масс заключенных.\n",
      "\n",
      "Концлагерь губернского подчинения был учрежден 26 мая 1920 г. по решению Архангельского губисполкома. Большинство заключенных составляли осужденные за уголовные преступления и «контрреволюцию», свыше трети узников – бывшие белые солдаты, офицеры и военные чиновники. Они направлялись на Соловки из тюрем и других концлагерей Архангельской губернии либо были привезены с юга России. Общая численность узников колебалась от 150–200 в 1920 г. до 239 в феврале 1921 г.\n",
      "\n",
      "Губернский концлагерь просуществовал менее года. В мае 1921 г. на трех пароходах, отремонтированных силами самих лагерных сидельцев, заключенные были вывезены в Холмогорский лагерь принудительных работ Архангельской губЧК.\n",
      "\n",
      "Однако уже в мае 1923 г. Лубянка выступила с инициативой организовать собственный «Соловецкий лагерь принудительных работ особого назначения». В июне 1923 г. ВЦИК принял решение о создании Северных лагерей ГПУ специально для содержания под стражей «политических и уголовных преступников, отбывающих наказание по внесудебным приговорам ГПУ». В «Положении о Соловецких лагерях принудительных работ» (март 1924 г.) указывалось, что эти лагеря предназначены «для изоляции особо вредных государственных преступников, как уголовных, так и политических, кои принесли или могут принести существенный ущерб спокойствию и целости СССР».\n",
      "\n",
      "«Заселение» Соловецких лагерей началось уже летом 1923 г. Первые 100 узников были доставлены из Архангельска. Через месяц привезли еще 150 социалистов и анархистов. К сентябрю число лагерников уже превышало 3 тыс. человек – 2714 мужчин и 335 женщин, из них более 300 «политических», 2550 «контрреволюционеров» («каэров») и уголовников и 200 бывших чекистов.\n",
      "\n",
      "В последующие годы количество заключенных СЛОНа неуклонно росло. Постепенно отдельные лагеря, отделения, «командировки» и другие объекты СЛОНа заняли все острова Соловецкого архипелага, Конд-остров, а с конца 1920-х гг. – и ряд пунктов на материке. В 1931 г. в состав СЛОНа входило 8 лагерных отделений, 6 из которых находились на материке, включая отдаленный Мурманск.\n",
      "\n",
      "К началу 1929 г. в местах заключения, подведомственных НКВД, содержалось 76,5 тыс. арестантов, или вдвое больше, чем они могли физически вместить. И хотя проблема «перенаселенности» мест заключения в «государстве рабочих и крестьян» остро встала почти с момента его появления, во второе десятилетие своего существования оно вступило с тюрьмами, переполненными сверх всякой меры. К тому же переход к политике «раскулачивания» обещал новое увеличение притока арестантов. Между тем содержание одного тюремного сидельца обходилось казне в среднем в 250 руб. в год (на Соловках – в 211 руб.), и государственный бюджет с трудом выдерживал такие нагрузки.\n",
      "\n",
      "Фрагмент описания Соловецкого лагеря перепечатывается с сайта Александра Н. Яковлева.\n",
      "\">Соловки</a>\n",
      "<a class=\"cctags cctags-block vid-1 level-1 depth-0 count-2 ccfilter tooltip\" href=\"http://1937god.info/taxonomy/term/555\" rel=\"tag\" title=\"\">Преследование прекращено</a>\n",
      "<a class=\"cctags cctags-block vid-1 level-1 depth-0 count-2 ccfilter tooltip\" href=\"http://1937god.info/taxonomy/term/505\" rel=\"tag\" title=\"Еврейский антифашистский комитет (ЕАК) - организация советских  евреев, впервые заявившая о себе на митинге в Москве 24 августа 1941 г. (митинг транслировался по радио). Уже к весне 1942 года ЕАК оформилась как весьма влиятельная организация. Ответственный секретарь ЕАК Ш. Эпштейн (умер в 1945 году), сменивший его на этом посту И.С. Фефер, заместитель ответственного секретаря и член Президиума ЕАК Г.М.Хейфец, другие члены Президиума И.С. Юзефович, С.М. Михоэлс, - по документальным данным, установленным Г.В. Костырченко, а также по данным П.А. Судоплатова, - все эти (и другие) активисты ЕАК одновременно были агентами НКВД, проводили в ЕАК согласованную с государственной линию.\n",
      "\n",
      "ЕАК информировала руководство страны о процессах, происходивших вокруг образования государства Израиль. На основании этой информации СССР (скрытно, через Чехословакию) оказывал поддержку Израилю в войне против арабов (в частности поставлял ему вооружение). Вскоре после образования государства Израиль выяснилась ошибочность всех основных прогнозов. В результате выборов 25 января 1949 года к власти в Израиле пришло правительство, занявшее во внешней политики однозначно проамериканскую (а не просоветскую, как ожидалось) позицию. Названные выше лидеры ЕАК были репрессированы, сам ЕАК распущен. Под влиянием этого события в руководстве страны произошли существенные перестановки на самом верхнем уровне (Молотов, Булганин, Микоян сняты с занимаемых высоких постов).\n",
      "\n",
      "Наряду с ЕАК в СССР в годы  второй мировой войны были созданы аналогичные комитеты: Всеславянский, Советских ученых, Женщин и др. После войны все они были либо распущены, либо существенно преобразованы в организации иной направленности. В 1946 году ставился вопрос о ликвидации ЕАК, но предложение было отклонено. Роспуск ЕАК произошел лишь в конце 1948 года после провала советской политики в отношении Израиля.\n",
      "\n",
      "Читайте работу Павлова В.А. Еврейский антифашистский комитет во внутренней и внешней политике Советского государства и его роль в Великой Отечественной войне.\n",
      "\n",
      "См. также подборку документов по теме ЕАК.\n",
      "\n",
      "&amp;nbsp;\n",
      "\">По делу ЕАК</a>\n",
      "<a class=\"cctags cctags-block vid-1 level-1 depth-0 count-1 ccfilter tooltip\" href=\"http://1937god.info/taxonomy/term/223\" rel=\"tag\" title=\"\">Осужден «в особом порядке»</a>\n",
      "<a href=\"http://top.mail.ru/jump?from=242527\"><img alt=\"Рейтинг@Mail.ru\" height=\"1\" src=\"./Алфавитный указатель _ 1937-й и другие годы_files/counter\" style=\"border:0;\" width=\"1\"/></a>\n",
      "<a href=\"http://top.mail.ru/jump?from=242527\"><img src=\"http://d3.cb.b3.a0.top.mail.ru/counter?js=na;id=242527\"/>\n",
      "style=\"border:0;\" height=\"1\" width=\"1\" alt=\"Рейтинг@Mail.ru\" /&gt;</a>\n",
      "<a href=\"http://top.mail.ru/jump?from=242527\"><img alt=\"Рейтинг@Mail.ru\" height=\"18\" src=\"./Алфавитный указатель _ 1937-й и другие годы_files/counter(1)\" style=\"border:0;\" width=\"88\"/></a>\n",
      "<a id=\"main-content\"></a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/9\">Абакумов Виктор Семенович + 19.12.1954</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/4\">Абих Рудольф Петрович + 01.11.1940</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/11\">Аболтин Владимир Яковлевич</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/8\">Абрамов Александр Лазаревич + 25.11.1937</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/8\">Абрамов Александр Лазаревич + 25.11.1937</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/7\">Абрамов Василий Семенович + 05.11.1937</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/1411\">Абрамян Хорен Арутюнович + 29.01.1938</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/6\">Абугов Ошер Осипович + 29.8.1938</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/5\">Авербах Леопольд Леонидович + 14.08.1939</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/5\">Авербах Леопольд Леонидович + 14.08.1939</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/10\">Аверин Василий Павлович + 11.09.1938</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/450\">Авиновицкий Яков Лазаревич + 08.01.1938</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/18\">Агабеков Георгий Сергеевич + 1938</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/1433\">Агапов Владимир Владимирович + 14.10.1937</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/16\">Агас Вениамин Соломонович + 22.02.1939</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/987\">Агеев Павел Михайлович + 1939</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/1142\">Агладзе Леонид Михайлович</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/985\">Агранов Яков Саулович + 01.08.1938</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/985\">Агранов Яков Саулович + 01.08.1938</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/1412\">Адаменко Роман Романович + 25.09.1938</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/988\">Айтаков Надырбай + 1938</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/988\">Айтаков Надырбай + 1938</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/268\">Айхенвальд Александр Юльевич + 11.09.1941</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/989\">Акаев Сарыкбай Джумагалиевич + 11.1937</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/990\">Аксельрод Моисей Моисеевич + 20.02.1939</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/1042\">Аксенов Алексей Михайлович + 23.08.1938</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/1482\">Аксенов Леонид Дмитриевич + 1937</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/991\">Акулов Иван Алексеевич + 30.10.1937</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/991\">Акулов Иван Алексеевич + 30.10.1937</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/1521\">Алабовский Михаил Петрович + 21.12.1937</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/317\">Алафузо Михаил Иванович + 13.07.1937</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/992\">Алгасов Владимир Александрович + 03.10.1938</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/992\">Алгасов Владимир Александрович + 03.10.1938</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/1413\">Александров Александр Соломонович + 26.10.1937</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/221\">Александров Александр Фомич + 1937</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/28\">Александровский Михаил Константинович + 15.11.1937</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/28\">Александровский Михаил Константинович + 15.11.1937</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/81\">Алексеев Глеб Васильевич + 1938</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/1074\">Алексеев Иван Иванович</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/222\">Алексеев Николай Кузьмич</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/224\">Алексеев Николай Николаевич + 09.12.1937</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/1044\">Алексеев Павел Александрович + 23.02.1942</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/595\">Алексеев Трофим Васильевич + 11.03.1938</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/225\">Алексеевский Владимир Александрович + 17.06.1937</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/993\">Алехин Михаил Сергеевич + 22.02.1939</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/1414\">Алиев Джабир Амирулла оглы + 01.09.1938</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/994\">Алкин Ильяс Саид-Гиреевич + 09.05.1938</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/994\">Алкин Ильяс Саид-Гиреевич + 09.05.1938</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/40\">Алкснис Яков Иванович + 28.07.1938</a>\n",
      "<a href=\"http://1937god.info/taxonomy/term/40\">Алкснис Яков Иванович + 28.07.1938</a>\n",
      "<a href=\"http://1937god.info/persons?page=1\" title=\"На страницу номер 2\">2</a>\n",
      "<a href=\"http://1937god.info/persons?page=2\" title=\"На страницу номер 3\">3</a>\n",
      "<a href=\"http://1937god.info/persons?page=3\" title=\"На страницу номер 4\">4</a>\n",
      "<a href=\"http://1937god.info/persons?page=4\" title=\"На страницу номер 5\">5</a>\n",
      "<a href=\"http://1937god.info/persons?page=5\" title=\"На страницу номер 6\">6</a>\n",
      "<a href=\"http://1937god.info/persons?page=6\" title=\"На страницу номер 7\">7</a>\n",
      "<a href=\"http://1937god.info/persons?page=7\" title=\"На страницу номер 8\">8</a>\n",
      "<a href=\"http://1937god.info/persons?page=8\" title=\"На страницу номер 9\">9</a>\n",
      "<a href=\"http://1937god.info/persons?page=1\" title=\"На следующую страницу\">следующая ›</a>\n",
      "<a href=\"http://1937god.info/persons?page=35\" title=\"На последнюю страницу\">последняя »</a>\n",
      "<a href=\"https://www.drupal.org/\">Drupal</a>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def main ():\n",
    "    html = open('C:\\\\Users\\\\User\\\\jupyterprojects\\\\1937_alphabit.html', encoding='utf-8').read()\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "    div = soup.find_all('a')\n",
    "    \n",
    "    for a in div:\n",
    "        print(a)\n",
    "    #find.all\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://1937god.info/persons#main-content\n",
      "http://1937god.info/\n",
      "http://1937god.info/\n",
      "http://1937god.info/\n",
      "http://1937god.info/persons/%D0%B0\n",
      "http://1937god.info/persons/%D0%B1\n",
      "http://1937god.info/persons/%D0%B2\n",
      "http://1937god.info/persons/%D0%B3\n",
      "http://1937god.info/persons/%D0%B4\n",
      "http://1937god.info/persons/%D0%B5\n",
      "http://1937god.info/persons/%D0%B6\n",
      "http://1937god.info/persons/%D0%B7\n",
      "http://1937god.info/persons/%D0%B8\n",
      "http://1937god.info/persons/%D0%BA\n",
      "http://1937god.info/persons/%D0%BB\n",
      "http://1937god.info/persons/%D0%BC\n",
      "http://1937god.info/persons/%D0%BD\n",
      "http://1937god.info/persons/%D0%BE\n",
      "http://1937god.info/persons/%D0%BF\n",
      "http://1937god.info/persons/%D1%80\n",
      "http://1937god.info/persons/%D1%81\n",
      "http://1937god.info/persons/%D1%82\n",
      "http://1937god.info/persons/%D1%83\n",
      "http://1937god.info/persons/%D1%84\n",
      "http://1937god.info/persons/%D1%85\n",
      "http://1937god.info/persons/%D1%86\n",
      "http://1937god.info/persons/%D1%87\n",
      "http://1937god.info/persons/%D1%88\n",
      "http://1937god.info/persons/%D1%89\n",
      "http://1937god.info/persons/%D1%8D\n",
      "http://1937god.info/persons/%D1%8E\n",
      "http://1937god.info/persons/%D1%8F\n",
      "http://1937god.info/\n",
      "http://1937god.info/cctags/page/1\n",
      "http://1937god.info/other\n",
      "http://1937god.info/taxonomy/term/271\n",
      "http://1937god.info/taxonomy/term/130\n",
      "http://1937god.info/taxonomy/term/582\n",
      "http://1937god.info/taxonomy/term/144\n",
      "http://1937god.info/taxonomy/term/986\n",
      "http://1937god.info/taxonomy/term/580\n",
      "http://1937god.info/taxonomy/term/126\n",
      "http://1937god.info/taxonomy/term/210\n",
      "http://1937god.info/taxonomy/term/215\n",
      "http://1937god.info/taxonomy/term/131\n",
      "http://1937god.info/taxonomy/term/127\n",
      "http://1937god.info/taxonomy/term/1481\n",
      "http://1937god.info/taxonomy/term/750\n",
      "http://1937god.info/taxonomy/term/129\n",
      "http://1937god.info/taxonomy/term/234\n",
      "http://1937god.info/taxonomy/term/146\n",
      "http://1937god.info/taxonomy/term/246\n",
      "http://1937god.info/taxonomy/term/265\n",
      "http://1937god.info/taxonomy/term/128\n",
      "http://www.hrono.ru/\n",
      "http://www.hrono.info/forum/\n",
      "http://www.pravitelimira.ru/portal/\n",
      "http://nik2nik.ru/\n",
      "http://1914ww.ru/\n",
      "http://www.doc20vek.ru/\n",
      "http://www.1812w.ru/\n",
      "http://1937god.info/taxonomy/term/1\n",
      "http://1937god.info/taxonomy/term/200\n",
      "http://1937god.info/taxonomy/term/73\n",
      "http://1937god.info/taxonomy/term/3\n",
      "http://1937god.info/taxonomy/term/374\n",
      "http://1937god.info/taxonomy/term/356\n",
      "http://1937god.info/taxonomy/term/89\n",
      "http://1937god.info/taxonomy/term/1494\n",
      "http://1937god.info/taxonomy/term/427\n",
      "http://1937god.info/taxonomy/term/452\n",
      "http://1937god.info/taxonomy/term/233\n",
      "http://1937god.info/taxonomy/term/1493\n",
      "http://1937god.info/taxonomy/term/2\n",
      "http://1937god.info/taxonomy/term/1509\n",
      "http://1937god.info/taxonomy/term/363\n",
      "http://1937god.info/taxonomy/term/1492\n",
      "http://1937god.info/taxonomy/term/762\n",
      "http://1937god.info/taxonomy/term/278\n",
      "http://1937god.info/taxonomy/term/748\n",
      "http://1937god.info/taxonomy/term/555\n",
      "http://1937god.info/taxonomy/term/505\n",
      "http://1937god.info/taxonomy/term/223\n",
      "http://top.mail.ru/jump?from=242527\n",
      "http://top.mail.ru/jump?from=242527\n",
      "http://top.mail.ru/jump?from=242527\n",
      "None\n",
      "http://1937god.info/taxonomy/term/9\n",
      "http://1937god.info/taxonomy/term/4\n",
      "http://1937god.info/taxonomy/term/11\n",
      "http://1937god.info/taxonomy/term/8\n",
      "http://1937god.info/taxonomy/term/8\n",
      "http://1937god.info/taxonomy/term/7\n",
      "http://1937god.info/taxonomy/term/1411\n",
      "http://1937god.info/taxonomy/term/6\n",
      "http://1937god.info/taxonomy/term/5\n",
      "http://1937god.info/taxonomy/term/5\n",
      "http://1937god.info/taxonomy/term/10\n",
      "http://1937god.info/taxonomy/term/450\n",
      "http://1937god.info/taxonomy/term/18\n",
      "http://1937god.info/taxonomy/term/1433\n",
      "http://1937god.info/taxonomy/term/16\n",
      "http://1937god.info/taxonomy/term/987\n",
      "http://1937god.info/taxonomy/term/1142\n",
      "http://1937god.info/taxonomy/term/985\n",
      "http://1937god.info/taxonomy/term/985\n",
      "http://1937god.info/taxonomy/term/1412\n",
      "http://1937god.info/taxonomy/term/988\n",
      "http://1937god.info/taxonomy/term/988\n",
      "http://1937god.info/taxonomy/term/268\n",
      "http://1937god.info/taxonomy/term/989\n",
      "http://1937god.info/taxonomy/term/990\n",
      "http://1937god.info/taxonomy/term/1042\n",
      "http://1937god.info/taxonomy/term/1482\n",
      "http://1937god.info/taxonomy/term/991\n",
      "http://1937god.info/taxonomy/term/991\n",
      "http://1937god.info/taxonomy/term/1521\n",
      "http://1937god.info/taxonomy/term/317\n",
      "http://1937god.info/taxonomy/term/992\n",
      "http://1937god.info/taxonomy/term/992\n",
      "http://1937god.info/taxonomy/term/1413\n",
      "http://1937god.info/taxonomy/term/221\n",
      "http://1937god.info/taxonomy/term/28\n",
      "http://1937god.info/taxonomy/term/28\n",
      "http://1937god.info/taxonomy/term/81\n",
      "http://1937god.info/taxonomy/term/1074\n",
      "http://1937god.info/taxonomy/term/222\n",
      "http://1937god.info/taxonomy/term/224\n",
      "http://1937god.info/taxonomy/term/1044\n",
      "http://1937god.info/taxonomy/term/595\n",
      "http://1937god.info/taxonomy/term/225\n",
      "http://1937god.info/taxonomy/term/993\n",
      "http://1937god.info/taxonomy/term/1414\n",
      "http://1937god.info/taxonomy/term/994\n",
      "http://1937god.info/taxonomy/term/994\n",
      "http://1937god.info/taxonomy/term/40\n",
      "http://1937god.info/taxonomy/term/40\n",
      "http://1937god.info/persons?page=1\n",
      "http://1937god.info/persons?page=2\n",
      "http://1937god.info/persons?page=3\n",
      "http://1937god.info/persons?page=4\n",
      "http://1937god.info/persons?page=5\n",
      "http://1937god.info/persons?page=6\n",
      "http://1937god.info/persons?page=7\n",
      "http://1937god.info/persons?page=8\n",
      "http://1937god.info/persons?page=1\n",
      "http://1937god.info/persons?page=35\n",
      "https://www.drupal.org/\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def main ():\n",
    "    html = open('C:\\\\Users\\\\User\\\\jupyterprojects\\\\1937_alphabit.html', encoding='utf-8').read()\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "    div = soup.find_all('a')\n",
    "    \n",
    "    for a in div:\n",
    "        link = a.get('href')\n",
    "        print(link)\n",
    "    #find.all\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<span>1937-й и другие годы</span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/271\">Белые</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/130\">Военные</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/582\">Депутаты ГД</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/144\">Дипломаты</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/986\">Из казаков</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/580\">Кадеты</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/126\">Карательные органы</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/210\">Лидеры нац. движений</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/215\">Меньшевики</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/131\">Партийные деятели</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/127\">Разведка</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/1481\">Сановники</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/750\">Священнослужители</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/129\">Творческие работники</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/234\">Троцкисты</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/146\">Ученые</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/246\">Харбинцы</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/265\">ЧСИР</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/128\">Эсеры</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/9\">Абакумов Виктор Семенович + 19.12.1954</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/4\">Абих Рудольф Петрович + 01.11.1940</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/11\">Аболтин Владимир Яковлевич</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/8\">Абрамов Александр Лазаревич + 25.11.1937</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/8\">Абрамов Александр Лазаревич + 25.11.1937</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/7\">Абрамов Василий Семенович + 05.11.1937</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/1411\">Абрамян Хорен Арутюнович + 29.01.1938</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/6\">Абугов Ошер Осипович + 29.8.1938</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/5\">Авербах Леопольд Леонидович + 14.08.1939</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/5\">Авербах Леопольд Леонидович + 14.08.1939</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/10\">Аверин Василий Павлович + 11.09.1938</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/450\">Авиновицкий Яков Лазаревич + 08.01.1938</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/18\">Агабеков Георгий Сергеевич + 1938</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/1433\">Агапов Владимир Владимирович + 14.10.1937</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/16\">Агас Вениамин Соломонович + 22.02.1939</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/987\">Агеев Павел Михайлович + 1939</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/1142\">Агладзе Леонид Михайлович</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/985\">Агранов Яков Саулович + 01.08.1938</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/985\">Агранов Яков Саулович + 01.08.1938</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/1412\">Адаменко Роман Романович + 25.09.1938</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/988\">Айтаков Надырбай + 1938</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/988\">Айтаков Надырбай + 1938</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/268\">Айхенвальд Александр Юльевич + 11.09.1941</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/989\">Акаев Сарыкбай Джумагалиевич + 11.1937</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/990\">Аксельрод Моисей Моисеевич + 20.02.1939</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/1042\">Аксенов Алексей Михайлович + 23.08.1938</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/1482\">Аксенов Леонид Дмитриевич + 1937</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/991\">Акулов Иван Алексеевич + 30.10.1937</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/991\">Акулов Иван Алексеевич + 30.10.1937</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/1521\">Алабовский Михаил Петрович + 21.12.1937</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/317\">Алафузо Михаил Иванович + 13.07.1937</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/992\">Алгасов Владимир Александрович + 03.10.1938</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/992\">Алгасов Владимир Александрович + 03.10.1938</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/1413\">Александров Александр Соломонович + 26.10.1937</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/221\">Александров Александр Фомич + 1937</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/28\">Александровский Михаил Константинович + 15.11.1937</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/28\">Александровский Михаил Константинович + 15.11.1937</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/81\">Алексеев Глеб Васильевич + 1938</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/1074\">Алексеев Иван Иванович</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/222\">Алексеев Николай Кузьмич</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/224\">Алексеев Николай Николаевич + 09.12.1937</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/1044\">Алексеев Павел Александрович + 23.02.1942</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/595\">Алексеев Трофим Васильевич + 11.03.1938</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/225\">Алексеевский Владимир Александрович + 17.06.1937</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/993\">Алехин Михаил Сергеевич + 22.02.1939</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/1414\">Алиев Джабир Амирулла оглы + 01.09.1938</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/994\">Алкин Ильяс Саид-Гиреевич + 09.05.1938</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/994\">Алкин Ильяс Саид-Гиреевич + 09.05.1938</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/40\">Алкснис Яков Иванович + 28.07.1938</a></span>, <span class=\"field-content\"><a href=\"http://1937god.info/taxonomy/term/40\">Алкснис Яков Иванович + 28.07.1938</a></span>, <span>Создано на <a href=\"https://www.drupal.org/\">Drupal</a></span>]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def main ():\n",
    "    html = open('C:\\\\Users\\\\User\\\\jupyterprojects\\\\1937_alphabit.html', encoding='utf-8').read()\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "    div = soup.find_all('span')\n",
    "    print(div)\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method PageElement.find_parent of <span>1937-й и другие годы</span>>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def main ():\n",
    "    html = open('C:\\\\Users\\\\User\\\\jupyterprojects\\\\1937_alphabit.html', encoding='utf-8').read()\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "    div = soup.find('span').find_parent\n",
    "    print(div)\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'find_parent'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-001e31e1dffe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-46-001e31e1dffe>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhtml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'lxml'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mdiv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'h20'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_parent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'div'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'views-field views-field-name'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdiv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'find_parent'"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def main ():\n",
    "    html = open('C:\\\\Users\\\\User\\\\jupyterprojects\\\\1937_alphabit.html', encoding='utf-8').read()\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "    div = soup.find('h1').find_parent('div', class_ = 'content')\n",
    "    print(div)\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def main ():\n",
    "    html = open('C:\\\\Users\\\\User\\\\jupyterprojects\\\\1937_alphabit.html', encoding='utf-8').read()\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "    text = soup.find('td').next_sibling\n",
    "\n",
    "    print(text)\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a href=\"http://1937god.info/taxonomy/term/986\">Из казаков</a>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import re\n",
    "def main ():\n",
    "    html = open('C:\\\\Users\\\\User\\\\jupyterprojects\\\\1937_alphabit.html', encoding='utf-8').read()\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "    a = soup.find('a', href = re.compile('http://1937god.info/taxonomy/term/9'))\n",
    "    a = a.get('href')\n",
    "    print(a)\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def main ():\n",
    "    html = open('C:\\\\Users\\\\User\\\\jupyterprojects\\\\1937_alphabit.html', encoding='utf-8').read()\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "    text = soup.find('ul').previous_sibling\n",
    "\n",
    "    print(text)\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a href=\"http://1937god.info/taxonomy/term/9\">Абакумов Виктор Семенович + 19.12.1954</a>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import re\n",
    "def main ():\n",
    "    html = open('C:\\\\Users\\\\User\\\\jupyterprojects\\\\1937_alphabit.html', encoding='utf-8').read()\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "    a = soup.find('a', href = re.compile('http://1937god.info/taxonomy/term/9$'))\n",
    "\n",
    "    print(a)\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main-menu\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import re\n",
    "def main ():\n",
    "    html = open('C:\\\\Users\\\\User\\\\jupyterprojects\\\\1937_alphabit.html', encoding='utf-8').read()\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "    div = soup.find('h2').parent\n",
    "    n = div.get('id')\n",
    "    print(n)\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-365a47c9f606>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-64-365a47c9f606>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhref\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'http://1937god.info/taxonomy/term/9$'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get' is not defined"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import re\n",
    "def main ():\n",
    "    html = open('C:\\\\Users\\\\User\\\\jupyterprojects\\\\1937_alphabit.html', encoding='utf-8').read()\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "    a = soup.find('h2').parent\n",
    "    n = div.get('id')\n",
    "    print(n)\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import re\n",
    "\n",
    "regexp = r'\\w\\-'\n",
    "def main ():\n",
    "    html = open('C:\\\\Users\\\\User\\\\jupyterprojects\\\\1937_alphabit.html', encoding='utf-8').read()\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "    a = soup.find('a', text = re.compile('regexp'))\n",
    "                  \n",
    "    print(a)\n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://1937god.info/persons?page=1\n",
      "19\n",
      "http://1937god.info/persons?page=2\n",
      "19\n",
      "http://1937god.info/persons?page=3\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv\n",
    "#План:\n",
    "    #1. выяснить количество страниц\n",
    "    #2. Сформировать список урлов на страницу выдачи \n",
    "    #3. Собрать данные\n",
    "def get_html(url):\n",
    "    r = requests.get(url)\n",
    "    return r.text\n",
    "\n",
    "def get_html(url):\n",
    "    r = requests.get(url)\n",
    "    return r.text\n",
    "#def get_total_pages(html):\n",
    "    #soup = BeautifulSoup(html, 'lxml')\n",
    "    \n",
    "    #pages = soup.find('ul', class_='pager').find_all('a', title = 'На страницу номер 3' )[-1].get('href')\n",
    "    #total_pages = pages.split('=')[1]\n",
    "    #return int(total_pages)\n",
    "\n",
    "def write_csv(data):\n",
    "    with open('1938.csv', 'a') as f:\n",
    "        writer = csv.writer(f)\n",
    "        \n",
    "        writer.writerow((data['url']))\n",
    "\n",
    "def get_page_data(html):\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    \n",
    "    ads = soup.find('table', class_ = 'views-view-grid cols-4').find_all('div', class_ = 'views-field views-field-name')\n",
    "    \n",
    "    for ad in ads:\n",
    "        try:\n",
    "            title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "        except:\n",
    "            title = ' '\n",
    "        try:\n",
    "            url = 'http://1937god.info'+ ad.find('span', class_='field-content').find('a').get('href')\n",
    "        except:\n",
    "            url = ' '\n",
    "            \n",
    "        data = {'title':title,\n",
    "                    'url':url}\n",
    "        write_csv(data)\n",
    "    print(len(ads))\n",
    "    \n",
    "def main ():\n",
    "    url = \"http://1937god.info/node/1\"\n",
    "    base_url = 'http://1937god.info/node/'\n",
    "    \n",
    "    #total_pages = get_total_pages(get_html(url))\n",
    "    \n",
    "    for i in range(1, 36):\n",
    "        url_gen = base_url + str(i)\n",
    "        print(url_gen)\n",
    "        html = get_html(url_gen)\n",
    "        get_page_data(html)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv\n",
    "#План:\n",
    "    #1. выяснить количество страниц\n",
    "    #2. Сформировать список урлов на страницу выдачи \n",
    "    #3. Собрать данные\n",
    "def get_html(url):\n",
    "    r = requests.get(url)\n",
    "    return r.text\n",
    "\n",
    "def get_html(url):\n",
    "    r = requests.get(url)\n",
    "    return r.text\n",
    "#def get_total_pages(html):\n",
    "    #soup = BeautifulSoup(html, 'lxml')\n",
    "    \n",
    "    #pages = soup.find('ul', class_='pager').find_all('a', title = 'На страницу номер 3' )[-1].get('href')\n",
    "    #total_pages = pages.split('=')[1]\n",
    "    #return int(total_pages)\n",
    "\n",
    "def write_csv(data):\n",
    "    with open('19376.csv', 'a') as f:\n",
    "        writer = csv.writer(f)\n",
    "        \n",
    "        writer.writerow((data['title'],\n",
    "                                    data['url']))\n",
    "\n",
    "def get_page_data(html):\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    \n",
    "    ads = soup.find('table', class_ = 'views-view-grid cols-4').find_all('div', class_ = 'views-field views-field-name')\n",
    "    \n",
    "    for ad in ads:\n",
    "        try:\n",
    "            title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "        except:\n",
    "            title = ' '\n",
    "        try:\n",
    "            url = 'http://1937god.info'+ ad.find('span', class_='field-content').find('a').get('href')\n",
    "        except:\n",
    "            url = ' '\n",
    "            \n",
    "        data = {'title':title,\n",
    "                    'url':url}\n",
    "        write_csv(data)\n",
    "    print(len(ads))\n",
    "    \n",
    "def main ():\n",
    "    url = \"https://wordstat.yandex.ru/#!/history?period=weekly&regions=10645&words=%D1%87%D1%80%D0%B5%D0%B7%D0%B2%D1%8B%D1%87%D0%B0%D0%B9%D0%BD%D0%BE%D0%B5%20%D0%BF%D0%BE%D0%BB%D0%BE%D0%B6%D0%B5%D0%BD%D0%B8%D0%B5\"\n",
    "    base_url = 'http://1937god.info/persons?'\n",
    "    page_part = 'page='\n",
    "    \n",
    "    #total_pages = get_total_pages(get_html(url))\n",
    "    \n",
    "    for i in range(1, 36):\n",
    "        url_gen = base_url + page_part + str(i)\n",
    "        print(url_gen)\n",
    "        html = get_html(url_gen)\n",
    "        get_page_data(html)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://1937god.info/persons?page=1\n",
      "50\n",
      "http://1937god.info/persons?page=2\n",
      "50\n",
      "http://1937god.info/persons?page=3\n",
      "50\n",
      "http://1937god.info/persons?page=4\n",
      "50\n",
      "http://1937god.info/persons?page=5\n",
      "50\n",
      "http://1937god.info/persons?page=6\n",
      "50\n",
      "http://1937god.info/persons?page=7\n",
      "50\n",
      "http://1937god.info/persons?page=8\n",
      "50\n",
      "http://1937god.info/persons?page=9\n",
      "50\n",
      "http://1937god.info/persons?page=10\n",
      "50\n",
      "http://1937god.info/persons?page=11\n",
      "50\n",
      "http://1937god.info/persons?page=12\n",
      "50\n",
      "http://1937god.info/persons?page=13\n",
      "50\n",
      "http://1937god.info/persons?page=14\n",
      "50\n",
      "http://1937god.info/persons?page=15\n",
      "50\n",
      "http://1937god.info/persons?page=16\n",
      "50\n",
      "http://1937god.info/persons?page=17\n",
      "50\n",
      "http://1937god.info/persons?page=18\n",
      "50\n",
      "http://1937god.info/persons?page=19\n",
      "50\n",
      "http://1937god.info/persons?page=20\n",
      "50\n",
      "http://1937god.info/persons?page=21\n",
      "50\n",
      "http://1937god.info/persons?page=22\n",
      "50\n",
      "http://1937god.info/persons?page=23\n",
      "50\n",
      "http://1937god.info/persons?page=24\n",
      "50\n",
      "http://1937god.info/persons?page=25\n",
      "50\n",
      "http://1937god.info/persons?page=26\n",
      "50\n",
      "http://1937god.info/persons?page=27\n",
      "50\n",
      "http://1937god.info/persons?page=28\n",
      "50\n",
      "http://1937god.info/persons?page=29\n",
      "50\n",
      "http://1937god.info/persons?page=30\n",
      "50\n",
      "http://1937god.info/persons?page=31\n",
      "50\n",
      "http://1937god.info/persons?page=32\n",
      "50\n",
      "http://1937god.info/persons?page=33\n",
      "50\n",
      "http://1937god.info/persons?page=34\n",
      "50\n",
      "http://1937god.info/persons?page=35\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv\n",
    "#План:\n",
    "    #1. выяснить количество страниц\n",
    "    #2. Сформировать список урлов на страницу выдачи \n",
    "    #3. Собрать данные\n",
    "def get_html(url):\n",
    "    r = requests.get(url)\n",
    "    return r.text\n",
    "\n",
    "def get_html(url):\n",
    "    r = requests.get(url)\n",
    "    return r.text\n",
    "\n",
    "def write_csv(data):\n",
    "    with open('19376.csv', 'a') as f:\n",
    "        writer = csv.writer(f)\n",
    "        \n",
    "        writer.writerow((data['title'],\n",
    "                                    data['url']))\n",
    "\n",
    "def get_page_data(html):\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    \n",
    "    ads = soup.find('table', class_ = 'views-view-grid cols-4').find_all('div', class_ = 'views-field views-field-name')\n",
    "    \n",
    "    for ad in ads:\n",
    "        try:\n",
    "            title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "        except:\n",
    "            title = ' '\n",
    "        try:\n",
    "            url = 'http://1937god.info'+ ad.find('span', class_='field-content').find('a').get('href')\n",
    "        except:\n",
    "            url = ' '\n",
    "            \n",
    "        data = {'title':title,\n",
    "                    'url':url}\n",
    "        write_csv(data)\n",
    "    print(len(ads))\n",
    "    \n",
    "def main ():\n",
    "    url = \"http://1937god.info/persons?page=1\"\n",
    "    base_url = 'http://1937god.info/persons?'\n",
    "    page_part = 'page='\n",
    "    \n",
    "    #total_pages = get_total_pages(get_html(url))\n",
    "    \n",
    "    for i in range(1, 36):\n",
    "        url_gen = base_url + page_part + str(i)\n",
    "        print(url_gen)\n",
    "        html = get_html(url_gen)\n",
    "        get_page_data(html)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv\n",
    "\n",
    "def get_html(url):\n",
    "    r = requests.get(url)\n",
    "    return r.text\n",
    "\n",
    "def write_csv(data1):\n",
    "    with open('19379.csv', 'a') as f:\n",
    "        writer = csv.writer(f)\n",
    "        \n",
    "        writer.writerow((data1['text']))\n",
    "\n",
    "def get_page_data(html):\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    ads = soup.find('div', class_ = 'taxonomy-term vocabulary-subjects').find_all('div', class_ = 'content')\n",
    "    \n",
    "    for ad in ads:\n",
    "        try:\n",
    "            text = ad.find('div', class_='taxonomy-term-description').find('p').text.strip()\n",
    "        except:\n",
    "            text = ' '\n",
    "            \n",
    "        data1 = {'text':text}\n",
    "        write_csv(data1)\n",
    "    \n",
    "def main (): \n",
    "    url = \"http://1937god.info/taxonomy/term/934\"\n",
    "    data = pd.read_csv(\"C:\\\\Users\\\\User\\\\PycharmProjects\\\\19375.csv\", engine ='python')\n",
    "    \n",
    "    for a in data['http://1937god.info/taxonomy/term/40']:\n",
    "        html = get_html(a)\n",
    "        get_page_data(html)\n",
    "        \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Алкснис Яков Иванович + 28.07.1938</th>\n",
       "      <th>http://1937god.info/taxonomy/term/40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Алкснис Ян Янович + 23.12.1943</td>\n",
       "      <td>http://1937god.info/taxonomy/term/454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Альшанский Анатолий Романович + 25 12 1940</td>\n",
       "      <td>http://1937god.info/taxonomy/term/995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Альшиц Даниил Нотанович</td>\n",
       "      <td>http://1937god.info/taxonomy/term/1508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Алякринский Николай Владимирович + 22.02.1938</td>\n",
       "      <td>http://1937god.info/taxonomy/term/933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Алякрицкий Борис Евгеньевич + 26.11.1937</td>\n",
       "      <td>http://1937god.info/taxonomy/term/934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Алкснис Яков Иванович + 28.07.1938  \\\n",
       "0                 Алкснис Ян Янович + 23.12.1943   \n",
       "1     Альшанский Анатолий Романович + 25 12 1940   \n",
       "2                        Альшиц Даниил Нотанович   \n",
       "3  Алякринский Николай Владимирович + 22.02.1938   \n",
       "4       Алякрицкий Борис Евгеньевич + 26.11.1937   \n",
       "\n",
       "     http://1937god.info/taxonomy/term/40  \n",
       "0   http://1937god.info/taxonomy/term/454  \n",
       "1   http://1937god.info/taxonomy/term/995  \n",
       "2  http://1937god.info/taxonomy/term/1508  \n",
       "3   http://1937god.info/taxonomy/term/933  \n",
       "4   http://1937god.info/taxonomy/term/934  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "data = pd.read_csv(\"C:\\\\Users\\\\User\\\\PycharmProjects\\\\19376.csv\", engine ='python')\n",
    "data.head()\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Алкснис Яков Иванович + 28.07.1938</th>\n",
       "      <th>http://1937god.info/taxonomy/term/40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Алкснис Ян Янович + 23.12.1943</td>\n",
       "      <td>http://1937god.info/taxonomy/term/454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Альшанский Анатолий Романович + 25 12 1940</td>\n",
       "      <td>http://1937god.info/taxonomy/term/995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Альшиц Даниил Нотанович</td>\n",
       "      <td>http://1937god.info/taxonomy/term/1508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Алякринский Николай Владимирович + 22.02.1938</td>\n",
       "      <td>http://1937god.info/taxonomy/term/933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Алякрицкий Борис Евгеньевич + 26.11.1937</td>\n",
       "      <td>http://1937god.info/taxonomy/term/934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Алкснис Яков Иванович + 28.07.1938  \\\n",
       "0                 Алкснис Ян Янович + 23.12.1943   \n",
       "1     Альшанский Анатолий Романович + 25 12 1940   \n",
       "2                        Альшиц Даниил Нотанович   \n",
       "3  Алякринский Николай Владимирович + 22.02.1938   \n",
       "4       Алякрицкий Борис Евгеньевич + 26.11.1937   \n",
       "\n",
       "     http://1937god.info/taxonomy/term/40  \n",
       "0   http://1937god.info/taxonomy/term/454  \n",
       "1   http://1937god.info/taxonomy/term/995  \n",
       "2  http://1937god.info/taxonomy/term/1508  \n",
       "3   http://1937god.info/taxonomy/term/933  \n",
       "4   http://1937god.info/taxonomy/term/934  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"C:\\\\Users\\\\User\\\\PycharmProjects\\\\19375.csv\", engine ='python')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://1937god.info/node/1\n",
      "http://1937god.info/node/2\n",
      "http://1937god.info/node/3\n",
      "http://1937god.info/node/4\n",
      "http://1937god.info/node/5\n",
      "http://1937god.info/node/6\n",
      "http://1937god.info/node/7\n",
      "http://1937god.info/node/8\n",
      "http://1937god.info/node/9\n",
      "http://1937god.info/node/10\n",
      "http://1937god.info/node/11\n",
      "http://1937god.info/node/12\n",
      "http://1937god.info/node/13\n",
      "http://1937god.info/node/14\n",
      "http://1937god.info/node/15\n",
      "http://1937god.info/node/16\n",
      "http://1937god.info/node/17\n",
      "http://1937god.info/node/18\n",
      "http://1937god.info/node/19\n",
      "http://1937god.info/node/20\n",
      "http://1937god.info/node/21\n",
      "http://1937god.info/node/22\n",
      "http://1937god.info/node/23\n",
      "http://1937god.info/node/24\n",
      "http://1937god.info/node/25\n",
      "http://1937god.info/node/26\n",
      "http://1937god.info/node/27\n",
      "http://1937god.info/node/28\n",
      "http://1937god.info/node/29\n",
      "http://1937god.info/node/30\n",
      "http://1937god.info/node/31\n",
      "http://1937god.info/node/32\n",
      "http://1937god.info/node/33\n",
      "http://1937god.info/node/34\n",
      "http://1937god.info/node/35\n"
     ]
    }
   ],
   "source": [
    "def main ():\n",
    "    url = \"http://1937god.info/node/1\"\n",
    "    base_url = 'http://1937god.info/node/'\n",
    "    \n",
    "    #total_pages = get_total_pages(get_html(url))\n",
    "    \n",
    "    for i in range(1, 36):\n",
    "        url_gen = base_url + str(i)\n",
    "        print(url_gen)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://1937god.info/node/1\n",
      "http://1937god.info/node/2\n",
      "http://1937god.info/node/3\n",
      "http://1937god.info/node/4\n",
      "http://1937god.info/node/5\n",
      "http://1937god.info/node/6\n",
      "http://1937god.info/node/7\n",
      "http://1937god.info/node/8\n",
      "http://1937god.info/node/9\n",
      "http://1937god.info/node/10\n",
      "http://1937god.info/node/11\n",
      "http://1937god.info/node/12\n",
      "http://1937god.info/node/13\n",
      "http://1937god.info/node/14\n",
      "http://1937god.info/node/15\n",
      "http://1937god.info/node/16\n",
      "http://1937god.info/node/17\n",
      "http://1937god.info/node/18\n",
      "http://1937god.info/node/19\n",
      "http://1937god.info/node/20\n",
      "http://1937god.info/node/21\n",
      "http://1937god.info/node/22\n",
      "http://1937god.info/node/23\n",
      "http://1937god.info/node/24\n",
      "http://1937god.info/node/25\n",
      "http://1937god.info/node/26\n",
      "http://1937god.info/node/27\n",
      "http://1937god.info/node/28\n",
      "http://1937god.info/node/29\n",
      "http://1937god.info/node/30\n",
      "http://1937god.info/node/31\n",
      "http://1937god.info/node/32\n",
      "http://1937god.info/node/33\n",
      "http://1937god.info/node/34\n",
      "http://1937god.info/node/35\n"
     ]
    }
   ],
   "source": [
    "url = \"http://1937god.info/node/1\"\n",
    "base_url = 'http://1937god.info/node/'\n",
    "    \n",
    "    #total_pages = get_total_pages(get_html(url))\n",
    "    \n",
    "for i in range(1, 36):\n",
    "    url_gen = base_url + str(i)\n",
    "    print(url_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 опись ГАРФ\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv\n",
    "#План:\n",
    "    #1. выяснить количество страниц\n",
    "    #2. Сформировать список урлов на страницу выдачи \n",
    "    #3. Собрать данные\n",
    "def get_html(url_2):\n",
    "    r = requests.get(url_2)\n",
    "    #r.encoding = 'UTF-8'\n",
    "    #r.encoding = 'cp1252'\n",
    "    #type(r.content)\n",
    "    #type(r.text)\n",
    "    #r.headers['Content-Type']\n",
    "    #r.encoding\n",
    "    #print(r.encoding)\n",
    "    #r = r.content.decode('utf-8','ignore')\n",
    "   # print(r.encoding)\n",
    "    #return r\n",
    "    return r.text\n",
    "\n",
    "def write_csv(data):\n",
    "    with open('garf_3.csv', 'a') as f:\n",
    "        writer = csv.writer(f)\n",
    "        \n",
    "        writer.writerow((data['familia'],\n",
    "                                    data['name'],\n",
    "                                    data['otch'],\n",
    "                                    data['together'],\n",
    "                                    data['nomer_dela'],\n",
    "                                    data['deloproizvod_nomer'],\n",
    "                                    data['krainie_dat'],\n",
    "                                    data['primechania'],\n",
    "                                    data['url'],))\n",
    "\n",
    "def get_page_data(html):\n",
    "    soup = BeautifulSoup(html, 'lxml', fromEncoding='utf-8')\n",
    "    #print(soup)\n",
    "    \n",
    "    #ads = soup.find('table', class_ = 'views-view-grid cols-4').find_all('div', class_ = 'views-field views-field-name')\n",
    "    #ads = soup.find_all('td')[6]#.find_all('p')\n",
    "    ads = soup.find_all('font', class_ = 'black')##[8]#.text.split()[4:7]\n",
    "    #print(ads)\n",
    "    \n",
    "    #for ad in ads:\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        familia = ads[6].text.split()[4]\n",
    "    except IndexError:\n",
    "        familia = 'NaN'\n",
    "        #except:\n",
    "            #familia = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        name = ads[6].text.split()[5]\n",
    "    except IndexError:\n",
    "        name = 'NaN'\n",
    "        #except:\n",
    "            #name = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        otch = ads[6].text.split()[6]\n",
    "    except IndexError:\n",
    "        otch = 'NaN'\n",
    "    #otch = ads[6].text.split()[6]\n",
    "        #except:\n",
    "            #otch = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    #together =  str(ads[6].text.split()[4:7]).strip('[]')\n",
    "    try:\n",
    "        together =  ' '.join(map(str, ads[6].text.split()[4:7]))\n",
    "    except IndexError:\n",
    "        together = 'NaN'\n",
    "    #together = print('  '.join(mylist)ads[6].text.split()[4:7])\n",
    "        #except:\n",
    "            #together = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        nomer_dela = ads[0].text.split()[0]\n",
    "    except IndexError:\n",
    "        nomer_dela = 'NaN'\n",
    "        #except:\n",
    "            #nomer_dela = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        deloproizvod_nomer = ads[1].text.split()[0]\n",
    "    except IndexError:\n",
    "        deloproizvod_nomer = 'NaN'\n",
    "        #except:\n",
    "            #deloproizvod_nomer = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        krainie_dat =  ' '.join(map(str, ads[8].text.split()))#[0]\n",
    "    except IndexError:\n",
    "        krainie_dat = 'NaN'\n",
    "        #except:\n",
    "            #krainie_dat = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        primechania = ' '.join(map(str, ads[10].text.split()))#[0]\n",
    "    except IndexError:\n",
    "        primechania = 'NaN'\n",
    "        #except:\n",
    "            #primechania = ' '\n",
    "        #try:\n",
    "    try:\n",
    "        url =  'http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447215&fond=3236&opis=6065&delo=509718'\n",
    "    except IndexError:\n",
    "        url = 'NaN'\n",
    "            #url = 'http://1937god.info'+ ad.find('span', class_='field-content').find('a').get('href')\n",
    "        #except:\n",
    "            #url = ' '\n",
    "            \n",
    "    data = {'familia':familia,\n",
    "                    'name':name,\n",
    "                    'otch':otch,\n",
    "                    'together':together,\n",
    "                    'nomer_dela':nomer_dela,\n",
    "                    'deloproizvod_nomer':deloproizvod_nomer,\n",
    "                    'krainie_dat':krainie_dat,\n",
    "                    'primechania':primechania,\n",
    "                    'url':url}\n",
    "    write_csv(data)\n",
    "    #print(data)\n",
    "    #print(len(ads))\n",
    "    \n",
    "def main ():\n",
    "    url = \"http://1937god.info/persons?page=1\"\n",
    "    url_2 = \"http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447215&fond=3236&opis=6065&delo=5029718\"\n",
    "    url_3 = \"http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447215&fond=3236&opis=6065&delo=5039454\"\n",
    "    base_url = 'http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447215&fond=3236&opis=6065&delo=50'\n",
    "    #base_url = 'http://1937god.info/persons?'\n",
    "    page_part = 'page='\n",
    "    \n",
    "    #total_pages = get_total_pages(get_html(url))\n",
    "    \n",
    "    for i in range(29718, 39455):\n",
    "    #for i in range(29718, 29722):\n",
    "        #if i == 29833 or i == 29835 or i == 29840 or i == 29841 or i == 29849:\n",
    "            #continue\n",
    "        #url_gen = base_url + page_part + str(i)\n",
    "        #print(url_gen)\n",
    "        #html = get_html(url_gen)\n",
    "        url_2 = base_url + str(i)\n",
    "        #print(url_2)\n",
    "        html = get_html(url_2)\n",
    "        #print(html)\n",
    "        get_page_data(html)\n",
    "        \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    \n",
    "#Soup = BeautifulSoup(r.content.decode('utf-8','ignore'),\"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "data_3 = pd.read_csv(\"C:\\\\Users\\\\User\\\\PycharmProjects\\\\garf_3.csv\", engine ='python',names= ['familia', 'name','otch', 'together','nomer_dela', 'deloproizvod_nomer','krainie_dat', 'primechania', 'url'])\n",
    "\n",
    "pd.DataFrame.to_csv(data_3, 'garf_33.csv')\n",
    "#data.tail()\n",
    "#data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 опись ГАРФ\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv\n",
    "#План:\n",
    "    #1. выяснить количество страниц\n",
    "    #2. Сформировать список урлов на страницу выдачи \n",
    "    #3. Собрать данные\n",
    "def get_html(url_2):\n",
    "    r = requests.get(url_2)\n",
    "    #r.encoding = 'UTF-8'\n",
    "    #r.encoding = 'cp1252'\n",
    "    #type(r.content)\n",
    "    #type(r.text)\n",
    "    #r.headers['Content-Type']\n",
    "    #r.encoding\n",
    "    #print(r.encoding)\n",
    "    #r = r.content.decode('utf-8','ignore')\n",
    "   # print(r.encoding)\n",
    "    #return r\n",
    "    return r.text\n",
    "\n",
    "def write_csv(data):\n",
    "    with open('garf_4.csv', 'a') as f:\n",
    "        writer = csv.writer(f)\n",
    "        \n",
    "        writer.writerow((data['familia'],\n",
    "                                    data['name'],\n",
    "                                    data['otch'],\n",
    "                                    data['together'],\n",
    "                                    data['nomer_dela'],\n",
    "                                    data['deloproizvod_nomer'],\n",
    "                                    data['krainie_dat'],\n",
    "                                    data['primechania'],\n",
    "                                    data['url'],))\n",
    "\n",
    "def get_page_data(html):\n",
    "    soup = BeautifulSoup(html, 'lxml', fromEncoding='utf-8')\n",
    "    #print(soup)\n",
    "    \n",
    "    #ads = soup.find('table', class_ = 'views-view-grid cols-4').find_all('div', class_ = 'views-field views-field-name')\n",
    "    #ads = soup.find_all('td')[6]#.find_all('p')\n",
    "    ads = soup.find_all('font', class_ = 'black')##[8]#.text.split()[4:7]\n",
    "    #print(ads)\n",
    "    \n",
    "    #for ad in ads:\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        familia = ads[6].text.split()[4]\n",
    "    except IndexError:\n",
    "        familia = 'NaN'\n",
    "        #except:\n",
    "            #familia = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        name = ads[6].text.split()[5]\n",
    "    except IndexError:\n",
    "        name = 'NaN'\n",
    "        #except:\n",
    "            #name = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        otch = ads[6].text.split()[6]\n",
    "    except IndexError:\n",
    "        otch = 'NaN'\n",
    "    #otch = ads[6].text.split()[6]\n",
    "        #except:\n",
    "            #otch = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    #together =  str(ads[6].text.split()[4:7]).strip('[]')\n",
    "    try:\n",
    "        together =  ' '.join(map(str, ads[6].text.split()[4:7]))\n",
    "    except IndexError:\n",
    "        together = 'NaN'\n",
    "    #together = print('  '.join(mylist)ads[6].text.split()[4:7])\n",
    "        #except:\n",
    "            #together = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        nomer_dela = ads[0].text.split()[0]\n",
    "    except IndexError:\n",
    "        nomer_dela = 'NaN'\n",
    "        #except:\n",
    "            #nomer_dela = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        deloproizvod_nomer = ads[1].text.split()[0]\n",
    "    except IndexError:\n",
    "        deloproizvod_nomer = 'NaN'\n",
    "        #except:\n",
    "            #deloproizvod_nomer = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        krainie_dat =  ' '.join(map(str, ads[8].text.split()))#[0]\n",
    "    except IndexError:\n",
    "        krainie_dat = 'NaN'\n",
    "        #except:\n",
    "            #krainie_dat = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        primechania = ' '.join(map(str, ads[10].text.split()))#[0]\n",
    "    except IndexError:\n",
    "        primechania = 'NaN'\n",
    "        #except:\n",
    "            #primechania = ' '\n",
    "        #try:\n",
    "    try:\n",
    "        url =  \"http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447411&fond=3236&opis=6066&delo=5013235\"\n",
    "    except IndexError:\n",
    "        url = 'NaN'\n",
    "            #url = 'http://1937god.info'+ ad.find('span', class_='field-content').find('a').get('href')\n",
    "        #except:\n",
    "            #url = ' '\n",
    "            \n",
    "    data = {'familia':familia,\n",
    "                    'name':name,\n",
    "                    'otch':otch,\n",
    "                    'together':together,\n",
    "                    'nomer_dela':nomer_dela,\n",
    "                    'deloproizvod_nomer':deloproizvod_nomer,\n",
    "                    'krainie_dat':krainie_dat,\n",
    "                    'primechania':primechania,\n",
    "                    'url':url}\n",
    "    write_csv(data)\n",
    "    #print(data)\n",
    "    #print(len(ads))\n",
    "    \n",
    "def main ():\n",
    "    url = \"http://1937god.info/persons?page=1\"\n",
    "    url_4 = \"http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447411&fond=3236&opis=6066&delo=5013235\"\n",
    "    url_3 = \"http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447411&fond=3236&opis=6066&delo=5023597\"\n",
    "                    #http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447411&fond=3236&opis=6066&delo=5013235\n",
    "    base_url = 'http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447411&fond=3236&opis=6066&delo=50'\n",
    "    #base_url = 'http://1937god.info/persons?'\n",
    "    page_part = 'page='\n",
    "    \n",
    "    #total_pages = get_total_pages(get_html(url))\n",
    "    \n",
    "    for i in range(13235, 23598):\n",
    "    #for i in range(13235, 13238):\n",
    "        #if i == 29833 or i == 29835 or i == 29840 or i == 29841 or i == 29849:\n",
    "            #continue\n",
    "        #url_gen = base_url + page_part + str(i)\n",
    "        #print(url_gen)\n",
    "        #html = get_html(url_gen)\n",
    "        url_2 = base_url + str(i)\n",
    "        #print(url_2)\n",
    "        html = get_html(url_2)\n",
    "        #print(html)\n",
    "        get_page_data(html)\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    \n",
    "#Soup = BeautifulSoup(r.content.decode('utf-8','ignore'),\"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>familia</th>\n",
       "      <th>name</th>\n",
       "      <th>otch</th>\n",
       "      <th>together</th>\n",
       "      <th>nomer_dela</th>\n",
       "      <th>deloproizvod_nomer</th>\n",
       "      <th>krainie_dat</th>\n",
       "      <th>primechania</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Кайгородов</td>\n",
       "      <td>Игнатий</td>\n",
       "      <td>Яковлевич</td>\n",
       "      <td>Кайгородов Игнатий Яковлевич</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12711.0</td>\n",
       "      <td>01 мая 1955</td>\n",
       "      <td>1882г.р.</td>\n",
       "      <td>http://opisi.garf.su/default.asp?base=garf&amp;men...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Королев</td>\n",
       "      <td>Василий</td>\n",
       "      <td>Иванович</td>\n",
       "      <td>Королев Василий Иванович</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12712.0</td>\n",
       "      <td>01 мая 1955</td>\n",
       "      <td>1891г.р.</td>\n",
       "      <td>http://opisi.garf.su/default.asp?base=garf&amp;men...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Кузнецов</td>\n",
       "      <td>Леонид</td>\n",
       "      <td>Федорович</td>\n",
       "      <td>Кузнецов Леонид Федорович</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12713.0</td>\n",
       "      <td>01 мая 1955</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://opisi.garf.su/default.asp?base=garf&amp;men...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Кастра</td>\n",
       "      <td>Альма</td>\n",
       "      <td>Мартыновна</td>\n",
       "      <td>Кастра Альма Мартыновна</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12714.0</td>\n",
       "      <td>01 мая 1955</td>\n",
       "      <td>1884г.р.</td>\n",
       "      <td>http://opisi.garf.su/default.asp?base=garf&amp;men...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Календро</td>\n",
       "      <td>Зоя</td>\n",
       "      <td>Леонидовна</td>\n",
       "      <td>Календро Зоя Леонидовна</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12715.0</td>\n",
       "      <td>01 апреля 1955</td>\n",
       "      <td>1896г.р.</td>\n",
       "      <td>http://opisi.garf.su/default.asp?base=garf&amp;men...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      familia     name        otch                      together  nomer_dela  \\\n",
       "0  Кайгородов  Игнатий   Яковлевич  Кайгородов Игнатий Яковлевич         1.0   \n",
       "1     Королев  Василий    Иванович      Королев Василий Иванович         2.0   \n",
       "2    Кузнецов   Леонид   Федорович     Кузнецов Леонид Федорович         3.0   \n",
       "3      Кастра    Альма  Мартыновна       Кастра Альма Мартыновна         4.0   \n",
       "4    Календро      Зоя  Леонидовна       Календро Зоя Леонидовна         5.0   \n",
       "\n",
       "   deloproizvod_nomer     krainie_dat primechania  \\\n",
       "0             12711.0     01 мая 1955    1882г.р.   \n",
       "1             12712.0     01 мая 1955    1891г.р.   \n",
       "2             12713.0     01 мая 1955         NaN   \n",
       "3             12714.0     01 мая 1955    1884г.р.   \n",
       "4             12715.0  01 апреля 1955    1896г.р.   \n",
       "\n",
       "                                                 url  \n",
       "0  http://opisi.garf.su/default.asp?base=garf&men...  \n",
       "1  http://opisi.garf.su/default.asp?base=garf&men...  \n",
       "2  http://opisi.garf.su/default.asp?base=garf&men...  \n",
       "3  http://opisi.garf.su/default.asp?base=garf&men...  \n",
       "4  http://opisi.garf.su/default.asp?base=garf&men...  "
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "data = pd.read_csv(\"C:\\\\Users\\\\User\\\\PycharmProjects\\\\garf_4.csv\", engine ='python',names= ['familia', 'name','otch', 'together','nomer_dela', 'deloproizvod_nomer','krainie_dat', 'primechania', 'url'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.to_csv(data, 'garf_44.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 опись ГАРФ\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv\n",
    "#План:\n",
    "    #1. выяснить количество страниц\n",
    "    #2. Сформировать список урлов на страницу выдачи \n",
    "    #3. Собрать данные\n",
    "def get_html(url_2):\n",
    "    r = requests.get(url_2)\n",
    "    #r.encoding = 'UTF-8'\n",
    "    #r.encoding = 'cp1252'\n",
    "    #type(r.content)\n",
    "    #type(r.text)\n",
    "    #r.headers['Content-Type']\n",
    "    #r.encoding\n",
    "    #print(r.encoding)\n",
    "    #r = r.content.decode('utf-8','ignore')\n",
    "   # print(r.encoding)\n",
    "    #return r\n",
    "    return r.text\n",
    "\n",
    "def write_csv(data):\n",
    "    with open('garf_5.csv', 'a') as f:\n",
    "        writer = csv.writer(f)\n",
    "        \n",
    "        writer.writerow((data['familia'],\n",
    "                                    data['name'],\n",
    "                                    data['otch'],\n",
    "                                    data['together'],\n",
    "                                    data['nomer_dela'],\n",
    "                                    data['deloproizvod_nomer'],\n",
    "                                    data['krainie_dat'],\n",
    "                                    data['primechania'],\n",
    "                                    data['url'],))\n",
    "\n",
    "def get_page_data(html):\n",
    "    soup = BeautifulSoup(html, 'lxml', fromEncoding='utf-8')\n",
    "    #print(soup)\n",
    "    \n",
    "    #ads = soup.find('table', class_ = 'views-view-grid cols-4').find_all('div', class_ = 'views-field views-field-name')\n",
    "    #ads = soup.find_all('td')[6]#.find_all('p')\n",
    "    ads = soup.find_all('font', class_ = 'black')##[8]#.text.split()[4:7]\n",
    "    #print(ads)\n",
    "    \n",
    "    #for ad in ads:\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        familia = ads[6].text.split()[4]\n",
    "    except IndexError:\n",
    "        familia = 'NaN'\n",
    "        #except:\n",
    "            #familia = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        name = ads[6].text.split()[5]\n",
    "    except IndexError:\n",
    "        name = 'NaN'\n",
    "        #except:\n",
    "            #name = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        otch = ads[6].text.split()[6]\n",
    "    except IndexError:\n",
    "        otch = 'NaN'\n",
    "    #otch = ads[6].text.split()[6]\n",
    "        #except:\n",
    "            #otch = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    #together =  str(ads[6].text.split()[4:7]).strip('[]')\n",
    "    try:\n",
    "        together =  ' '.join(map(str, ads[6].text.split()[4:7]))\n",
    "    except IndexError:\n",
    "        together = 'NaN'\n",
    "    #together = print('  '.join(mylist)ads[6].text.split()[4:7])\n",
    "        #except:\n",
    "            #together = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        nomer_dela = ads[0].text.split()[0]\n",
    "    except IndexError:\n",
    "        nomer_dela = 'NaN'\n",
    "        #except:\n",
    "            #nomer_dela = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        deloproizvod_nomer = ads[1].text.split()[0]\n",
    "    except IndexError:\n",
    "        deloproizvod_nomer = 'NaN'\n",
    "        #except:\n",
    "            #deloproizvod_nomer = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        krainie_dat =  ' '.join(map(str, ads[8].text.split()))#[0]\n",
    "    except IndexError:\n",
    "        krainie_dat = 'NaN'\n",
    "        #except:\n",
    "            #krainie_dat = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        primechania = ' '.join(map(str, ads[10].text.split()))#[0]\n",
    "    except IndexError:\n",
    "        primechania = 'NaN'\n",
    "        #except:\n",
    "            #primechania = ' '\n",
    "        #try:\n",
    "    try:\n",
    "        url =  \"http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447411&fond=3236&opis=6066&delo=5013235\"\n",
    "    except IndexError:\n",
    "        url = 'NaN'\n",
    "            #url = 'http://1937god.info'+ ad.find('span', class_='field-content').find('a').get('href')\n",
    "        #except:\n",
    "            #url = ' '\n",
    "            \n",
    "    data = {'familia':familia,\n",
    "                    'name':name,\n",
    "                    'otch':otch,\n",
    "                    'together':together,\n",
    "                    'nomer_dela':nomer_dela,\n",
    "                    'deloproizvod_nomer':deloproizvod_nomer,\n",
    "                    'krainie_dat':krainie_dat,\n",
    "                    'primechania':primechania,\n",
    "                    'url':url}\n",
    "    write_csv(data)\n",
    "    #print(data)\n",
    "    #print(len(ads))\n",
    "    \n",
    "def main ():\n",
    "    url = \"http://1937god.info/persons?page=1\"\n",
    "    url_4 = \"http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447433&fond=3236&opis=6067&delo=5023598\"\n",
    "    url_3 = \"http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447433&fond=3236&opis=6067&delo=5046655\"\n",
    "                    #http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447433&fond=3236&opis=6067&delo=5023598\n",
    "    base_url = 'http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447433&fond=3236&opis=6067&delo=50'\n",
    "    #base_url = 'http://1937god.info/persons?'\n",
    "    page_part = 'page='\n",
    "    \n",
    "    #total_pages = get_total_pages(get_html(url))\n",
    "    \n",
    "    for i in range(23598, 46656):\n",
    "    #for i in range(13235, 13238):\n",
    "        #if i == 29833 or i == 29835 or i == 29840 or i == 29841 or i == 29849:\n",
    "            #continue\n",
    "        #url_gen = base_url + page_part + str(i)\n",
    "        #print(url_gen)\n",
    "        #html = get_html(url_gen)\n",
    "        url_2 = base_url + str(i)\n",
    "        #print(url_2)\n",
    "        html = get_html(url_2)\n",
    "        #print(html)\n",
    "        get_page_data(html)\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    \n",
    "#Soup = BeautifulSoup(r.content.decode('utf-8','ignore'),\"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "data_5 = pd.read_csv(\"C:\\\\Users\\\\User\\\\PycharmProjects\\\\garf_5.csv\", engine ='python',names= ['familia', 'name','otch', 'together','nomer_dela', 'deloproizvod_nomer','krainie_dat', 'primechania', 'url'])\n",
    "pd.DataFrame.to_csv(data_5, 'garf_55.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6 опись ГАРФ\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv\n",
    "#План:\n",
    "    #1. выяснить количество страниц\n",
    "    #2. Сформировать список урлов на страницу выдачи \n",
    "    #3. Собрать данные\n",
    "def get_html(url_2):\n",
    "    r = requests.get(url_2)\n",
    "    #r.encoding = 'UTF-8'\n",
    "    #r.encoding = 'cp1252'\n",
    "    #type(r.content)\n",
    "    #type(r.text)\n",
    "    #r.headers['Content-Type']\n",
    "    #r.encoding\n",
    "    #print(r.encoding)\n",
    "    #r = r.content.decode('utf-8','ignore')\n",
    "   # print(r.encoding)\n",
    "    #return r\n",
    "    return r.text\n",
    "\n",
    "def write_csv(data):\n",
    "    with open('garf_6.csv', 'a') as f:\n",
    "        writer = csv.writer(f)\n",
    "        \n",
    "        writer.writerow((data['familia'],\n",
    "                                    data['name'],\n",
    "                                    data['otch'],\n",
    "                                    data['together'],\n",
    "                                    data['nomer_dela'],\n",
    "                                    data['deloproizvod_nomer'],\n",
    "                                    data['krainie_dat'],\n",
    "                                    data['primechania'],\n",
    "                                    data['url'],))\n",
    "\n",
    "def get_page_data(html):\n",
    "    soup = BeautifulSoup(html, 'lxml', fromEncoding='utf-8')\n",
    "    #print(soup)\n",
    "    \n",
    "    #ads = soup.find('table', class_ = 'views-view-grid cols-4').find_all('div', class_ = 'views-field views-field-name')\n",
    "    #ads = soup.find_all('td')[6]#.find_all('p')\n",
    "    ads = soup.find_all('font', class_ = 'black')##[8]#.text.split()[4:7]\n",
    "    #print(ads)\n",
    "    \n",
    "    #for ad in ads:\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        familia = ads[6].text.split()[4]\n",
    "    except IndexError:\n",
    "        familia = 'NaN'\n",
    "        #except:\n",
    "            #familia = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        name = ads[6].text.split()[5]\n",
    "    except IndexError:\n",
    "        name = 'NaN'\n",
    "        #except:\n",
    "            #name = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        otch = ads[6].text.split()[6]\n",
    "    except IndexError:\n",
    "        otch = 'NaN'\n",
    "    #otch = ads[6].text.split()[6]\n",
    "        #except:\n",
    "            #otch = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    #together =  str(ads[6].text.split()[4:7]).strip('[]')\n",
    "    try:\n",
    "        together =  ' '.join(map(str, ads[6].text.split()[4:7]))\n",
    "    except IndexError:\n",
    "        together = 'NaN'\n",
    "    #together = print('  '.join(mylist)ads[6].text.split()[4:7])\n",
    "        #except:\n",
    "            #together = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        nomer_dela = ads[0].text.split()[0]\n",
    "    except IndexError:\n",
    "        nomer_dela = 'NaN'\n",
    "        #except:\n",
    "            #nomer_dela = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        deloproizvod_nomer = ads[1].text.split()[0]\n",
    "    except IndexError:\n",
    "        deloproizvod_nomer = 'NaN'\n",
    "        #except:\n",
    "            #deloproizvod_nomer = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        krainie_dat =  ' '.join(map(str, ads[8].text.split()))#[0]\n",
    "    except IndexError:\n",
    "        krainie_dat = 'NaN'\n",
    "        #except:\n",
    "            #krainie_dat = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        primechania = ' '.join(map(str, ads[10].text.split()))#[0]\n",
    "    except IndexError:\n",
    "        primechania = 'NaN'\n",
    "        #except:\n",
    "            #primechania = ' '\n",
    "        #try:\n",
    "    try:\n",
    "        url =  \"http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447449&fond=3236&opis=6068&delo=5046656\"\n",
    "    except IndexError:\n",
    "        url = 'NaN'\n",
    "            #url = 'http://1937god.info'+ ad.find('span', class_='field-content').find('a').get('href')\n",
    "        #except:\n",
    "            #url = ' '\n",
    "            \n",
    "    data = {'familia':familia,\n",
    "                    'name':name,\n",
    "                    'otch':otch,\n",
    "                    'together':together,\n",
    "                    'nomer_dela':nomer_dela,\n",
    "                    'deloproizvod_nomer':deloproizvod_nomer,\n",
    "                    'krainie_dat':krainie_dat,\n",
    "                    'primechania':primechania,\n",
    "                    'url':url}\n",
    "    write_csv(data)\n",
    "    #print(data)\n",
    "    #print(len(ads))\n",
    "    \n",
    "def main ():\n",
    "    url = \"http://1937god.info/persons?page=1\"\n",
    "    url_2 = \"http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447449&fond=3236&opis=6068&delo=5046656\"\n",
    "    url_3 = \"http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447446&fond=3236&opis=6068&delo=5056299\"\n",
    "    base_url = 'http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447446&fond=3236&opis=6068&delo=50'\n",
    "    #base_url = 'http://1937god.info/persons?'\n",
    "    page_part = 'page='\n",
    "    \n",
    "    #total_pages = get_total_pages(get_html(url))\n",
    "    \n",
    "    for i in range(46656, 56300):\n",
    "    #for i in range(37188, 37193):\n",
    "        #if i == 29833 or i == 29835 or i == 29840 or i == 29841 or i == 29849:\n",
    "            #continue\n",
    "        #url_gen = base_url + page_part + str(i)\n",
    "        #print(url_gen)\n",
    "        #html = get_html(url_gen)\n",
    "        url_2 = base_url + str(i)\n",
    "        #print(url_2)\n",
    "        html = get_html(url_2)\n",
    "        #print(html)\n",
    "        get_page_data(html)\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    \n",
    "#Soup = BeautifulSoup(r.content.decode('utf-8','ignore'),\"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "data_6 = pd.read_csv(\"C:\\\\Users\\\\User\\\\PycharmProjects\\\\garf_6.csv\", engine ='python',names= ['familia', 'name','otch', 'together','nomer_dela', 'deloproizvod_nomer','krainie_dat', 'primechania', 'url'])\n",
    "pd.DataFrame.to_csv(data_6, 'garf_66.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7 опись ГАРФ\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv\n",
    "#План:\n",
    "    #1. выяснить количество страниц\n",
    "    #2. Сформировать список урлов на страницу выдачи \n",
    "    #3. Собрать данные\n",
    "def get_html(url_2):\n",
    "    r = requests.get(url_2)\n",
    "    #r.encoding = 'UTF-8'\n",
    "    #r.encoding = 'cp1252'\n",
    "    #type(r.content)\n",
    "    #type(r.text)\n",
    "    #r.headers['Content-Type']\n",
    "    #r.encoding\n",
    "    #print(r.encoding)\n",
    "    #r = r.content.decode('utf-8','ignore')\n",
    "   # print(r.encoding)\n",
    "    #return r\n",
    "    return r.text\n",
    "\n",
    "def write_csv(data):\n",
    "    with open('garf_7.csv', 'a') as f:\n",
    "        writer = csv.writer(f)\n",
    "        \n",
    "        writer.writerow((data['familia'],\n",
    "                                    data['name'],\n",
    "                                    data['otch'],\n",
    "                                    data['together'],\n",
    "                                    data['nomer_dela'],\n",
    "                                    data['deloproizvod_nomer'],\n",
    "                                    data['krainie_dat'],\n",
    "                                    data['primechania'],\n",
    "                                    data['url'],))\n",
    "\n",
    "def get_page_data(html):\n",
    "    soup = BeautifulSoup(html, 'lxml', fromEncoding='utf-8')\n",
    "    #print(soup)\n",
    "    \n",
    "    #ads = soup.find('table', class_ = 'views-view-grid cols-4').find_all('div', class_ = 'views-field views-field-name')\n",
    "    #ads = soup.find_all('td')[6]#.find_all('p')\n",
    "    ads = soup.find_all('font', class_ = 'black')##[8]#.text.split()[4:7]\n",
    "    #print(ads)\n",
    "    \n",
    "    #for ad in ads:\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        familia = ads[6].text.split()[4]\n",
    "    except IndexError:\n",
    "        familia = 'NaN'\n",
    "        #except:\n",
    "            #familia = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        name = ads[6].text.split()[5]\n",
    "    except IndexError:\n",
    "        name = 'NaN'\n",
    "        #except:\n",
    "            #name = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        otch = ads[6].text.split()[6]\n",
    "    except IndexError:\n",
    "        otch = 'NaN'\n",
    "    #otch = ads[6].text.split()[6]\n",
    "        #except:\n",
    "            #otch = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    #together =  str(ads[6].text.split()[4:7]).strip('[]')\n",
    "    try:\n",
    "        together =  ' '.join(map(str, ads[6].text.split()[4:7]))\n",
    "    except IndexError:\n",
    "        together = 'NaN'\n",
    "    #together = print('  '.join(mylist)ads[6].text.split()[4:7])\n",
    "        #except:\n",
    "            #together = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        nomer_dela = ads[0].text.split()[0]\n",
    "    except IndexError:\n",
    "        nomer_dela = 'NaN'\n",
    "        #except:\n",
    "            #nomer_dela = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        deloproizvod_nomer = ads[1].text.split()[0]\n",
    "    except IndexError:\n",
    "        deloproizvod_nomer = 'NaN'\n",
    "        #except:\n",
    "            #deloproizvod_nomer = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        krainie_dat =  ' '.join(map(str, ads[8].text.split()))#[0]\n",
    "    except IndexError:\n",
    "        krainie_dat = 'NaN'\n",
    "        #except:\n",
    "            #krainie_dat = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        primechania = ' '.join(map(str, ads[10].text.split()))#[0]\n",
    "    except IndexError:\n",
    "        primechania = 'NaN'\n",
    "        #except:\n",
    "            #primechania = ' '\n",
    "        #try:\n",
    "    try:\n",
    "        url =  \"http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447215&fond=3236&opis=6065&delo=5029718\"\n",
    "    except IndexError:\n",
    "        url = 'NaN'\n",
    "            #url = 'http://1937god.info'+ ad.find('span', class_='field-content').find('a').get('href')\n",
    "        #except:\n",
    "            #url = ' '\n",
    "            \n",
    "    data = {'familia':familia,\n",
    "                    'name':name,\n",
    "                    'otch':otch,\n",
    "                    'together':together,\n",
    "                    'nomer_dela':nomer_dela,\n",
    "                    'deloproizvod_nomer':deloproizvod_nomer,\n",
    "                    'krainie_dat':krainie_dat,\n",
    "                    'primechania':primechania,\n",
    "                    'url':url}\n",
    "    write_csv(data)\n",
    "    #print(data)\n",
    "    #print(len(ads))\n",
    "    \n",
    "def main ():\n",
    "    url = \"http://1937god.info/persons?page=1\"\n",
    "    url_2 = \"http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447450&fond=3236&opis=6069&delo=5056300\"\n",
    "    url_3 = \"http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447451&fond=3236&opis=6069&delo=5066504\"\n",
    "    base_url = 'http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447451&fond=3236&opis=6069&delo=50'\n",
    "    #base_url = 'http://1937god.info/persons?'\n",
    "    page_part = 'page='\n",
    "    \n",
    "    #total_pages = get_total_pages(get_html(url))\n",
    "    \n",
    "    for i in range(56300, 66505):\n",
    "    #for i in range(37188, 37193):\n",
    "        #if i == 29833 or i == 29835 or i == 29840 or i == 29841 or i == 29849:\n",
    "            #continue\n",
    "        #url_gen = base_url + page_part + str(i)\n",
    "        #print(url_gen)\n",
    "        #html = get_html(url_gen)\n",
    "        url_2 = base_url + str(i)\n",
    "        #print(url_2)\n",
    "        html = get_html(url_2)\n",
    "        #print(html)\n",
    "        get_page_data(html)\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    \n",
    "#Soup = BeautifulSoup(r.content.decode('utf-8','ignore'),\"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "data_7 = pd.read_csv(\"C:\\\\Users\\\\User\\\\PycharmProjects\\\\garf_7.csv\", engine ='python',names= ['familia', 'name','otch', 'together','nomer_dela', 'deloproizvod_nomer','krainie_dat', 'primechania', 'url'])\n",
    "pd.DataFrame.to_csv(data_7, 'garf_77.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8 опись ГАРФ\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv\n",
    "#План:\n",
    "    #1. выяснить количество страниц\n",
    "    #2. Сформировать список урлов на страницу выдачи \n",
    "    #3. Собрать данные\n",
    "def get_html(url_2):\n",
    "    r = requests.get(url_2)\n",
    "    #r.encoding = 'UTF-8'\n",
    "    #r.encoding = 'cp1252'\n",
    "    #type(r.content)\n",
    "    #type(r.text)\n",
    "    #r.headers['Content-Type']\n",
    "    #r.encoding\n",
    "    #print(r.encoding)\n",
    "    #r = r.content.decode('utf-8','ignore')\n",
    "   # print(r.encoding)\n",
    "    #return r\n",
    "    return r.text\n",
    "\n",
    "def write_csv(data):\n",
    "    with open('garf_8.csv', 'a') as f:\n",
    "        writer = csv.writer(f)\n",
    "        \n",
    "        writer.writerow((data['familia'],\n",
    "                                    data['name'],\n",
    "                                    data['otch'],\n",
    "                                    data['together'],\n",
    "                                    data['nomer_dela'],\n",
    "                                    data['deloproizvod_nomer'],\n",
    "                                    data['krainie_dat'],\n",
    "                                    data['primechania'],\n",
    "                                    data['url'],))\n",
    "\n",
    "def get_page_data(html):\n",
    "    soup = BeautifulSoup(html, 'lxml', fromEncoding='utf-8')\n",
    "    #print(soup)\n",
    "    \n",
    "    #ads = soup.find('table', class_ = 'views-view-grid cols-4').find_all('div', class_ = 'views-field views-field-name')\n",
    "    #ads = soup.find_all('td')[6]#.find_all('p')\n",
    "    ads = soup.find_all('font', class_ = 'black')##[8]#.text.split()[4:7]\n",
    "    #print(ads)\n",
    "    \n",
    "    #for ad in ads:\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        familia = ads[6].text.split()[4]\n",
    "    except IndexError:\n",
    "        familia = 'NaN'\n",
    "        #except:\n",
    "            #familia = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        name = ads[6].text.split()[5]\n",
    "    except IndexError:\n",
    "        name = 'NaN'\n",
    "        #except:\n",
    "            #name = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        otch = ads[6].text.split()[6]\n",
    "    except IndexError:\n",
    "        otch = 'NaN'\n",
    "    #otch = ads[6].text.split()[6]\n",
    "        #except:\n",
    "            #otch = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    #together =  str(ads[6].text.split()[4:7]).strip('[]')\n",
    "    try:\n",
    "        together =  ' '.join(map(str, ads[6].text.split()[4:7]))\n",
    "    except IndexError:\n",
    "        together = 'NaN'\n",
    "    #together = print('  '.join(mylist)ads[6].text.split()[4:7])\n",
    "        #except:\n",
    "            #together = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        nomer_dela = ads[0].text.split()[0]\n",
    "    except IndexError:\n",
    "        nomer_dela = 'NaN'\n",
    "        #except:\n",
    "            #nomer_dela = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        deloproizvod_nomer = ads[1].text.split()[0]\n",
    "    except IndexError:\n",
    "        deloproizvod_nomer = 'NaN'\n",
    "        #except:\n",
    "            #deloproizvod_nomer = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        krainie_dat =  ' '.join(map(str, ads[8].text.split()))#[0]\n",
    "    except IndexError:\n",
    "        krainie_dat = 'NaN'\n",
    "        #except:\n",
    "            #krainie_dat = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        primechania = ' '.join(map(str, ads[10].text.split()))#[0]\n",
    "    except IndexError:\n",
    "        primechania = 'NaN'\n",
    "        #except:\n",
    "            #primechania = ' '\n",
    "        #try:\n",
    "    try:\n",
    "        url =  \"http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447215&fond=3236&opis=6065&delo=5029718\"\n",
    "    except IndexError:\n",
    "        url = 'NaN'\n",
    "            #url = 'http://1937god.info'+ ad.find('span', class_='field-content').find('a').get('href')\n",
    "        #except:\n",
    "            #url = ' '\n",
    "            \n",
    "    data = {'familia':familia,\n",
    "                    'name':name,\n",
    "                    'otch':otch,\n",
    "                    'together':together,\n",
    "                    'nomer_dela':nomer_dela,\n",
    "                    'deloproizvod_nomer':deloproizvod_nomer,\n",
    "                    'krainie_dat':krainie_dat,\n",
    "                    'primechania':primechania,\n",
    "                    'url':url}\n",
    "    write_csv(data)\n",
    "    #print(data)\n",
    "    #print(len(ads))\n",
    "    \n",
    "def main ():\n",
    "    url = \"http://1937god.info/persons?page=1\"\n",
    "    url_2 = \"http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447453&fond=3236&opis=6070&delo=5066505\"\n",
    "    url_3 = \"http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447456&fond=3236&opis=6070&delo=5077050\"\n",
    "    base_url = 'http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447456&fond=3236&opis=6070&delo=50'\n",
    "    #base_url = 'http://1937god.info/persons?'\n",
    "    page_part = 'page='\n",
    "    \n",
    "    #total_pages = get_total_pages(get_html(url))\n",
    "    \n",
    "    for i in range(66505, 77051):\n",
    "    #for i in range(37188, 37193):\n",
    "        #if i == 29833 or i == 29835 or i == 29840 or i == 29841 or i == 29849:\n",
    "            #continue\n",
    "        #url_gen = base_url + page_part + str(i)\n",
    "        #print(url_gen)\n",
    "        #html = get_html(url_gen)\n",
    "        url_2 = base_url + str(i)\n",
    "        #print(url_2)\n",
    "        html = get_html(url_2)\n",
    "        #print(html)\n",
    "        get_page_data(html)\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    \n",
    "#Soup = BeautifulSoup(r.content.decode('utf-8','ignore'),\"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "data_8 = pd.read_csv(\"C:\\\\Users\\\\User\\\\PycharmProjects\\\\garf_8.csv\", engine ='python',names= ['familia', 'name','otch', 'together','nomer_dela', 'deloproizvod_nomer','krainie_dat', 'primechania', 'url'])\n",
    "pd.DataFrame.to_csv(data_8, 'garf_88.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9 опись ГАРФ\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv\n",
    "#План:\n",
    "    #1. выяснить количество страниц\n",
    "    #2. Сформировать список урлов на страницу выдачи \n",
    "    #3. Собрать данные\n",
    "def get_html(url_2):\n",
    "    r = requests.get(url_2)\n",
    "    #r.encoding = 'UTF-8'\n",
    "    #r.encoding = 'cp1252'\n",
    "    #type(r.content)\n",
    "    #type(r.text)\n",
    "    #r.headers['Content-Type']\n",
    "    #r.encoding\n",
    "    #print(r.encoding)\n",
    "    #r = r.content.decode('utf-8','ignore')\n",
    "   # print(r.encoding)\n",
    "    #return r\n",
    "    return r.text\n",
    "\n",
    "def write_csv(data):\n",
    "    with open('garf_9.csv', 'a') as f:\n",
    "        writer = csv.writer(f)\n",
    "        \n",
    "        writer.writerow((data['familia'],\n",
    "                                    data['name'],\n",
    "                                    data['otch'],\n",
    "                                    data['together'],\n",
    "                                    data['nomer_dela'],\n",
    "                                    data['deloproizvod_nomer'],\n",
    "                                    data['krainie_dat'],\n",
    "                                    data['primechania'],\n",
    "                                    data['url'],))\n",
    "\n",
    "def get_page_data(html):\n",
    "    soup = BeautifulSoup(html, 'lxml', fromEncoding='utf-8')\n",
    "    #print(soup)\n",
    "    \n",
    "    #ads = soup.find('table', class_ = 'views-view-grid cols-4').find_all('div', class_ = 'views-field views-field-name')\n",
    "    #ads = soup.find_all('td')[6]#.find_all('p')\n",
    "    ads = soup.find_all('font', class_ = 'black')##[8]#.text.split()[4:7]\n",
    "    #print(ads)\n",
    "    \n",
    "    #for ad in ads:\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        familia = ads[6].text.split()[4]\n",
    "    except IndexError:\n",
    "        familia = 'NaN'\n",
    "        #except:\n",
    "            #familia = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        name = ads[6].text.split()[5]\n",
    "    except IndexError:\n",
    "        name = 'NaN'\n",
    "        #except:\n",
    "            #name = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        otch = ads[6].text.split()[6]\n",
    "    except IndexError:\n",
    "        otch = 'NaN'\n",
    "    #otch = ads[6].text.split()[6]\n",
    "        #except:\n",
    "            #otch = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    #together =  str(ads[6].text.split()[4:7]).strip('[]')\n",
    "    try:\n",
    "        together =  ' '.join(map(str, ads[6].text.split()[4:7]))\n",
    "    except IndexError:\n",
    "        together = 'NaN'\n",
    "    #together = print('  '.join(mylist)ads[6].text.split()[4:7])\n",
    "        #except:\n",
    "            #together = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        nomer_dela = ads[0].text.split()[0]\n",
    "    except IndexError:\n",
    "        nomer_dela = 'NaN'\n",
    "        #except:\n",
    "            #nomer_dela = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        deloproizvod_nomer = ads[1].text.split()[0]\n",
    "    except IndexError:\n",
    "        deloproizvod_nomer = 'NaN'\n",
    "        #except:\n",
    "            #deloproizvod_nomer = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        krainie_dat =  ' '.join(map(str, ads[8].text.split()))#[0]\n",
    "    except IndexError:\n",
    "        krainie_dat = 'NaN'\n",
    "        #except:\n",
    "            #krainie_dat = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        primechania = ' '.join(map(str, ads[10].text.split()))#[0]\n",
    "    except IndexError:\n",
    "        primechania = 'NaN'\n",
    "        #except:\n",
    "            #primechania = ' '\n",
    "        #try:\n",
    "    try:\n",
    "        url =  \"http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447215&fond=3236&opis=6065&delo=5029718\"\n",
    "    except IndexError:\n",
    "        url = 'NaN'\n",
    "            #url = 'http://1937god.info'+ ad.find('span', class_='field-content').find('a').get('href')\n",
    "        #except:\n",
    "            #url = ' '\n",
    "            \n",
    "    data = {'familia':familia,\n",
    "                    'name':name,\n",
    "                    'otch':otch,\n",
    "                    'together':together,\n",
    "                    'nomer_dela':nomer_dela,\n",
    "                    'deloproizvod_nomer':deloproizvod_nomer,\n",
    "                    'krainie_dat':krainie_dat,\n",
    "                    'primechania':primechania,\n",
    "                    'url':url}\n",
    "    write_csv(data)\n",
    "    #print(data)\n",
    "    #print(len(ads))\n",
    "    \n",
    "def main ():\n",
    "    url = \"http://1937god.info/persons?page=1\"\n",
    "    url_2 = \"http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447458&fond=3236&opis=6071&delo=5077051\"\n",
    "    url_3 = \"http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447461&fond=3236&opis=6071&delo=5087416\"\n",
    "    base_url = 'http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447458&fond=3236&opis=6071&delo=50'\n",
    "    #base_url = 'http://1937god.info/persons?'\n",
    "    page_part = 'page='\n",
    "    \n",
    "    #total_pages = get_total_pages(get_html(url))\n",
    "    \n",
    "    for i in range(77051, 87417):\n",
    "    #for i in range(37188, 37193):\n",
    "        #if i == 29833 or i == 29835 or i == 29840 or i == 29841 or i == 29849:\n",
    "            #continue\n",
    "        #url_gen = base_url + page_part + str(i)\n",
    "        #print(url_gen)\n",
    "        #html = get_html(url_gen)\n",
    "        url_2 = base_url + str(i)\n",
    "        #print(url_2)\n",
    "        html = get_html(url_2)\n",
    "        #print(html)\n",
    "        get_page_data(html)\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    \n",
    "#Soup = BeautifulSoup(r.content.decode('utf-8','ignore'),\"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "data_9 = pd.read_csv(\"C:\\\\Users\\\\User\\\\PycharmProjects\\\\garf_9.csv\", engine ='python',names= ['familia', 'name','otch', 'together','nomer_dela', 'deloproizvod_nomer','krainie_dat', 'primechania', 'url'])\n",
    "pd.DataFrame.to_csv(data_9, 'garf_99.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10 опись ГАРФ\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv\n",
    "#План:\n",
    "    #1. выяснить количество страниц\n",
    "    #2. Сформировать список урлов на страницу выдачи \n",
    "    #3. Собрать данные\n",
    "def get_html(url_2):\n",
    "    r = requests.get(url_2)\n",
    "    #r.encoding = 'UTF-8'\n",
    "    #r.encoding = 'cp1252'\n",
    "    #type(r.content)\n",
    "    #type(r.text)\n",
    "    #r.headers['Content-Type']\n",
    "    #r.encoding\n",
    "    #print(r.encoding)\n",
    "    #r = r.content.decode('utf-8','ignore')\n",
    "   # print(r.encoding)\n",
    "    #return r\n",
    "    return r.text\n",
    "\n",
    "def write_csv(data):\n",
    "    with open('garf_10.csv', 'a') as f:\n",
    "        writer = csv.writer(f)\n",
    "        \n",
    "        writer.writerow((data['familia'],\n",
    "                                    data['name'],\n",
    "                                    data['otch'],\n",
    "                                    data['together'],\n",
    "                                    data['nomer_dela'],\n",
    "                                    data['deloproizvod_nomer'],\n",
    "                                    data['krainie_dat'],\n",
    "                                    data['primechania'],\n",
    "                                    data['url'],))\n",
    "\n",
    "def get_page_data(html):\n",
    "    soup = BeautifulSoup(html, 'lxml', fromEncoding='utf-8')\n",
    "    #print(soup)\n",
    "    \n",
    "    #ads = soup.find('table', class_ = 'views-view-grid cols-4').find_all('div', class_ = 'views-field views-field-name')\n",
    "    #ads = soup.find_all('td')[6]#.find_all('p')\n",
    "    ads = soup.find_all('font', class_ = 'black')##[8]#.text.split()[4:7]\n",
    "    #print(ads)\n",
    "    \n",
    "    #for ad in ads:\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        familia = ads[6].text.split()[4]\n",
    "    except IndexError:\n",
    "        familia = 'NaN'\n",
    "        #except:\n",
    "            #familia = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        name = ads[6].text.split()[5]\n",
    "    except IndexError:\n",
    "        name = 'NaN'\n",
    "        #except:\n",
    "            #name = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        otch = ads[6].text.split()[6]\n",
    "    except IndexError:\n",
    "        otch = 'NaN'\n",
    "    #otch = ads[6].text.split()[6]\n",
    "        #except:\n",
    "            #otch = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    #together =  str(ads[6].text.split()[4:7]).strip('[]')\n",
    "    try:\n",
    "        together =  ' '.join(map(str, ads[6].text.split()[4:7]))\n",
    "    except IndexError:\n",
    "        together = 'NaN'\n",
    "    #together = print('  '.join(mylist)ads[6].text.split()[4:7])\n",
    "        #except:\n",
    "            #together = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        nomer_dela = ads[0].text.split()[0]\n",
    "    except IndexError:\n",
    "        nomer_dela = 'NaN'\n",
    "        #except:\n",
    "            #nomer_dela = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        deloproizvod_nomer = ads[1].text.split()[0]\n",
    "    except IndexError:\n",
    "        deloproizvod_nomer = 'NaN'\n",
    "        #except:\n",
    "            #deloproizvod_nomer = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        krainie_dat =  ' '.join(map(str, ads[8].text.split()))#[0]\n",
    "    except IndexError:\n",
    "        krainie_dat = 'NaN'\n",
    "        #except:\n",
    "            #krainie_dat = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        primechania = ' '.join(map(str, ads[10].text.split()))#[0]\n",
    "    except IndexError:\n",
    "        primechania = 'NaN'\n",
    "        #except:\n",
    "            #primechania = ' '\n",
    "        #try:\n",
    "    try:\n",
    "        url =  \"http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447215&fond=3236&opis=6065&delo=5029718\"\n",
    "    except IndexError:\n",
    "        url = 'NaN'\n",
    "            #url = 'http://1937god.info'+ ad.find('span', class_='field-content').find('a').get('href')\n",
    "        #except:\n",
    "            #url = ' '\n",
    "            \n",
    "    data = {'familia':familia,\n",
    "                    'name':name,\n",
    "                    'otch':otch,\n",
    "                    'together':together,\n",
    "                    'nomer_dela':nomer_dela,\n",
    "                    'deloproizvod_nomer':deloproizvod_nomer,\n",
    "                    'krainie_dat':krainie_dat,\n",
    "                    'primechania':primechania,\n",
    "                    'url':url}\n",
    "    write_csv(data)\n",
    "    #print(data)\n",
    "    #print(len(ads))\n",
    "    \n",
    "def main ():\n",
    "    url = \"http://1937god.info/persons?page=1\"\n",
    "    url_2 = \"http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447462&fond=3236&opis=6072&delo=5087417\"\n",
    "    url_3 = \"http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447465&fond=3236&opis=6072&delo=5097393\"\n",
    "    base_url = 'http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447462&fond=3236&opis=6072&delo=50'\n",
    "    #base_url = 'http://1937god.info/persons?'\n",
    "    page_part = 'page='\n",
    "    \n",
    "    #total_pages = get_total_pages(get_html(url))\n",
    "    \n",
    "    for i in range(87417, 97393):\n",
    "    #for i in range(37188, 37193):\n",
    "        #if i == 29833 or i == 29835 or i == 29840 or i == 29841 or i == 29849:\n",
    "            #continue\n",
    "        #url_gen = base_url + page_part + str(i)\n",
    "        #print(url_gen)\n",
    "        #html = get_html(url_gen)\n",
    "        url_2 = base_url + str(i)\n",
    "        #print(url_2)\n",
    "        html = get_html(url_2)\n",
    "        #print(html)\n",
    "        get_page_data(html)\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    \n",
    "#Soup = BeautifulSoup(r.content.decode('utf-8','ignore'),\"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "data_10 = pd.read_csv(\"C:\\\\Users\\\\User\\\\PycharmProjects\\\\garf_10.csv\", engine ='python',names= ['familia', 'name','otch', 'together','nomer_dela', 'deloproizvod_nomer','krainie_dat', 'primechania', 'url'])\n",
    "pd.DataFrame.to_csv(data_10, 'garf_1010.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#11 опись ГАРФ\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv\n",
    "#План:\n",
    "    #1. выяснить количество страниц\n",
    "    #2. Сформировать список урлов на страницу выдачи \n",
    "    #3. Собрать данные\n",
    "def get_html(url_2):\n",
    "    r = requests.get(url_2)\n",
    "    #r.encoding = 'UTF-8'\n",
    "    #r.encoding = 'cp1252'\n",
    "    #type(r.content)\n",
    "    #type(r.text)\n",
    "    #r.headers['Content-Type']\n",
    "    #r.encoding\n",
    "    #print(r.encoding)\n",
    "    #r = r.content.decode('utf-8','ignore')\n",
    "   # print(r.encoding)\n",
    "    #return r\n",
    "    return r.text\n",
    "\n",
    "def write_csv(data):\n",
    "    with open('garf_11_2.csv', 'a') as f:\n",
    "        writer = csv.writer(f)\n",
    "        \n",
    "        writer.writerow((data['familia'],\n",
    "                                    data['name'],\n",
    "                                    data['otch'],\n",
    "                                    data['together'],\n",
    "                                    data['nomer_dela'],\n",
    "                                    data['deloproizvod_nomer'],\n",
    "                                    data['krainie_dat'],\n",
    "                                    data['primechania'],\n",
    "                                    data['url'],))\n",
    "\n",
    "def get_page_data(html):\n",
    "    soup = BeautifulSoup(html, 'lxml', fromEncoding='utf-8')\n",
    "    #print(soup)\n",
    "    \n",
    "    #ads = soup.find('table', class_ = 'views-view-grid cols-4').find_all('div', class_ = 'views-field views-field-name')\n",
    "    #ads = soup.find_all('td')[6]#.find_all('p')\n",
    "    ads = soup.find_all('font', class_ = 'black')##[8]#.text.split()[4:7]\n",
    "    #print(ads)\n",
    "    \n",
    "    #for ad in ads:\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        familia = ads[6].text.split()[4]\n",
    "    except IndexError:\n",
    "        familia = 'NaN'\n",
    "        #except:\n",
    "            #familia = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        name = ads[6].text.split()[5]\n",
    "    except IndexError:\n",
    "        name = 'NaN'\n",
    "        #except:\n",
    "            #name = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        otch = ads[6].text.split()[6]\n",
    "    except IndexError:\n",
    "        otch = 'NaN'\n",
    "    #otch = ads[6].text.split()[6]\n",
    "        #except:\n",
    "            #otch = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    #together =  str(ads[6].text.split()[4:7]).strip('[]')\n",
    "    try:\n",
    "        together =  ' '.join(map(str, ads[6].text.split()[4:7]))\n",
    "    except IndexError:\n",
    "        together = 'NaN'\n",
    "    #together = print('  '.join(mylist)ads[6].text.split()[4:7])\n",
    "        #except:\n",
    "            #together = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        nomer_dela = ads[0].text.split()[0]\n",
    "    except IndexError:\n",
    "        nomer_dela = 'NaN'\n",
    "        #except:\n",
    "            #nomer_dela = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        deloproizvod_nomer = ads[1].text.split()[0]\n",
    "    except IndexError:\n",
    "        deloproizvod_nomer = 'NaN'\n",
    "        #except:\n",
    "            #deloproizvod_nomer = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        krainie_dat =  ' '.join(map(str, ads[8].text.split()))#[0]\n",
    "    except IndexError:\n",
    "        krainie_dat = 'NaN'\n",
    "        #except:\n",
    "            #krainie_dat = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        primechania = ' '.join(map(str, ads[10].text.split()))#[0]\n",
    "    except IndexError:\n",
    "        primechania = 'NaN'\n",
    "        #except:\n",
    "            #primechania = ' '\n",
    "        #try:\n",
    "    try:\n",
    "        url =  \"http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447215&fond=3236&opis=6065&delo=5029718\"\n",
    "    except IndexError:\n",
    "        url = 'NaN'\n",
    "            #url = 'http://1937god.info'+ ad.find('span', class_='field-content').find('a').get('href')\n",
    "        #except:\n",
    "            #url = ' '\n",
    "            \n",
    "    data = {'familia':familia,\n",
    "                    'name':name,\n",
    "                    'otch':otch,\n",
    "                    'together':together,\n",
    "                    'nomer_dela':nomer_dela,\n",
    "                    'deloproizvod_nomer':deloproizvod_nomer,\n",
    "                    'krainie_dat':krainie_dat,\n",
    "                    'primechania':primechania,\n",
    "                    'url':url}\n",
    "    write_csv(data)\n",
    "    #print(data)\n",
    "    #print(len(ads))\n",
    "    \n",
    "def main ():\n",
    "    url = \"http://1937god.info/persons?page=1\"\n",
    "    url_2 = \"http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447466&fond=3236&opis=6073&delo=5097394\"\n",
    "    url_3 = \"http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447468&fond=3236&opis=6073&delo=5107830\"\n",
    "    base_url = 'http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447466&fond=3236&opis=6073&delo=5'\n",
    "    base_url_1 = 'http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447466&fond=3236&opis=6073&delo=50'\n",
    "    #base_url = 'http://1937god.info/persons?'\n",
    "    page_part = 'page='\n",
    "    \n",
    "    #total_pages = get_total_pages(get_html(url))\n",
    "    \n",
    "    for i in range(97394, 107830):\n",
    "        if i < 100000:\n",
    "            url_2 = base_url_1 + str(i)\n",
    "        else:\n",
    "    #for i in range(37188, 37193):\n",
    "        #if i == 29833 or i == 29835 or i == 29840 or i == 29841 or i == 29849:\n",
    "            #continue\n",
    "        #url_gen = base_url + page_part + str(i)\n",
    "        #print(url_gen)\n",
    "        #html = get_html(url_gen)\n",
    "            url_2 = base_url + str(i)\n",
    "        #print(url_2)\n",
    "        html = get_html(url_2)\n",
    "        #print(html)\n",
    "        get_page_data(html)\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    \n",
    "#Soup = BeautifulSoup(r.content.decode('utf-8','ignore'),\"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "data_11 = pd.read_csv(\"C:\\\\Users\\\\User\\\\PycharmProjects\\\\garf_11_2.csv\", engine ='python',names= ['familia', 'name','otch', 'together','nomer_dela', 'deloproizvod_nomer','krainie_dat', 'primechania', 'url'])\n",
    "pd.DataFrame.to_csv(data_11, 'garf_1111.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "#12 опись ГАРФ\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv\n",
    "#План:\n",
    "    #1. выяснить количество страниц\n",
    "    #2. Сформировать список урлов на страницу выдачи \n",
    "    #3. Собрать данные\n",
    "def get_html(url_2):\n",
    "    r = requests.get(url_2)\n",
    "    #r.encoding = 'UTF-8'\n",
    "    #r.encoding = 'cp1252'\n",
    "    #type(r.content)\n",
    "    #type(r.text)\n",
    "    #r.headers['Content-Type']\n",
    "    #r.encoding\n",
    "    #print(r.encoding)\n",
    "    #r = r.content.decode('utf-8','ignore')\n",
    "   # print(r.encoding)\n",
    "    #return r\n",
    "    return r.text\n",
    "\n",
    "def write_csv(data):\n",
    "    with open('garf_12.csv', 'a') as f:\n",
    "        writer = csv.writer(f)\n",
    "        \n",
    "        writer.writerow((data['familia'],\n",
    "                                    data['name'],\n",
    "                                    data['otch'],\n",
    "                                    data['together'],\n",
    "                                    data['nomer_dela'],\n",
    "                                    data['deloproizvod_nomer'],\n",
    "                                    data['krainie_dat'],\n",
    "                                    data['primechania'],\n",
    "                                    data['url'],))\n",
    "\n",
    "def get_page_data(html):\n",
    "    soup = BeautifulSoup(html, 'lxml', fromEncoding='utf-8')\n",
    "    #print(soup)\n",
    "    \n",
    "    #ads = soup.find('table', class_ = 'views-view-grid cols-4').find_all('div', class_ = 'views-field views-field-name')\n",
    "    #ads = soup.find_all('td')[6]#.find_all('p')\n",
    "    ads = soup.find_all('font', class_ = 'black')##[8]#.text.split()[4:7]\n",
    "    #print(ads)\n",
    "    \n",
    "    #for ad in ads:\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        familia = ads[6].text.split()[4]\n",
    "    except IndexError:\n",
    "        familia = 'NaN'\n",
    "        #except:\n",
    "            #familia = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        name = ads[6].text.split()[5]\n",
    "    except IndexError:\n",
    "        name = 'NaN'\n",
    "        #except:\n",
    "            #name = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        otch = ads[6].text.split()[6]\n",
    "    except IndexError:\n",
    "        otch = 'NaN'\n",
    "    #otch = ads[6].text.split()[6]\n",
    "        #except:\n",
    "            #otch = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    #together =  str(ads[6].text.split()[4:7]).strip('[]')\n",
    "    try:\n",
    "        together =  ' '.join(map(str, ads[6].text.split()[4:7]))\n",
    "    except IndexError:\n",
    "        together = 'NaN'\n",
    "    #together = print('  '.join(mylist)ads[6].text.split()[4:7])\n",
    "        #except:\n",
    "            #together = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        nomer_dela = ads[0].text.split()[0]\n",
    "    except IndexError:\n",
    "        nomer_dela = 'NaN'\n",
    "        #except:\n",
    "            #nomer_dela = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        deloproizvod_nomer = ads[1].text.split()[0]\n",
    "    except IndexError:\n",
    "        deloproizvod_nomer = 'NaN'\n",
    "        #except:\n",
    "            #deloproizvod_nomer = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        krainie_dat =  ' '.join(map(str, ads[8].text.split()))#[0]\n",
    "    except IndexError:\n",
    "        krainie_dat = 'NaN'\n",
    "        #except:\n",
    "            #krainie_dat = ' '\n",
    "        #try:\n",
    "            #title = ad.find('span', class_='field-content').find('a').text.strip()\n",
    "    try:\n",
    "        primechania = ' '.join(map(str, ads[10].text.split()))#[0]\n",
    "    except IndexError:\n",
    "        primechania = 'NaN'\n",
    "        #except:\n",
    "            #primechania = ' '\n",
    "        #try:\n",
    "    try:\n",
    "        url =  \"http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447215&fond=3236&opis=6065&delo=5029718\"\n",
    "    except IndexError:\n",
    "        url = 'NaN'\n",
    "            #url = 'http://1937god.info'+ ad.find('span', class_='field-content').find('a').get('href')\n",
    "        #except:\n",
    "            #url = ' '\n",
    "            \n",
    "    data = {'familia':familia,\n",
    "                    'name':name,\n",
    "                    'otch':otch,\n",
    "                    'together':together,\n",
    "                    'nomer_dela':nomer_dela,\n",
    "                    'deloproizvod_nomer':deloproizvod_nomer,\n",
    "                    'krainie_dat':krainie_dat,\n",
    "                    'primechania':primechania,\n",
    "                    'url':url}\n",
    "    write_csv(data)\n",
    "    #print(data)\n",
    "    #print(len(ads))\n",
    "    \n",
    "def main ():\n",
    "    url = \"http://1937god.info/persons?page=1\"\n",
    "    url_2 = \"http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447472&fond=3236&opis=6074&delo=5107839\"\n",
    "    url_3 = \"http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447474&fond=3236&opis=6074&delo=5117404\"\n",
    "    base_url = 'http://opisi.garf.su/default.asp?base=garf&menu=2&v=7&node=576&co=335244&cd=1447472&fond=3236&opis=6074&delo=5'\n",
    "    #base_url = 'http://1937god.info/persons?'\n",
    "    page_part = 'page='\n",
    "    \n",
    "    #total_pages = get_total_pages(get_html(url))\n",
    "    \n",
    "    for i in range(107839, 117405):\n",
    "    #for i in range(37188, 37193):\n",
    "        #if i == 29833 or i == 29835 or i == 29840 or i == 29841 or i == 29849:\n",
    "            #continue\n",
    "        #url_gen = base_url + page_part + str(i)\n",
    "        #print(url_gen)\n",
    "        #html = get_html(url_gen)\n",
    "        url_2 = base_url + str(i)\n",
    "        #print(url_2)\n",
    "        html = get_html(url_2)\n",
    "        #print(html)\n",
    "        get_page_data(html)\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    \n",
    "#Soup = BeautifulSoup(r.content.decode('utf-8','ignore'),\"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "data_12 = pd.read_csv(\"C:\\\\Users\\\\User\\\\PycharmProjects\\\\garf_12.csv\", engine ='python',names= ['familia', 'name','otch', 'together','nomer_dela', 'deloproizvod_nomer','krainie_dat', 'primechania', 'url'])\n",
    "pd.DataFrame.to_csv(data_12, 'garf_1212.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
